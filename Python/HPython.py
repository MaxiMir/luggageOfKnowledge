####### Python #######

'''
Документация на русском (неофициальная, неполная) https://pythoner.name/documentation/reference
Документация на английском (официальная, полная) https://docs.python.org/3/
'''

#@ Типы данных и переменные

# числа

number1 = 42
number2 = -1000.005

# строки

string1 = "string"
string2 = 'string (another)'
long_string = '''very
"long" string with various 'quotes'
inside'''

# логические значения

x = True
y = False


#@ Преобразование типов
one = int('234')
two = str(34)


#@ Операции

# Арифметические операции
1 + 5 - 8 * 3 / 2 % 4

# Логические операции
True or False and not True

# Создание переменных
string = 'i am a string'

# Обращение к символам строки
string[0]  # i
print("-> {}".format(string)) # -> i am a string
print('-> ' + string) # -> i am a string


# Условные конструкции
if a > b:
	 print('a больше, чем b')
elif a == b:
    print('a равен b')
else:
	 print('a меньше, чем b')

result = 'yes' if a > b else 'no'


# Циклы
i = 1
while i <= 10:
    i = i + 1
    print(i)
    if i > 5:
        break


# Функции

# Определение функции
def get(string, index=0):
    return string[index]

# Вызов функции
get('lala', 3)


'''
src/solution.py
Реализуйте функцию binary, которая возвращает двоичное представление десятичного числа в виде строки.

Алгоритм
Перевод числа из десятичной системы в двоичную делается по следующему алгоритму:

Исходное число (number) делится пополам.
Остаток от деления (modulo) записывается в начало строки (result).
Исходным числом становится число полученное по формуле: number // 2.
Если исходное число (number) больше нуля, то повторяем с первого пункта.
Если исходное число равно нулю, то возвращаем (result).

10 / 2  5 0
 5 / 2  2 1
 2 / 2  1 0
          1
-> 1010

Примеры
'''

binary(0)  # '0'
binary(1)  # '1'
binary(5)  # '101'

'''
Подсказки
Перед добавлением в строку числа нужно превратить в строки str(modulo)
'''

# FILE: /app/src/solution.py

def binary(number):
    if not number:
        return '0'
    binary_number = ''
    while number:
        bit = number % 2
        binary_number = str(bit) + binary_number
        number = number // 2
    return binary_number


# FILE: /app/tests/test_solution.py
import unittest

import solution

class TestBinary(unittest.TestCase):

    cases = [
		 ['0', 0],
		 ['1', 1],
		 ['101', 5],
		 ['110', 6],
		 ['1011', 11],
		 ['1100101', 101],
		 ['100100101001', 2345],
	 ]

    def test_cases(self):
        for expectation, argument in self.cases:
            self.assertEqual(1, 1)



'''*@@@
src/solution.py
Реализуйте и функцию is_power_of_three, которая определяет, является ли переданное число натуральной степенью тройки. Например, число 27 — это третья степень: 3 ** 3, а 81 — это четвёртая: 3 ** 4.

>>> is_power_of_three(1)
True
>>> is_power_of_three(2)
False
>>> is_power_of_three(9)
True
'''

def is_power_of_three(number):
    counter = 1  # 3 ** 0
    while counter < number:
		  counter *= 3
    return counter == number



'''*@@@
Реализуйте функцию fib, находящую положительные Числа Фибоначчи. Аргументом функции является порядковый номер числа.
'''
def fib(index):
    if index <= 0:
        result = 0
    elif index == 1:
        result = 1
    else:
        result = fib(index - 1) + fib(index - 2)
    return result


'''*@@@
Реализуйте функцию binary_sum, которая принимает на вход два двоичных числа (в виде строк) и возвращает их сумму. Результат (вычисленная сумма) также должен быть бинарным числом в виде строки.

Посмотрите примеры работы функции:
'''

binary_sum('10', '1')      # 11
binary_sum('1101', '101')  # 10010

def binary_sum(number_a, number_b):
    binary_a = int(number_a, base=2)
    binary_b = int(number_b, base=2)
    return bin(binary_a + binary_b).replace('0b', '')


'''*@@@
Реализуйте функцию fizz_buzz, которая возвращает строку с числами (через пробел) в диапазоне от begin до end включительно. При этом:

> Если число делится без остатка на 3, то вместо него выводится слово Fizz
> Если число делится без остатка на 5, то вместо него выводится слово Buzz
> Если число делится без остатка и на 3, и на 5, то вместо числа выводится слово FizzBuzz
> В остальных случаях в строку добавляется само число
Функция принимает два параметра (begin и end), определяющих начало и конец диапазона (включительно). Если диапазон пуст (в случае, когда begin > end), то функция возвращает пустую строку.
'''

def fizz_buzz(start, stop):
    result = ''
    while start <= stop:
        if result:
            result += ' '
        if start % 15 == 0:
            result += 'FizzBuzz'
        elif start % 3 == 0:
            result += 'Fizz'
        elif start % 5 == 0:
            result += 'Buzz'
        else:
            result += str(start)
        start += 1
    return result




'''*@@@
Реализуйте функцию is_palindrome, которая принимает на вход слово, определяет является ли оно палиндромом и возвращает логическое значение.

Примеры использования:
'''

is_palindrome('radar')  # True
is_palindrome('a')      # True
is_palindrome('abs')    # False

def is_palindrome(string):
    start = 0
    end = len(string) - 1
    while end - start > 0:
        if string[start] != string[end]:
            return False
        start += 1
        end -= 1
    return True


'''*@@@
В этом испытании вы будете работать с "тройками" — кортежами из трёх элементов. Вам предстоит реализовать две функции, которые "вращают" тройку влево и вправо. Как это выглядит, вы можете понять из пары примеров:

>>> triple = ('A', 'B', 'C')
>>> rotate_left(triple)
('B', 'C', 'A')
>>> rotate_right(triple)
('C', 'A', 'B')
'''

def rotate_left(triple):
    elem1, elem2, elem3 = triple
    return (elem2, elem3, elem1)


def rotate_right(triple):
    elem1, elem2, elem3 = triple
    return (elem3, elem1, elem2)


#>>>>>> Отладка <<<<<<

'''
Один из наиболее достоверных способов убедиться в том, что человек разбирается в программировании — посмотреть на то, как он отлаживает программу, то есть анализирует возникающие ошибки и устраняет их. Навык отладки (дебага, debug) не появляется сам по себе, его необходимо развивать и начинать это делать нужно как можно раньше. Этому весьма способствует настройка локальной среды разработки и повторение всего того, что делается в курсах, у себя на компьютере. Следующие курсы как раз помогают проделать эти шаги.

Первое, что вам понадобится для отладки — это хотя бы минимальное знание английского языка и умение пользоваться словарём. В отличие от документации языка, которую можно найти на русском, сообщения об ошибках будут всегда написаны на английском. Не пытайтесь отгадывать или менять код методом тыка в надежде, что он заработает. Прочитайте сообщение об ошибке, поймите его. Понимание — это ключевое действие, на основе которого можно планировать дальнейшие шаги.

Traceback (most recent call last):
  File "users.py", line 4, in <module>
    main()
  File "users.py", line 2, in main
    create()
NameError: name 'create' is not defined


Вывод ошибок делится на две части: непосредственно сообщение об ошибке и трейсбэк (traceback). Traceback — это список всех вызовов функций от запуска программы вплоть до того места, где произошла ошибка. Трейсбэк — очень важный инструмент, который позволяет увидеть то, как выполнялась ваша программа и какие функции вызывались. Отладка всегда сводится к двум вещам:

1. Перевести сообщение об ошибке
2. Найти в трейсбэке то место в своем коде, в котором произошла ошибка.

Каждая запись в трейсбэке представляет собой указание на файл и строчку, в которой была вызвана соответствующая функция. В рамках одного трейсбэка возможны (и часто встречаются) ситуации, когда часть функций вызывается где-то в библиотеках, которые вы не писали, но используете, а часть — в вашем коде.

# Типы ошибок
Наиболее простые и понятные ошибки — синтаксические. Они связаны исключительно с тем, что код записан неверно, например, забыта точка с запятой в конце инструкции. В выводе таких ошибок всегда присутствует фраза "SyntaxError: …". Для их исправления нужно открыть то место в коде, на которое указывает ошибка, и внимательно на него посмотреть.

Traceback (most recent call last):
  File "users.py", line 2
    print("Hello" + "world')
                           ^
SyntaxError: EOL while scanning string literal


Ещё одна большая группа ошибок называется ошибками программирования. К ним, например, относятся:

- вызов несуществующей функции
	 - использование необъявленной переменной
	 - передача неверных аргументов в функции, например, аргументов, имеющих неверный тип

Эти ошибки исправить труднее, чем синтаксические. Обычно они возникают в результате неправильной логики в другом, более раннем вызове.

	 Последний тип ошибок — логические ошибки. Исправить такие ошибки бывает крайне сложно, так как программа продолжает работать, но выдаёт неверный результат. Причём, обычно программа выдаёт неверный результат не всегда, а только лишь для некоторых входных данных. В подавляющем большинстве случаев проблема кроется в неверной логике: скажем, если перепутана операция, и вместо сложения выполняется вычитание.
'''

# Функция должна считать сумму чисел, но считает разность:
def sum(a, b):
    return a - b

# при таком вызове ошибка неочевидна, потому что
# и при сложении и при вычитании будет один и тот же результат
sum(4, 0)  # 4

# Отладка

'''
Существует множество способов отладки программ. Но какой бы способ вы не выбрали, общая идея отладки сводится к анализу того, как меняются значения переменных в процессе работы кода.

	 Рассмотрим конкретный пример. Ниже описана функция, которая считает сумму чисел от числа start до числа finish. Если начало равно трём, а конец — пяти, то программа должна вычислить: 3 + 4 + 5.
'''
def sum_of_series(start, finish):
    result = 0
    n = start
    while n < finish:
        result += n
        n += 1
    return result

'''
В этом коде допущена ошибка. Вы её видите? Если очень постараться, ошибку можно заметить, но на это никогда не стоит надеяться. Новички часто думают, что они невнимательны, и очень расстраиваются, когда допускают такие ошибки. Хочу вас успокоить: опытные разработчики допускают такие ошибки не реже новичков. Важно не то, что вы их допускаете, а то, что вы способны отладить этот код (и сделать это быстро). Этим отличаются опытные разработчики от начинающих. Никогда не пытайтесь найти ошибку с помощью "медитации" над кодом, сверля его взглядом. Если быстрая проверка не дала ответа, то приступайте к отладке.

	 На Хекслете, в обсуждении уроков, ученики часто нам пишут: "этот код не работает", и показывают свой код. Вероятно, начинающие разработчики думают, что опытные могут понять, в чём ошибка и найти её, просто посмотрев на код. Но это совсем не так. Глядя на такой код, невозможно понять, а что, собственно, пошло не так. И я уже не говорю про нахождение самой ошибки. Нам также нужно увидеть сообщение об ошибке и начать отладку.

	 Глядя на код функции sum_of_series замечаем, что основных переменных там две: n и result — именно они меняются в цикле. Из этого можно сделать ровно один вывод: нужно явно посмотреть, какие значения им даются на каждой итерации. После этого найти ошибку не составит труда.

	 Один из способов отслеживать значения переменных во время выполнения кода связан с использованием специальных программ-отладчиков. Отладчики интегрируются с популярными редакторами и позволяют визуально выполнить код по шагам, отслеживая любые изменения. Подробнее о том, как их использовать можно прочитать во множестве статей (гуглить "python pdb").
'''

# Отладочная печать

'''
В среде Хекслета отладчика нет, поэтому здесь используется другой подход (но выполняющий ту же задачу) — отладочная печать. Суть такая же, как и в визуальном отладчике, но для вывода значений переменных используется обычная печать на экран:
'''

def sum_of_series(start, finish):
    result = 0
    n = start
    while n < finish:
        print('new iteration !!!!')
        print(n)
        result += n
        n += 1
        print(result)
    return result

sum_of_series(3, 5)

# new iteration !!!!
# 3
# 3
# new iteration !!!!
# 4
# 7

'''
То, что печатается на экран, отображается во вкладке OUTPUT, на которую автоматически переключается редактор во время проверки. Из этого вывода сразу можно понять, что итераций цикла на одну меньше, чем нужно. Почему-то не выполняется сложение для последнего числа, которое обозначено как finish. И действительно, если посмотреть на определение, то видно, что там используется n < finish вместо n <= finish.

# Дополнительные материалы
	 Как найти ошибки в коде? https://help.hexlet.io/article/7-how-to-debug-code
		 pdb — The Python Debugger https://docs.python.org/3/library/pdb.html
'''



>>>>>> Модули <<<<<<

'''
Программы на Python содержат тысячи, десятки тысяч и сотни тысяч строк кода (есть проекты с миллионами). В таких условиях одним файлом с кодом не обойдёшься — его нужно разбивать на части. Для получения доступа к коду, который находится в других файлах, в Python реализован механизм модулей.

# Модули и импортирование
	 Итак, файл с кодом на Python называется модулем. Имя модуля соответствует имени файла, поэтому файлы в Python принято называть в стиле "snake_case" (отметьте иронию: Python — питон — змея — snake — snake_case). Одни модули могут использовать содержимое других, если импортируют эти другие модули с помощью инструкции import.

	 Строго говоря, в Python импортировать модули можно несколькими способами:

импортировать сам модуль
импортировать отдельные определения из модуля
импортировать всё содержимое модуля сразу


# Импортирование модуля

Рассмотрим применение первого способа — импортирование модуля целиком. Главное удобство упоминания модуля по имени: глядя на код, мы сразу видим, что используемая переменная или вызываемая функция — это часть модуля.

	 Синтаксис импорта: import <имя_модуля (без суффикса ".py")>

Всё просто: после ключевого слова import указываем имя модуля (файла). Но при этом суффикс .py в имени надо опустить. То есть, к примеру, для модуля с именем my_module.py в инструкции импорта достаточно прописать my_module, а полный вид инструкции будет таким: import my_module.

	 В модуле (файле) с именем greeting.py определим функцию say_hi и переменную name:
'''

# file: greeting.py
def say_hi():
    print('Hi!')

name = 'Bob'

// А в модуле с именем main.py сделаем импорт содержимого модуля greeting.py:

# file: main.py
import greeting  # заметьте, расширение ".py" не указывается!

print(greeting.name)  # => Bob
greeting.say_hi()     # => Hi!

'''
Импортирование модуля в таком виде делает модуль доступным по имени — в данном случае это greeting. К содержимому же модуля можно обратиться, как говорят, "через точку". Причём можно как получить доступ к переменным (greeting.name), так и вызывать функции модуля (greeting.say_hi).

# Импортирование отдельных определений

	 Синтаксис импорта: from <имя_модуля (без суффикса ".py")> import <список определений>

	 Иногда из всего модуля нужна пара функций или переменных, а имя модуля слишком длинное, чтобы писать его каждый раз. Здесь нам может пригодиться следующий вариант использования инструкции import:
'''

# file: main.py
from greeting import say_hi, name

print(name)  # используем переменную
say_hi()     # вызываем функцию

'''
Здесь после ключевого слова from указано имя модуля, а затем после ключевого слова import — имена определений из этого модуля, которые мы в дальнейшем хотим использовать напрямую (а не "через точку").

В следующем уроке мы рассмотрим третий вариант импортирования модуля ("импорт всего содержимого") и в целом немного углубим наши познания в этой теме.
'''




>>>>>> Модули поглубже <<<<<<

'''
Продолжим знакомиться с системой модулей языка Python. Но для начала…

# Немного терминологии
В предыдущем уроке несколько раз встречалось словосочетание "через точку". Так часто говорят для краткости. Однако для такой формы записи имён определений (module.name) существует и официальный термин: квалифицированное имя от слова "квалифицировать" ("qualify"). Соответственно, "импорт модуля целиком" (см. прошлый урок) официально называется квалифицированным импортом.

	 Также стоит отметить, что в Python все строчки с import принято располагать в самом начале кода модуля. Такой набор строчек часто называют "блок импортов", хотя синтаксически этот блок никак не выделен — всего лишь обычные строчки одна за другой. Нужна эта группировка во многом для того, чтобы можно было быстро найти, что в текущем модуле откуда пришло — при работе с чужим (и даже своим!) кодом подобным часто приходится заниматься.

# Импорт всего содержимого модуля
	 Ранее мы познакомились с модулями и рассмотрели два из трёх вариантов импортирования — импорт самого модуля и импорт отдельных определений. Рассмотрим оставшийся вариант — импортирование всего содержимого модуля. Пример:
'''
from some_module import *
from another_module import *

'''
Здесь из модулей some_module и another_module импортируются все определения неявно. Часто после такого импорта программисту становятся доступны десятки переменных, констант, функций и тому подобного. В этом-то и кроется проблема! Когда ниже по коду программист, читающий этот код, встречает некое имя, то ему бывает очень сложно понять, откуда это имя взялось — нельзя, просто взглянув на блок импортов, найти источник. Поиск по коду модуля тоже не помогает — все имена определений, импортированных данным способом, скрываются за *!

	 Большинство руководств по написанию хорошего кода на Python крайне не рекомендует использовать такой стиль импортирования. Однако в реальном коде такие импорты встречаются, поэтому мы не могли этот вариант не упомянуть.

# Сочетание способов импортирования
	 Импортирование модуля целиком (т.е. квалифицированное) и импортирование отдельных определений могут сочетаться даже применительно к одному и тому же модулю!

	 Давайте рассмотрим пример.

	 В модуле computation.py определим функцию и переменные:
'''

# file: computation.py
PI = 3.1415926
E = 2.7182818

def pi_times(x):
    return x + PI

// А в модуле main.py сделаем разными способами импорты из модуля computation.py:

# file: main.py
import computation
from computation import PI, E
from computation import pi_times

print(PI)
print(computation.E)
print(pi_times(2))
print(computation.pi_times(E))

'''
Из кода видно, что:

оба способа импорта использованы совместно
импортировать отдельные определения можно в несколько заходов
если модуль импортирован по имени, то "через точку" можно получить доступ и к тем определениям, которые уже явно импортированы
'''

>>>>>> Пакеты <<<<<<

'''
Мы уже знаем, что в Python код хранится в отдельных файлах, называемых модулями. Но если начать делить код достаточно большого проекта на модули, то довольно быстро может возникнуть желание сгруппировать несколько модулей "по смыслу". Или же мы захотим вынести часть модулей из проекта с целью использования оных в других проектах. Для объединения модулей в группы и служат пакеты (packages).

	 Итак, пакет — это папка (далее "каталог") с файлами модулей, имеющая имя в формате "snake_case" и содержащая, помимо прочего, специальный модуль с именем "__init__.py". Именно наличие этого специального файла подсказывает интерпретатору Python, что каталог следует воспринимать именно как пакет.

# Простейший пакет

	 Давайте рассмотрим пример простейшего пакета. Пусть пакет состоит из каталога package и модуля __init__.py внутри этого каталога:

package/
└── __init__.py
Файл __init__.py пусть содержит код:
'''

# file __init__.py
NAME = 'super_package'

// Это, хотя и небольшой, но уже полноценный пакет. Его можно импортировать так же, как мы импортировали бы модуль:

import package

print(package.NAME)

'''
Заметьте — мы не импортировали файл __init__.py непосредственно. При первом обращении к пакету Python автоматически импортирует модуль __init__.py в этом пакете. Поэтому, очевидно, нельзя импортировать "просто каталог" — ведь каталог без файла __init__.py не будет полноценным пакетом!

# Содержимое пакета
	 С простым пакетом всё ясно — его можно использовать как модуль. Но давайте уже перейдём к группировке в пакете нескольких модулей! Для этого в пакет положим ещё два модуля:

package/
├── constants.py
├── functions.py
└── __init__.py
Содержимое модуля constants.py:
'''
# file constants.py
PERSON = 'Alice'

// Содержимое модуля functions.py:
# file functions.py
def greet(who):
    print('Hello, ' + who + '!')

// Когда пакет содержит другие модули, кроме __init__.py, таковые можно импортировать по их именам. В главе про модули упоминались два варианта импортирования: квалифицированный импорт и импортирование отдельных определений. Квалифицированный импорт в данном случае будет выглядеть так:

import package.functions
import package.constants

package.functions.greet(package.constants.PERSON)  # => Hello, Alice!

// Этот вариант самый понятный: в строчке вызова функции greet сразу видно, откуда пришла функция, а откуда — её аргумент. Но писать имя пакета и имя модуля каждый раз — утомительно! Давайте импортируем сами функцию и аргумент:

from package.functions import greet
from package.constants import PERSON

greet(PERSON)  # => Hello, Alice!

// Так строчка вызова функции выглядит гораздо лучше! Но помните, что тому, кто будет читать этот код в дальнейшем, потребуется посмотреть в блок импортов, чтобы узнать, откуда функция и константа появились.

>>>>>>>> Модуль random <<<<<<<<
'''
Python знаменит тем, что поставляется в комплекте с "батарейками" - так называют модули и пакеты, составляющие стандартную библиотеку. Более того, батареек в поставке Пайтона изрядное количество! Настоящий питонист (pythonista) - так мы, программисты на Python, себя называем - обязан хорошо ориентироваться в стандартной библиотеке, ведь это знание позволяет экономить время и силы. В этом уроке мы познакомимся с первой батарейкой - модулем random.

	 При разработке программ довольно часто возникает необходимость получить некоторое случайно выбранное из некоего множества значение. Случайные значения полезны, когда мы разрабатываем компьютерные игры, генерируем изображения и звук, и даже просто пишем тесты.

	 Любое значение в компьютере может быть представлено в виде набора чисел, поэтому получение случайных значений всегда предполагает использование Генератора Случайных Чисел, ГСЧ. ГСЧ бывают программными (специализированные программы) и аппаратными (специализированные устройства), но программист обычно работает с некоторой обобщённой "обёрткой" - модулем или пакетом, который скрывает ненужные детали.

	 Модуль random предоставляет множество функций, полезных в разных ситуациях, но мы пока остановимся на двух:

randint, генерация целого числа в заданном диапазоне,
choice, выбор случайного элемента из заданного набора.

# Генерация случайных чисел
	 Для того, чтобы сгенерировать случайное число, нам нужно импортировать функцию randint из модуля random:
'''
from random import randint

// Теперь мы можем сгенерировать число от 1 до 100:
random_number = randint(1, 100)

// При вызове randint с такими границами диапазона может "выпасть" и 1 и 100 - обе границы диапазона включены и об этом следует помнить. Когда это может быть важно? Давайте рассмотрим другой пример - выбор случайного символа некоторой строки:

string = 'abcde'
random_index = randint(0, len(string) - 1)
char = string[random_index]

'''
Строка в переменной string имеет длину 5. Но мы помним, что символы строки индексируются с нуля, поэтому если сгенерировать индекс так randint(0, 5), то в какой-то момент мы получим значение 5 и при попытке взять символ по этому индексу мы увидим ошибку IndexError: индекс последнего элемента в строке равен 4! Вот поэтому в коде выше из длины вычитается единица.

# Выбор случайного элемента
	 Выше мы рассмотрели пример, в котором выбирался случайный символ строки. Эта задача возникает достаточно часто, поэтому в модуле random существует функция choice. С использованием этой функции выбор символа строки будет выглядеть так:
'''

from random import choice

string = 'abcde'
char = choice(string)

'''
При использовании choice не нужно думать о границах генерируемых индексов. И даже о самих индексах думать не нужно - функция сама знает, как правильно и безопасно выбирать элементы! Правда, придётся заботиться о том, чтобы строка, из который мы выбираем символы, не была пустой, иначе мы получим ошибку IndexError: Cannot choose from an empty sequence ("Нельзя просто так взять и выбрать, если выбирать не из чего").

		 Пока мы можем использовать choice только со строками, ведь это единственный тип, значения которого могут содержать несколько элементов. Но в дальнейшем мы познакомимся и с другими составными типами - и с многими из таких типов функция choice тоже может работать!

# Случайна ли случайность?
	 Строго говоря, генерируемые числа у компьютера получаются не полностью случайными, поэтому большинство ГСЧ представляют собой генераторы псевдослучайных чисел. И хотя для простоты приставку "псевдо-" часто опускают (как поступили и мы), о ней не стоит забывать. Дело в том, что некоторые алгоритмы требуют максимально случайной генерации чисел. Одна из областей с такими высокими требованиями к качеству случайности — криптография (шифрование). Представьте, что вы сгенерировали случайный пароль, длинный и сложный, а злоумышленник, пользуясь тем, что при определённых условиях можно воспроизвести ту же последовательность случайных чисел, получил тот же пароль! Вот поэтому существует большое количество специализированных ГСЧ, безопасных для использования в шифровании и создание таких генераторов - это важная, сложная и интересная работа.

# Ссылки
	 Модуль random https://docs.python.org/3.6/library/random.html
ГСЧ https://ru.wikipedia.org/wiki/Генератор_псевдослучайных_чисел
'''

>>>>>> Кортежи <<<<<<<
'''
До этого момента мы встречались только с примитивными типами — строка, число, булев тип. Ещё нам знакомы функции и модули с пакетами (да, в Python модули и пакеты, это тоже значения специальных встроенных типов). Но часто в программировании приходится создавать более сложные, чем числа и строки, значения и манипулировать такими значениями. Именно поэтому во многих языках программирования есть составные типы. Значение составного типа может состоять как из значений примитивных типов, так и из значений других составных типов, таким образом составные типы позволяют описывать сущности произвольной сложности — и шахматные доски, и космические ракеты!

	 В этом уроке мы познакомимся с самым простым, но очень полезным составным типом — кортежем (в англоязычных текстах оный известен, как tuple).

# Кортежи
Кортеж — это несколько значений, записанных через запятую. Да, всё очень просто! Вот несколько примеров:
'''
rgb_colour = (255, 127, 64)
name_and_age = ('Bob', 42)
three_booleans = (True, False, True)
two_pairs_of_numbers = ((1, 2), (3, 4))

'''
Определять кортежи очень просто, сложности могут возникнуть только с кортежами, содержащими ровно один элемент. Если мы просто укажем значение в скобках, то Python подумает, что мы хотим посчитать арифметическое выражение со скобками:
'''
not_a_tuple = (42)  # 42

// Чтобы сказать пайтону, что мы хотим создать именно кортеж, нужно поставить после элемента кортежа запятую:

tuple = (42,)  # (42,)

'''
Да, форма записи довольно необычная, но вы привыкнете :)

# Возврат нескольких значений из функции
Кортежи очень полезны, когда нам нужно вернуть из функции сразу несколько значений. Так, функция, которая принимает два аргумента-числа и возвращает одновременно результат деления нацело и остаток от деления, будет выглядеть так:
'''

def div_mod(a, b):
    quotient = a // b
    modulo = a % b
    return (quotient, modulo)

div_mod(13, 4)  # (3, 1)

'''
# Получение элементов кортежа по индексу
Выше мы только создавали кортежи. Теперь научимся их разбирать! В простейшем случае достаточно обратиться к элементу кортежа по индексу:
'''

name_and_age = ('Bob', 42)

name_and_age[0]  # 'Bob'
name_and_age[1]  # 42

// Также у кортежа есть длина, которую, как и для строки, можно получить с помощью функции len:

tuple = (42,)  # (42,)
len(tuple)     # 1
pair = (1, 2)  # (1, 2)
len(pair)      # 2

'''
# Деструктуризация
Обращение по индексу, это не самый удобный способ работы с кортежами. Дело в том, что кортежи часто содержат значения разных типов, и помнить, по какому индексу что лежит — очень непросто. Но есть способ лучше! Как мы кортеж собираем, так его можно и разобрать:
'''

name_and_age = ('Bob', 42)

(name, age) = name_and_age
name  # 'Bob'
age   # 42

'''
Именно таким способом принято получать и сразу разбирать значения, которые возвращает функция (если таковая возвращает несколько значений, конечно):
'''
(quotient, modulo) = div_mod(13, 4)

// Соответственно кортеж из одного элемента нужно разбирать так:
(a,) = (42,)
a  # 42

'''
Если же после имени переменной не поставить запятую, то синтаксической ошибки не будет, но в переменную a кортеж запишется целиком, т.е. ничего не распакуется! Всегда помните о запятых!

# Кортежи, множественное присваивание и обмен значениями
	 Благодаря тому, что кортежи легко собирать и разбирать, в Python удобно делать такие вещи, как множественное присваивание. Смотрите:
'''
(a, b, c) = (1, 2, 3)
a  # 1
b  # 2
c  # 3

// Используя множественное присваивание, можно провернуть интересный трюк: обмен значениями между двумя переменными. Вот код:

a = 100
b = 'foo'

(a, b) = (b, a)
a  # 'foo'
b  # 100

'''
Cтрочку (a, b) = (b, a) нужно понимать как "присвоить в а и b значения из кортежа, состоящего из значений переменных b и a".

# Ссылки
	 Кортеж https://ru.wikipedia.org/wiki/Кортеж_(информатика)
'''


>>>>>> История развития языка Python <<<<<<

'''
Итак, мы учимся языку Python. Для начала стоит определиться с названием. Правильно говорить "Пайтон" с ударением на первом слоге — язык назван в честь известного комедийного шоу "Летающий Цирк Монти Пайтона", т.е. Пайтон — это фамилия, а фамилию человека принято произносить так, как это делает носитель фамилии!

	 Ещё пара сухих фактов:

Первый релиз интерпретатора языка Python был представлен в далёком 1991г,
Автор языка — Гвидо ван Россум.
	 Сам по себе язык — это не то же самое, что его интерпретаторы. Но основная реализация языка — CPython — настолько распространена, что почти всегда, когда мы слышим "Python", подразумевается именно она. Наши курсы тоже будут касаться именно CPython, это стоит иметь в виду!

# Самое начало
	 Python появился, чтобы заменить собой язык ABC, в работе над которым принимал участие будущий автор пайтона Гвидо ван Россум. Представленный в 1991 году Python версии 0.9.0 вобрал в себя многие идеи из существовавших на тот момент языков: например, взяв систему модулей из языка Modula-3. Элементы функционального программирования (их мы будем изучать в следующих курсах!) — функции map, filter, reduce — появились в языке тоже довольно рано, в версии 1.0.

	 Стоит отметить, что Пайтон изначально позиционировался как "язык для каждого", поэтому большой упор делался на читаемость кода и лаконичность синтаксиса. В версии 2.0 появились знаменитые "списковые включения" ("list comprehensions"), позаимствованные из языков SETL и Haskell. В этой же версии сборщик мусора (механизм автоматического управления памятью) научился работать с циклическими структурами. С ними мы также познакомимся в последующих курсах.

# Py2 vs Py3
	 Python, как язык, непрерывно развивается с самого начала времени своего существования. На данный момент в основном используются версии языка, начинающиеся с "3".

	 Первый релиз "третьего пайтона" (python3, py3) вышел ещё в 2008 году, но переход на это семейство версий со "второго пайтона" (python2, py2) происходил (кое-где всё ещё происходит!) "со скрипом". Дело в том, что py3 не полностью обратно совместим с кодом, написанным для py2, т.е. мы не можем просто заменить интерпретатор — нам потребуется внести определённые изменения в код! На такой шаг можно пойти, если наш проект — живой. Но с проектами, находящимися в состоянии "только поддержка" (такие проекты ещё называют legacy), такой фокус не пройдёт — обычно просто некому заниматься адаптацией. А ведь legacy-проекты — это не всегда лишь конечные приложения, в такой ситуации могут оказаться и библиотеки. Именно из-за невозможности отказаться от нужных, но существующих в состоянии legacy, библиотек многие проекты долго оставались несовместимыми с py3.

	 К счастью, сейчас большая часть библиотек, достаточно популярных и полезных в повседневной жизни разработчика, успешно переведена на py3, и новые проекты нужно делать именно на какой-то из версий этого семейства (сейчас рекомендуемая версия — это Python 3.7.x). Более того, py2 скоро перестанет быть безопасным для широкого использования! Дело в том, что техническая поддержка py2 — т.е. устранение уязвимостей и критических ошибок — с 2020г перестанет осуществляться. А мы ведь не хотим подвергать угрозе свои детища!

# Системный Python
	 Работая с Python, стоит иметь в виду, что Python распространён не только в виде языка, на котором пишутся конечные проекты: этот язык часто используется для автоматизации различных задач, скажем, по системному администрированию (Ansible — один из примеров написанного на Python ПО, используемого при администрировании). Поэтому python часто уже присутствует в установленных операционных системах.

	 Особенно велика вероятность обнаружить в системе установленный Python, когда речь идёт об ОС семейства Linux — а именно, какая-то из версий Linux будет скорее всего установлена на машину, на которой вы захотите запустить сервер своего web-приложения или многопользовательской игры (да, такие тоже пишут на Python!). Тут-то и кроется проблема: установленный вместе с операционной системой Python может быть тем самым "вторым пайтоном" — да, такое, увы, пока встречается. И заменить его будет нельзя, ведь замена может привести к выходу из строя всей ОС.

	 Но не пугайтесь, в курсе про настройку окружения вы узнаете, как использовать в проекте нужную версию Python и не бояться сломать что-то другое!
'''

'''*@@@
	 src/solution.py
Реализуйте функцию sort_pair, которая принимает пару (кортеж из двух значений) и возвращает пару, значения которой расположенны строго в порядке возрастания.

	 Пример:
'''

# обратите внимание на скобки у аргумента функции
sort_pair((5, 1)) == (1, 5)
sort_pair((2, 2)) == (2, 2)
sort_pair((7, 8)) == (7, 8)


// FILE /app/src/solution.py:
def sort_pair(pair):
    (first, second) = pair
    if first > second:
        return (second, first)
    return pair


'''*@@@
	 src/package/__init__.py
Дан пакет следующей структуры:

$ tree package
package/
├── __init__.py
├── functions.py
└── names.py
Добавьте в __init__.py блок импортов таким образом, чтобы можно было импортировать package и получить доступ

к константе NAME из package.names
к функции greet из package.functions
Если задание будет выполнено успешно, то следующий код должен будет работать:
'''

from package import greet, NAME

greet(NAME)  # 'Hello, Bob!'


// FILE: /app/src/__init__.py:
from package.names import NAME
from package.functions import greet


// FILE: /app/src/functions.py:
def greet(name):
    return 'Hello, {}!'.format(name)

// FILE: /app/src/names.py:
NAME = 'Bob'




'>>>>>> HTTP <<<<<<

'''
Популярный вопрос на собеседовании веб-разработчиков часто звучит так: «Что происходит после того, как в браузер ввели адрес сайта?». Подробный ответ на этот вопрос можно найти здесь. Главное, что хочет услышать собеседующий — ваш уровень понимания HTTP (Hyper-Text Transferring Protocol).

Для начала пару слов о том, что такое протокол. Протокол — это набор соглашений, правил, по которым разные программы могут обмениваться информацией. HTTP — это набор правил, который известен и вашему компьютеру и физически отдалённому компьютеру. С помощью него общаются браузер и веб-сервер.

Веб-сервер — программа, установленная на сервере и обслуживающая входящие соединения, например, от браузеров. В рамках такого соединения от браузера передаётся информация о том, какую страницу и какого сайта мы хотим загрузить, а веб-сервер, в свою очередь, возвращает браузеру содержимое страницы этого сайта.

Пример http-сессии (запрос-ответ) через программу curl:
'''
$ curl --head -v code-basics.ru
	 * Rebuilt URL to: code-basics.ru/
*   Trying 35.157.19.194...
* TCP_NODELAY set
	 * Connected to code-basics.ru (35.157.19.194) port 80 (#0)
> GET / HTTP/1.1
> Host: code-basics.ru
	 > User-Agent: curl/7.54.0
	 > Accept: *'''
>
< HTTP/1.1 200 OK
< Date: Sun, 07 Jan 2018 14:19:00 GMT
< Content-Type: text/html; charset=utf-8
< Content-Length: 5123
< Connection: keep-alive
< server: Cowboy
< cache-control: max-age=0, private, must-revalidate
<
* Connection #0 to host code-basics.ru left intact

'''
http нужно не просто знать, но и уметь делать сырые http-запросы — не косвенно через браузер, а самостоятельно, эмулируя поведение браузера. Для этой задачи используют программу telnet.

# Для чего требуется знание http?
	 Работа с формами, загрузка файлов, перенаправления.
	 Аутентификация целиком зависит от http.
	 Извлечение информации о запросе (например, определение браузера, из которого был выполнен запрос).
Увеличение производительности. Кеширование.
	 Обеспечение безопасности. http — текстовый протокол без шифрования, он не безопасен.

# https
	 Кроме http, в сети всё большее распространение получает https. Каждый пользователь сети должен знать, что нельзя выполнять действия, связанные с любыми секретными данными (например кредитками), на страницах, работающих по протоколу http. В таком случае любой человек, имеющий доступ к оборудованию, которое лежит между вами и сервером, обслуживающим сайт, сможет прочитать эти данные. Обратите внимание, что на популярных сайтах страницы оплаты всегда отдаются по https. В свою очередь, умение работать с https сразу добавляет новые понятия:

Шифрование, асимметричное шифрование
Сертификаты
Цифровая подпись

# TCP/IP
Но одним http обойтись не получится. Дело в том, что http существует не сам по себе, а поверх стека протоколов TCP/IP. Базовое знание сетей важно по следующим причинам:

Безопасность. Очень легко совершить ошибку и быть взломанным.
	 Отладка. Немалая часть вопросов запуска и конфигурирования сайтов и их частей (в том числе базы данных) связана с сетевыми сокетами. Не зная сети вы будете останавливаться на любой простейшей проблеме без понимания, что вообще делать.

# DNS
	 Ещё один столп веба — DNS, служба доменных имён. Каждый раз, когда мы вбиваем адрес в браузер, он выполняет DNS запросы к соответствующим серверам для выяснения того, какой ip-адрес принадлежит сайту. Дело в том, что соединение с сервером идёт по tcp/ip, а не по http. http начинает работать уже после того, как было установлено tcp соединение. Знание DNS важно по следующим причинам:

Зная DNS вы сможете не только купить домен, но и привязать его к вашему серверу
Почта для домена, верификация вашего проекта различными сервисами — всё это работает через возможности DNS
Опять же, отладка. Нередко проблемы загрузки связаны с DNS.
'''<?

####### Python #######

#@ Документация
'''
Документация на русском (неофициальная, неполная) https://pythoner.name/documentation/reference
Документация на английском (официальная, полная) https://docs.python.org/3/
'''

#@ Типы данных и переменные

# числа

number1 = 42
number2 = -1000.005

# строки

string1 = "string"
string2 = 'string (another)'
long_string = '''very
"long" string with various 'quotes'
inside'''

# логические значения

x = True
y = False


#@ Преобразование типов
one = int('234')
two = str(34)


#@ Операции

# Арифметические операции
1 + 5 - 8 * 3 / 2 % 4

# Логические операции
True or False and not True

# Создание переменных
string = 'i am a string'

# Обращение к символам строки
string[0]  # i
print("-> {}".format(string))  # -> i am a string
print('-> ' + string)          # -> i am a string


# Условные конструкции
if a > b:
    print('a больше, чем b')
elif a == b:
    print('a равен b')
else:
    print('a меньше, чем b')

result = 'yes' if a > b else 'no'


# Циклы
i = 1
while i <= 10:
    i = i + 1
    print(i)
    if i > 5:
        break


# Функции

# Определение функции
def get(string, index=0):
    return string[index]

# Вызов функции
get('lala', 3)

'''
src/solution.py
Реализуйте функцию binary, которая возвращает двоичное представление десятичного числа в виде строки.

	 Алгоритм
Перевод числа из десятичной системы в двоичную делается по следующему алгоритму:

Исходное число (number) делится пополам.
	 Остаток от деления (modulo) записывается в начало строки (result).
	 Исходным числом становится число полученное по формуле: number // 2.
Если исходное число (number) больше нуля, то повторяем с первого пункта.
	 Если исходное число равно нулю, то возвращаем (result).

	 10 / 2  5 0
 5 / 2  2 1
 2 / 2  1 0
          1
-> 1010

Примеры

binary(0)  # '0'
binary(1)  # '1'
binary(5)  # '101'


Подсказки
Перед добавлением в строку числа нужно превратить в строки str(modulo)
'''

// FILE: /app/src/solution.py
def binary(number):
    if not number:
        return '0'
    binary_number = ''
    while number:
        bit = number % 2
        binary_number = str(bit) + binary_number
        number = number // 2
    return binary_number


// FILE: /app/tests/test_solution.py
import unittest

import solution


class TestBinary(unittest.TestCase):

    cases = [
        ['0', 0],
        ['1', 1],
        ['101', 5],
        ['110', 6],
        ['1011', 11],
        ['1100101', 101],
        ['100100101001', 2345],
    ]

    def test_cases(self):
        for expectation, argument in self.cases:
            self.assertEqual(1, 1)



'''*@@@
	 src/solution.py
Реализуйте и функцию is_power_of_three, которая определяет, является ли переданное число натуральной степенью тройки. Например, число 27 — это третья степень: 3 ** 3, а 81 — это четвёртая: 3 ** 4.

	 >>> is_power_of_three(1)
True
>>> is_power_of_three(2)
False
>>> is_power_of_three(9)
True
 '''

def is_power_of_three(number):
    counter = 1  # 3 ** 0
    while counter < number:
		  counter *= 3
    return counter == number




>>>>>> Отладка <<<<<<

'''
Один из наиболее достоверных способов убедиться в том, что человек разбирается в программировании — посмотреть на то, как он отлаживает программу, то есть анализирует возникающие ошибки и устраняет их. Навык отладки (дебага, debug) не появляется сам по себе, его необходимо развивать и начинать это делать нужно как можно раньше. Этому весьма способствует настройка локальной среды разработки и повторение всего того, что делается в курсах, у себя на компьютере. Следующие курсы как раз помогают проделать эти шаги.

	 Первое, что вам понадобится для отладки — это хотя бы минимальное знание английского языка и умение пользоваться словарём. В отличие от документации языка, которую можно найти на русском, сообщения об ошибках будут всегда написаны на английском. Не пытайтесь отгадывать или менять код методом тыка в надежде, что он заработает. Прочитайте сообщение об ошибке, поймите его. Понимание — это ключевое действие, на основе которого можно планировать дальнейшие шаги.

	 Traceback (most recent call last):
  File "users.py", line 4, in <module>
    main()
  File "users.py", line 2, in main
    create()
NameError: name 'create' is not defined


Вывод ошибок делится на две части: непосредственно сообщение об ошибке и трейсбэк (traceback). Traceback — это список всех вызовов функций от запуска программы вплоть до того места, где произошла ошибка. Трейсбэк — очень важный инструмент, который позволяет увидеть то, как выполнялась ваша программа и какие функции вызывались. Отладка всегда сводится к двум вещам:

1. Перевести сообщение об ошибке
2. Найти в трейсбэке то место в своем коде, в котором произошла ошибка.

	 Каждая запись в трейсбэке представляет собой указание на файл и строчку, в которой была вызвана соответствующая функция. В рамках одного трейсбэка возможны (и часто встречаются) ситуации, когда часть функций вызывается где-то в библиотеках, которые вы не писали, но используете, а часть — в вашем коде.

# Типы ошибок
	 Наиболее простые и понятные ошибки — синтаксические. Они связаны исключительно с тем, что код записан неверно, например, забыта точка с запятой в конце инструкции. В выводе таких ошибок всегда присутствует фраза "SyntaxError: …". Для их исправления нужно открыть то место в коде, на которое указывает ошибка, и внимательно на него посмотреть.

	 Traceback (most recent call last):
  File "users.py", line 2
    print("Hello" + "world')
                           ^
SyntaxError: EOL while scanning string literal


Ещё одна большая группа ошибок называется ошибками программирования. К ним, например, относятся:

- вызов несуществующей функции
- использование необъявленной переменной
- передача неверных аргументов в функции, например, аргументов, имеющих неверный тип

Эти ошибки исправить труднее, чем синтаксические. Обычно они возникают в результате неправильной логики в другом, более раннем вызове.

Последний тип ошибок — логические ошибки. Исправить такие ошибки бывает крайне сложно, так как программа продолжает работать, но выдаёт неверный результат. Причём, обычно программа выдаёт неверный результат не всегда, а только лишь для некоторых входных данных. В подавляющем большинстве случаев проблема кроется в неверной логике: скажем, если перепутана операция, и вместо сложения выполняется вычитание.
'''
# Функция должна считать сумму чисел, но считает разность:
def sum(a, b):
    return a - b

# при таком вызове ошибка неочевидна, потому что
# и при сложении и при вычитании будет один и тот же результат
sum(4, 0)  # 4

# Отладка

'''
Существует множество способов отладки программ. Но какой бы способ вы не выбрали, общая идея отладки сводится к анализу того, как меняются значения переменных в процессе работы кода.

Рассмотрим конкретный пример. Ниже описана функция, которая считает сумму чисел от числа start до числа finish. Если начало равно трём, а конец — пяти, то программа должна вычислить: 3 + 4 + 5.
'''
def sum_of_series(start, finish):
    result = 0
    n = start
    while n < finish:
        result += n
        n += 1
    return result

'''
В этом коде допущена ошибка. Вы её видите? Если очень постараться, ошибку можно заметить, но на это никогда не стоит надеяться. Новички часто думают, что они невнимательны, и очень расстраиваются, когда допускают такие ошибки. Хочу вас успокоить: опытные разработчики допускают такие ошибки не реже новичков. Важно не то, что вы их допускаете, а то, что вы способны отладить этот код (и сделать это быстро). Этим отличаются опытные разработчики от начинающих. Никогда не пытайтесь найти ошибку с помощью "медитации" над кодом, сверля его взглядом. Если быстрая проверка не дала ответа, то приступайте к отладке.

На Хекслете, в обсуждении уроков, ученики часто нам пишут: "этот код не работает", и показывают свой код. Вероятно, начинающие разработчики думают, что опытные могут понять, в чём ошибка и найти её, просто посмотрев на код. Но это совсем не так. Глядя на такой код, невозможно понять, а что, собственно, пошло не так. И я уже не говорю про нахождение самой ошибки. Нам также нужно увидеть сообщение об ошибке и начать отладку.

Глядя на код функции sum_of_series замечаем, что основных переменных там две: n и result — именно они меняются в цикле. Из этого можно сделать ровно один вывод: нужно явно посмотреть, какие значения им даются на каждой итерации. После этого найти ошибку не составит труда.

Один из способов отслеживать значения переменных во время выполнения кода связан с использованием специальных программ-отладчиков. Отладчики интегрируются с популярными редакторами и позволяют визуально выполнить код по шагам, отслеживая любые изменения. Подробнее о том, как их использовать можно прочитать во множестве статей (гуглить "python pdb").
'''

# Отладочная печать

'''
В среде Хекслета отладчика нет, поэтому здесь используется другой подход (но выполняющий ту же задачу) — отладочная печать. Суть такая же, как и в визуальном отладчике, но для вывода значений переменных используется обычная печать на экран:
'''

def sum_of_series(start, finish):
    result = 0
    n = start
    while n < finish:
        print('new iteration !!!!')
        print(n)
        result += n
        n += 1
        print(result)
    return result

sum_of_series(3, 5)

# new iteration !!!!
# 3
# 3
# new iteration !!!!
# 4
# 7

'''
То, что печатается на экран, отображается во вкладке OUTPUT, на которую автоматически переключается редактор во время проверки. Из этого вывода сразу можно понять, что итераций цикла на одну меньше, чем нужно. Почему-то не выполняется сложение для последнего числа, которое обозначено как finish. И действительно, если посмотреть на определение, то видно, что там используется n < finish вместо n <= finish.

# Дополнительные материалы
Как найти ошибки в коде? https://help.hexlet.io/article/7-how-to-debug-code
pdb — The Python Debugger https://docs.python.org/3/library/pdb.html
'''



>>>>>> Модули <<<<<<

'''
Программы на Python содержат тысячи, десятки тысяч и сотни тысяч строк кода (есть проекты с миллионами). В таких условиях одним файлом с кодом не обойдёшься — его нужно разбивать на части. Для получения доступа к коду, который находится в других файлах, в Python реализован механизм модулей.

# Модули и импортирование
Итак, файл с кодом на Python называется модулем. Имя модуля соответствует имени файла, поэтому файлы в Python принято называть в стиле "snake_case" (отметьте иронию: Python — питон — змея — snake — snake_case). Одни модули могут использовать содержимое других, если импортируют эти другие модули с помощью инструкции import.

Строго говоря, в Python импортировать модули можно несколькими способами:

импортировать сам модуль
импортировать отдельные определения из модуля
импортировать всё содержимое модуля сразу


# Импортирование модуля

Рассмотрим применение первого способа — импортирование модуля целиком. Главное удобство упоминания модуля по имени: глядя на код, мы сразу видим, что используемая переменная или вызываемая функция — это часть модуля.

Синтаксис импорта: import <имя_модуля (без суффикса ".py")>

Всё просто: после ключевого слова import указываем имя модуля (файла). Но при этом суффикс .py в имени надо опустить. То есть, к примеру, для модуля с именем my_module.py в инструкции импорта достаточно прописать my_module, а полный вид инструкции будет таким: import my_module.

В модуле (файле) с именем greeting.py определим функцию say_hi и переменную name:
'''

# file: greeting.py
def say_hi():
    print('Hi!')

name = 'Bob'

// А в модуле с именем main.py сделаем импорт содержимого модуля greeting.py:

# file: main.py
import greeting  # заметьте, расширение ".py" не указывается!

print(greeting.name)  # => Bob
greeting.say_hi()     # => Hi!

'''
Импортирование модуля в таком виде делает модуль доступным по имени — в данном случае это greeting. К содержимому же модуля можно обратиться, как говорят, "через точку". Причём можно как получить доступ к переменным (greeting.name), так и вызывать функции модуля (greeting.say_hi).

# Импортирование отдельных определений

Синтаксис импорта: from <имя_модуля (без суффикса ".py")> import <список определений>

Иногда из всего модуля нужна пара функций или переменных, а имя модуля слишком длинное, чтобы писать его каждый раз. Здесь нам может пригодиться следующий вариант использования инструкции import:
'''

# file: main.py
from greeting import say_hi, name

print(name)  # используем переменную
say_hi()     # вызываем функцию

'''
Здесь после ключевого слова from указано имя модуля, а затем после ключевого слова import — имена определений из этого модуля, которые мы в дальнейшем хотим использовать напрямую (а не "через точку").

В следующем уроке мы рассмотрим третий вариант импортирования модуля ("импорт всего содержимого") и в целом немного углубим наши познания в этой теме.
'''




>>>>>> Модули поглубже <<<<<<

'''
Продолжим знакомиться с системой модулей языка Python. Но для начала…

# Немного терминологии
В предыдущем уроке несколько раз встречалось словосочетание "через точку". Так часто говорят для краткости. Однако для такой формы записи имён определений (module.name) существует и официальный термин: квалифицированное имя от слова "квалифицировать" ("qualify"). Соответственно, "импорт модуля целиком" (см. прошлый урок) официально называется квалифицированным импортом.

Также стоит отметить, что в Python все строчки с import принято располагать в самом начале кода модуля. Такой набор строчек часто называют "блок импортов", хотя синтаксически этот блок никак не выделен — всего лишь обычные строчки одна за другой. Нужна эта группировка во многом для того, чтобы можно было быстро найти, что в текущем модуле откуда пришло — при работе с чужим (и даже своим!) кодом подобным часто приходится заниматься.

# Импорт всего содержимого модуля
Ранее мы познакомились с модулями и рассмотрели два из трёх вариантов импортирования — импорт самого модуля и импорт отдельных определений. Рассмотрим оставшийся вариант — импортирование всего содержимого модуля. Пример:
'''
from some_module import *
from another_module import *

'''
Здесь из модулей some_module и another_module импортируются все определения неявно. Часто после такого импорта программисту становятся доступны десятки переменных, констант, функций и тому подобного. В этом-то и кроется проблема! Когда ниже по коду программист, читающий этот код, встречает некое имя, то ему бывает очень сложно понять, откуда это имя взялось — нельзя, просто взглянув на блок импортов, найти источник. Поиск по коду модуля тоже не помогает — все имена определений, импортированных данным способом, скрываются за *!

Большинство руководств по написанию хорошего кода на Python крайне не рекомендует использовать такой стиль импортирования. Однако в реальном коде такие импорты встречаются, поэтому мы не могли этот вариант не упомянуть.

# Сочетание способов импортирования
Импортирование модуля целиком (т.е. квалифицированное) и импортирование отдельных определений могут сочетаться даже применительно к одному и тому же модулю!

Давайте рассмотрим пример.

В модуле computation.py определим функцию и переменные:
'''

# file: computation.py
PI = 3.1415926
E = 2.7182818

def pi_times(x):
    return x + PI

// А в модуле main.py сделаем разными способами импорты из модуля computation.py:

# file: main.py
import computation
from computation import PI, E
from computation import pi_times

print(PI)
print(computation.E)
print(pi_times(2))
print(computation.pi_times(E))

'''
Из кода видно, что:

оба способа импорта использованы совместно
импортировать отдельные определения можно в несколько заходов
если модуль импортирован по имени, то "через точку" можно получить доступ и к тем определениям, которые уже явно импортированы
'''

>>>>>> Пакеты <<<<<<

'''
Мы уже знаем, что в Python код хранится в отдельных файлах, называемых модулями. Но если начать делить код достаточно большого проекта на модули, то довольно быстро может возникнуть желание сгруппировать несколько модулей "по смыслу". Или же мы захотим вынести часть модулей из проекта с целью использования оных в других проектах. Для объединения модулей в группы и служат пакеты (packages).

Итак, пакет — это папка (далее "каталог") с файлами модулей, имеющая имя в формате "snake_case" и содержащая, помимо прочего, специальный модуль с именем "__init__.py". Именно наличие этого специального файла подсказывает интерпретатору Python, что каталог следует воспринимать именно как пакет.

# Простейший пакет

Давайте рассмотрим пример простейшего пакета. Пусть пакет состоит из каталога package и модуля __init__.py внутри этого каталога:

package/
└── __init__.py
Файл __init__.py пусть содержит код:
'''

# file __init__.py
NAME = 'super_package'

// Это, хотя и небольшой, но уже полноценный пакет. Его можно импортировать так же, как мы импортировали бы модуль:

import package

print(package.NAME)

'''
Заметьте — мы не импортировали файл __init__.py непосредственно. При первом обращении к пакету Python автоматически импортирует модуль __init__.py в этом пакете. Поэтому, очевидно, нельзя импортировать "просто каталог" — ведь каталог без файла __init__.py не будет полноценным пакетом!

# Содержимое пакета
С простым пакетом всё ясно — его можно использовать как модуль. Но давайте уже перейдём к группировке в пакете нескольких модулей! Для этого в пакет положим ещё два модуля:

package/
├── constants.py
├── functions.py
└── __init__.py
Содержимое модуля constants.py:
'''
# file constants.py
PERSON = 'Alice'

// Содержимое модуля functions.py:
# file functions.py
def greet(who):
    print('Hello, ' + who + '!')

// Когда пакет содержит другие модули, кроме __init__.py, таковые можно импортировать по их именам. В главе про модули упоминались два варианта импортирования: квалифицированный импорт и импортирование отдельных определений. Квалифицированный импорт в данном случае будет выглядеть так:

import package.functions
import package.constants

package.functions.greet(package.constants.PERSON)  # => Hello, Alice!

// Этот вариант самый понятный: в строчке вызова функции greet сразу видно, откуда пришла функция, а откуда — её аргумент. Но писать имя пакета и имя модуля каждый раз — утомительно! Давайте импортируем сами функцию и аргумент:

from package.functions import greet
from package.constants import PERSON

greet(PERSON)  # => Hello, Alice!

// Так строчка вызова функции выглядит гораздо лучше! Но помните, что тому, кто будет читать этот код в дальнейшем, потребуется посмотреть в блок импортов, чтобы узнать, откуда функция и константа появились.

>>>>>>>> Модуль random <<<<<<<<
'''
Python знаменит тем, что поставляется в комплекте с "батарейками" - так называют модули и пакеты, составляющие стандартную библиотеку. Более того, батареек в поставке Пайтона изрядное количество! Настоящий питонист (pythonista) - так мы, программисты на Python, себя называем - обязан хорошо ориентироваться в стандартной библиотеке, ведь это знание позволяет экономить время и силы. В этом уроке мы познакомимся с первой батарейкой - модулем random.

При разработке программ довольно часто возникает необходимость получить некоторое случайно выбранное из некоего множества значение. Случайные значения полезны, когда мы разрабатываем компьютерные игры, генерируем изображения и звук, и даже просто пишем тесты.

Любое значение в компьютере может быть представлено в виде набора чисел, поэтому получение случайных значений всегда предполагает использование Генератора Случайных Чисел, ГСЧ. ГСЧ бывают программными (специализированные программы) и аппаратными (специализированные устройства), но программист обычно работает с некоторой обобщённой "обёрткой" - модулем или пакетом, который скрывает ненужные детали.

Модуль random предоставляет множество функций, полезных в разных ситуациях, но мы пока остановимся на двух:

randint, генерация целого числа в заданном диапазоне,
choice, выбор случайного элемента из заданного набора.

# Генерация случайных чисел
Для того, чтобы сгенерировать случайное число, нам нужно импортировать функцию randint из модуля random:
'''
from random import randint

// Теперь мы можем сгенерировать число от 1 до 100:
random_number = randint(1, 100)

// При вызове randint с такими границами диапазона может "выпасть" и 1 и 100 - обе границы диапазона включены и об этом следует помнить. Когда это может быть важно? Давайте рассмотрим другой пример - выбор случайного символа некоторой строки:

string = 'abcde'
random_index = randint(0, len(string) - 1)
char = string[random_index]

'''
Строка в переменной string имеет длину 5. Но мы помним, что символы строки индексируются с нуля, поэтому если сгенерировать индекс так randint(0, 5), то в какой-то момент мы получим значение 5 и при попытке взять символ по этому индексу мы увидим ошибку IndexError: индекс последнего элемента в строке равен 4! Вот поэтому в коде выше из длины вычитается единица.

# Выбор случайного элемента
Выше мы рассмотрели пример, в котором выбирался случайный символ строки. Эта задача возникает достаточно часто, поэтому в модуле random существует функция choice. С использованием этой функции выбор символа строки будет выглядеть так:
'''

from random import choice

string = 'abcde'
char = choice(string)

'''
При использовании choice не нужно думать о границах генерируемых индексов. И даже о самих индексах думать не нужно - функция сама знает, как правильно и безопасно выбирать элементы! Правда, придётся заботиться о том, чтобы строка, из который мы выбираем символы, не была пустой, иначе мы получим ошибку IndexError: Cannot choose from an empty sequence ("Нельзя просто так взять и выбрать, если выбирать не из чего").

Пока мы можем использовать choice только со строками, ведь это единственный тип, значения которого могут содержать несколько элементов. Но в дальнейшем мы познакомимся и с другими составными типами - и с многими из таких типов функция choice тоже может работать!

# Случайна ли случайность?
Строго говоря, генерируемые числа у компьютера получаются не полностью случайными, поэтому большинство ГСЧ представляют собой генераторы псевдослучайных чисел. И хотя для простоты приставку "псевдо-" часто опускают (как поступили и мы), о ней не стоит забывать. Дело в том, что некоторые алгоритмы требуют максимально случайной генерации чисел. Одна из областей с такими высокими требованиями к качеству случайности — криптография (шифрование). Представьте, что вы сгенерировали случайный пароль, длинный и сложный, а злоумышленник, пользуясь тем, что при определённых условиях можно воспроизвести ту же последовательность случайных чисел, получил тот же пароль! Вот поэтому существует большое количество специализированных ГСЧ, безопасных для использования в шифровании и создание таких генераторов - это важная, сложная и интересная работа.

# Ссылки
Модуль random https://docs.python.org/3.6/library/random.html
ГСЧ https://ru.wikipedia.org/wiki/Генератор_псевдослучайных_чисел
'''

>>>>>> Кортежи <<<<<<<
'''
До этого момента мы встречались только с примитивными типами — строка, число, булев тип. Ещё нам знакомы функции и модули с пакетами (да, в Python модули и пакеты, это тоже значения специальных встроенных типов). Но часто в программировании приходится создавать более сложные, чем числа и строки, значения и манипулировать такими значениями. Именно поэтому во многих языках программирования есть составные типы. Значение составного типа может состоять как из значений примитивных типов, так и из значений других составных типов, таким образом составные типы позволяют описывать сущности произвольной сложности — и шахматные доски, и космические ракеты!

В этом уроке мы познакомимся с самым простым, но очень полезным составным типом — кортежем (в англоязычных текстах оный известен, как tuple).

# Кортежи
Кортеж — это несколько значений, записанных через запятую. Да, всё очень просто! Вот несколько примеров:
'''
rgb_colour = (255, 127, 64)
name_and_age = ('Bob', 42)
three_booleans = (True, False, True)
two_pairs_of_numbers = ((1, 2), (3, 4))

'''
Определять кортежи очень просто, сложности могут возникнуть только с кортежами, содержащими ровно один элемент. Если мы просто укажем значение в скобках, то Python подумает, что мы хотим посчитать арифметическое выражение со скобками:
'''
not_a_tuple = (42)  # 42

// Чтобы сказать пайтону, что мы хотим создать именно кортеж, нужно поставить после элемента кортежа запятую:

tuple = (42,)  # (42,)

'''
Да, форма записи довольно необычная, но вы привыкнете :)

# Возврат нескольких значений из функции
Кортежи очень полезны, когда нам нужно вернуть из функции сразу несколько значений. Так, функция, которая принимает два аргумента-числа и возвращает одновременно результат деления нацело и остаток от деления, будет выглядеть так:
'''

def div_mod(a, b):
    quotient = a // b
    modulo = a % b
    return (quotient, modulo)

div_mod(13, 4)  # (3, 1)

'''
# Получение элементов кортежа по индексу
Выше мы только создавали кортежи. Теперь научимся их разбирать! В простейшем случае достаточно обратиться к элементу кортежа по индексу:
'''

name_and_age = ('Bob', 42)

name_and_age[0]  # 'Bob'
name_and_age[1]  # 42

// Также у кортежа есть длина, которую, как и для строки, можно получить с помощью функции len:

tuple = (42,)  # (42,)
len(tuple)     # 1
pair = (1, 2)  # (1, 2)
len(pair)      # 2

'''
# Деструктуризация
Обращение по индексу, это не самый удобный способ работы с кортежами. Дело в том, что кортежи часто содержат значения разных типов, и помнить, по какому индексу что лежит — очень непросто. Но есть способ лучше! Как мы кортеж собираем, так его можно и разобрать:
'''

name_and_age = ('Bob', 42)

(name, age) = name_and_age
name  # 'Bob'
age   # 42

'''
Именно таким способом принято получать и сразу разбирать значения, которые возвращает функция (если таковая возвращает несколько значений, конечно):
'''
(quotient, modulo) = div_mod(13, 4)

// Соответственно кортеж из одного элемента нужно разбирать так:
(a,) = (42,)
a  # 42

'''
Если же после имени переменной не поставить запятую, то синтаксической ошибки не будет, но в переменную a кортеж запишется целиком, т.е. ничего не распакуется! Всегда помните о запятых!

# Кортежи, множественное присваивание и обмен значениями
Благодаря тому, что кортежи легко собирать и разбирать, в Python удобно делать такие вещи, как множественное присваивание. Смотрите:
'''
(a, b, c) = (1, 2, 3)
a  # 1
b  # 2
c  # 3

// Используя множественное присваивание, можно провернуть интересный трюк: обмен значениями между двумя переменными. Вот код:

a = 100
b = 'foo'

(a, b) = (b, a)
a  # 'foo'
b  # 100

'''
Cтрочку (a, b) = (b, a) нужно понимать как "присвоить в а и b значения из кортежа, состоящего из значений переменных b и a".

# Ссылки
Кортеж https://ru.wikipedia.org/wiki/Кортеж_(информатика)
'''


>>>>>> История развития языка Python <<<<<<

'''
Итак, мы учимся языку Python. Для начала стоит определиться с названием. Правильно говорить "Пайтон" с ударением на первом слоге — язык назван в честь известного комедийного шоу "Летающий Цирк Монти Пайтона", т.е. Пайтон — это фамилия, а фамилию человека принято произносить так, как это делает носитель фамилии!

Ещё пара сухих фактов:

Первый релиз интерпретатора языка Python был представлен в далёком 1991г,
Автор языка — Гвидо ван Россум.
Сам по себе язык — это не то же самое, что его интерпретаторы. Но основная реализация языка — CPython — настолько распространена, что почти всегда, когда мы слышим "Python", подразумевается именно она. Наши курсы тоже будут касаться именно CPython, это стоит иметь в виду!

# Самое начало
Python появился, чтобы заменить собой язык ABC, в работе над которым принимал участие будущий автор пайтона Гвидо ван Россум. Представленный в 1991 году Python версии 0.9.0 вобрал в себя многие идеи из существовавших на тот момент языков: например, взяв систему модулей из языка Modula-3. Элементы функционального программирования (их мы будем изучать в следующих курсах!) — функции map, filter, reduce — появились в языке тоже довольно рано, в версии 1.0.

Стоит отметить, что Пайтон изначально позиционировался как "язык для каждого", поэтому большой упор делался на читаемость кода и лаконичность синтаксиса. В версии 2.0 появились знаменитые "списковые включения" ("list comprehensions"), позаимствованные из языков SETL и Haskell. В этой же версии сборщик мусора (механизм автоматического управления памятью) научился работать с циклическими структурами. С ними мы также познакомимся в последующих курсах.

# Py2 vs Py3
Python, как язык, непрерывно развивается с самого начала времени своего существования. На данный момент в основном используются версии языка, начинающиеся с "3".

Первый релиз "третьего пайтона" (python3, py3) вышел ещё в 2008 году, но переход на это семейство версий со "второго пайтона" (python2, py2) происходил (кое-где всё ещё происходит!) "со скрипом". Дело в том, что py3 не полностью обратно совместим с кодом, написанным для py2, т.е. мы не можем просто заменить интерпретатор — нам потребуется внести определённые изменения в код! На такой шаг можно пойти, если наш проект — живой. Но с проектами, находящимися в состоянии "только поддержка" (такие проекты ещё называют legacy), такой фокус не пройдёт — обычно просто некому заниматься адаптацией. А ведь legacy-проекты — это не всегда лишь конечные приложения, в такой ситуации могут оказаться и библиотеки. Именно из-за невозможности отказаться от нужных, но существующих в состоянии legacy, библиотек многие проекты долго оставались несовместимыми с py3.

К счастью, сейчас большая часть библиотек, достаточно популярных и полезных в повседневной жизни разработчика, успешно переведена на py3, и новые проекты нужно делать именно на какой-то из версий этого семейства (сейчас рекомендуемая версия — это Python 3.7.x). Более того, py2 скоро перестанет быть безопасным для широкого использования! Дело в том, что техническая поддержка py2 — т.е. устранение уязвимостей и критических ошибок — с 2020г перестанет осуществляться. А мы ведь не хотим подвергать угрозе свои детища!

# Системный Python
Работая с Python, стоит иметь в виду, что Python распространён не только в виде языка, на котором пишутся конечные проекты: этот язык часто используется для автоматизации различных задач, скажем, по системному администрированию (Ansible — один из примеров написанного на Python ПО, используемого при администрировании). Поэтому python часто уже присутствует в установленных операционных системах.

Особенно велика вероятность обнаружить в системе установленный Python, когда речь идёт об ОС семейства Linux — а именно, какая-то из версий Linux будет скорее всего установлена на машину, на которой вы захотите запустить сервер своего web-приложения или многопользовательской игры (да, такие тоже пишут на Python!). Тут-то и кроется проблема: установленный вместе с операционной системой Python может быть тем самым "вторым пайтоном" — да, такое, увы, пока встречается. И заменить его будет нельзя, ведь замена может привести к выходу из строя всей ОС.

Но не пугайтесь, в курсе про настройку окружения вы узнаете, как использовать в проекте нужную версию Python и не бояться сломать что-то другое!
'''

'''*@@@
src/solution.py
Реализуйте функцию sort_pair, которая принимает пару (кортеж из двух значений) и возвращает пару, значения которой расположенны строго в порядке возрастания.

Пример:
'''

# обратите внимание на скобки у аргумента функции
sort_pair((5, 1)) == (1, 5)
sort_pair((2, 2)) == (2, 2)
sort_pair((7, 8)) == (7, 8)


// FILE /app/src/solution.py:
def sort_pair(pair):
    (first, second) = pair
    if first > second:
        return (second, first)
    return pair


'''*@@@
src/package/__init__.py
Дан пакет следующей структуры:

$ tree package
package/
├── __init__.py
├── functions.py
└── names.py
Добавьте в __init__.py блок импортов таким образом, чтобы можно было импортировать package и получить доступ

к константе NAME из package.names
к функции greet из package.functions
Если задание будет выполнено успешно, то следующий код должен будет работать:
'''

from package import greet, NAME

greet(NAME)  # 'Hello, Bob!'


// FILE: /app/src/__init__.py:
from package.names import NAME
from package.functions import greet


// FILE: /app/src/functions.py:
def greet(name):
    return 'Hello, {}!'.format(name)

// FILE: /app/src/names.py:
NAME = 'Bob'




'>>>>>> HTTP <<<<<<

'''
Популярный вопрос на собеседовании веб-разработчиков часто звучит так: «Что происходит после того, как в браузер ввели адрес сайта?». Подробный ответ на этот вопрос можно найти здесь. Главное, что хочет услышать собеседующий — ваш уровень понимания HTTP (Hyper-Text Transferring Protocol).

Для начала пару слов о том, что такое протокол. Протокол — это набор соглашений, правил, по которым разные программы могут обмениваться информацией. HTTP — это набор правил, который известен и вашему компьютеру и физически отдалённому компьютеру. С помощью него общаются браузер и веб-сервер.

Веб-сервер — программа, установленная на сервере и обслуживающая входящие соединения, например, от браузеров. В рамках такого соединения от браузера передаётся информация о том, какую страницу и какого сайта мы хотим загрузить, а веб-сервер, в свою очередь, возвращает браузеру содержимое страницы этого сайта.

Пример http-сессии (запрос-ответ) через программу curl:
'''
$ curl --head -v code-basics.ru
* Rebuilt URL to: code-basics.ru/
*   Trying 35.157.19.194...
* TCP_NODELAY set
* Connected to code-basics.ru (35.157.19.194) port 80 (#0)
> GET / HTTP/1.1
> Host: code-basics.ru
> User-Agent: curl/7.54.0
> Accept: *'''
>
< HTTP/1.1 200 OK
< Date: Sun, 07 Jan 2018 14:19:00 GMT
< Content-Type: text/html; charset=utf-8
< Content-Length: 5123
< Connection: keep-alive
< server: Cowboy
< cache-control: max-age=0, private, must-revalidate
<
* Connection #0 to host code-basics.ru left intact

'''
http нужно не просто знать, но и уметь делать сырые http-запросы — не косвенно через браузер, а самостоятельно, эмулируя поведение браузера. Для этой задачи используют программу telnet.

# Для чего требуется знание http?
Работа с формами, загрузка файлов, перенаправления.
Аутентификация целиком зависит от http.
Извлечение информации о запросе (например, определение браузера, из которого был выполнен запрос).
Увеличение производительности. Кеширование.
Обеспечение безопасности. http — текстовый протокол без шифрования, он не безопасен.

# https
Кроме http, в сети всё большее распространение получает https. Каждый пользователь сети должен знать, что нельзя выполнять действия, связанные с любыми секретными данными (например кредитками), на страницах, работающих по протоколу http. В таком случае любой человек, имеющий доступ к оборудованию, которое лежит между вами и сервером, обслуживающим сайт, сможет прочитать эти данные. Обратите внимание, что на популярных сайтах страницы оплаты всегда отдаются по https. В свою очередь, умение работать с https сразу добавляет новые понятия:

Шифрование, асимметричное шифрование
Сертификаты
Цифровая подпись

# TCP/IP
Но одним http обойтись не получится. Дело в том, что http существует не сам по себе, а поверх стека протоколов TCP/IP. Базовое знание сетей важно по следующим причинам:

Безопасность. Очень легко совершить ошибку и быть взломанным.
Отладка. Немалая часть вопросов запуска и конфигурирования сайтов и их частей (в том числе базы данных) связана с сетевыми сокетами. Не зная сети вы будете останавливаться на любой простейшей проблеме без понимания, что вообще делать.

# DNS
Ещё один столп веба — DNS, служба доменных имён. Каждый раз, когда мы вбиваем адрес в браузер, он выполняет DNS запросы к соответствующим серверам для выяснения того, какой ip-адрес принадлежит сайту. Дело в том, что соединение с сервером идёт по tcp/ip, а не по http. http начинает работать уже после того, как было установлено tcp соединение. Знание DNS важно по следующим причинам:

Зная DNS вы сможете не только купить домен, но и привязать его к вашему серверу
Почта для домена, верификация вашего проекта различными сервисами — всё это работает через возможности DNS
Опять же, отладка. Нередко проблемы загрузки связаны с DNS.
'''



############## Python: Настройка окружения ##############

'''
Мы поддерживаем репозиторий python-package https://github.com/hexlet-boilerplates/python-package — так называемую заготовку, содержащую базовую структуру нового проекта на Python. Вы всегда можете подглядывать в него и делать по аналогии.


#@ Установка Python

Ubuntu
$ sudo apt update
$ sudo apt install python3

macOS
# https://brew.sh/index_ru.html
$ brew install python

Наберите в терминале python3 --version. Вывод должен быть примерно такой:
Python 3.6.8



#@ pyenv

Совсем другой способ установки Python — утилита pyenv https://github.com/pyenv/pyenv (для пользователей Windows нужна особая версия утилиты - pyenv-win). Кроме установки любых версий Python, эта утилита позволяет удобно переключаться между версиями. Такое может быть нужно когда вы одновременно работаете над несколькими проектами, требующими разные версии Python.


#@ REPL

Python поставляется со встроенным REPL. REPL – это программа, которая работает как командная оболочка (программу REPL ещё называют интерактивным интерпретатором Python), предназначенная для ввода и выполнения кода на языке Python. Акроним REPL расшифровывается так:

Read — прочитать ввод от пользователя,
Eval — выполнить введённый код,
Print — распечатать на экран результат,
Loop — снова войти в режим ожидания.

Для запуска REPL достаточно набрать:
$ python3

Теперь можно выполнять код на Python и сразу же смотреть на результат его выполнения. Наберите любой корректный код на Python, например такой:

30 + 12

REPL выводит результат выполнения операции прямо на экран и снова входит в режим ожидания ввода команд. Для выхода из REPL нужно вместо ввода кода нажать Ctrl + D.

#@ Встроенная документация

Язык Python прямо на уровне синтаксиса поддерживает дополнение кода документацией. Основным средством документирования являются так называемые "строки документации" ("docstrings"). Документированная функция выглядит так:
'''
def add(x, y):
    """Add one argument to another."""
    return x + y

'''
Из таких docstrings генерируется online-документация. А ещё эта документация доступна для просмотра прямо в REPL! Для просмотра документации служит функция help. Давайте объявим функцию add в REPL, попробуем её вызвать, а затем посмотрим описание нашей функции и нескольких встроенных.
'''



# >>>>>> Подробнее о Python <<<<<<
'''
Язык программирования

С одной стороны, языком программирования называют правила (синтаксические и семантические), по которым записывается и работает исходный код. В отличие от естественных языков, эти правила достаточно строги. Любая мельчайшая ошибка и код либо не запустится, либо запустится, но не заработает, как ожидается. Например, в Python нельзя написать my name = 5 (с пробелом в имени переменной). Эти правила существуют не только в книгах, но и в головах конкретных программистов и разработчиков языка. Часто весь свод правил, называемый спецификацией, существует в виде отдельного специального документа.

С другой стороны, языком программирования называют программу, которая непосредственно запускает (или компилирует) наш код. В предыдущем уроке мы как раз установили такую. Обычно её называют средой выполнения, иногда "рантаймом" ("runtime"), если речь идёт про интерпретацию. Среда выполнения — конкретное воплощение спецификации, по-другому называемое реализацией (или implementation). Реализаций конкретного языка может существовать несколько, но часто существует так называемая эталонная реализация (или reference implementation), на которую могут равняться другие. Различные реализации могут разрабатываться разными людьми и компаниями.

У Python нет выделенной спецификации, но есть эталонная реализация, называемая CPython (интерпретатор Python, реализованный на языке C). Если вы слышите, что кто-то говорит Python, то скорее всего имеется в виду именно эталонная реализация. Прочие же реализации обычно имеют свои названия. Например, реализация языка, предназначенная для запуска программ на платформе .NET, называется IronPython https://ironpython.net/.
'''

#@ Python

'''
Python — интерпретируемый язык программирования с сильной динамической типизацией. Разберём эти слова по отдельности.
'''

#@ Интерпретируемый

'''
У Python отсутствует стадия компиляции в машинный код, которая присутствует, скажем, у языков C, Rust, Go. Программа исполняется интерпретатором шаг за шагом, а не запускается напрямую на процессоре компьютера. Поэтому для запуска программы на Python всегда нужна среда исполнения (интерпретатор) — только она может выполнять Python-программы.

Строго говоря, у Python есть фаза компиляции, во время которой код из текста преобразуется в специальное представление, называемое "байткод" ("bytecode"), а затем уже этот байткод передаётся в интерпретатор. Но внешне Python ведёт себя именно как интерпретируемый язык программирования: интерпретатор при запуске вашей программы загружает из файлов её (программы) исходный код, преобразует для удобства в байткод (при этом проверяются ошибки синтаксиса), а дальше начинает исполнять по шагам.
'''


#@ Динамическая типизация

'''
В динамически типизированных языках проверка типов, доступности функций и переменных производится интерпретатором во время выполнения кода. Поэтому, если мы случайно ошиблись и, например, вызвали несуществующую функцию, то ошибка всплывёт только во время вызова этой функции! В статически же типизированных языках подобные ошибки отслеживаются на этапе анализа исходного текста без запуска кода на выполнение (слово "статический" как раз означает, что программа не выполняется). Обычно статическими проверками занимаются компиляторы, но существуют и выделенные инструменты статической проверки кода, так называемые статические анализаторы кода. Для некоторых языков с динамической типизацией такие анализаторы тоже существуют, но отслеживают значительно меньшее число ошибок.
'''

#@ Сильная типизация

'''
Сильная типизация означает то, что Python старается не приводить типы (преобразовывать значения одних типов в значения других) автоматически. Это означает, что Python не даст сложить число со строкой: при попытке сделать что-то подобное мы получим ошибку. Далеко не все языки с динамической типизацией столь педантичны в силу различных причин. Но Python в этом вопросе принципиален и требует, чтобы любые преобразования типов были явными (т.е. программист использовал в каждом конкретном случае соответствующие функции-преобразователи).
'''


# >>>>>> Пакеты и индексы <<<<<<

'''
В какой-то момент разработчик понимает, что код, который он написал, может быть полезен другим. Это может быть библиотека полезных функций или готовая программа, но в любом случае автор оной обычно хочет, чтобы его творение было удобно и просто использовать. Так вот, питонисты делятся между собой кодом с помощью… пакетов!
'''

#@ Опять пакеты

'''
В рамках курса по основам Python уже упоминались пакеты (packages). Тогда пакеты описывались, как наборы модулей и вложенных пакетов. Но это не единственное значение слова "пакет" в Python-мире.

В более широком смысле пакет — это некая единица обмена кодом между разработчиками. Python-пакет содержит и исходный код (как раз в виде пакета в узком смысле, поэтому и название общее), и так называемые метаданные — дополнительную информацию о пакете. Метаданные описывают

предназначение пакета
версию пакета
совместимость с разными версиями Python
лицензию (software license), под которой распространяется пакет
список и версии зависимостей пакета (об этом поговорим позже)
и многое другое.
'''

#@ Индекс

'''
Предположим, что мы имеем готовый пакет (а мы в итоге обязательно научимся их создавать), но как им поделиться с миром? Как правило, собранный пакет представляет собой обычный файл и в принципе его можно просто передать другому человеку — это даже сработает! А если вдруг окажется, что наш пакет требует каких-то других пакетов для своей работы? Вот тут-то и начнутся сложности — нужно будет приложить к нашему пакету дополнительные пакеты, которые могут потребовать ещё больше пакетов и т.д. и т.п.

Для упрощения жизни как авторов пакетов, так и пользователей оных существуют так называемые репозитории пакетов. Только в Python их принято называть индексами. Помимо предоставления пакетов, индексы также могут обладать интерфейсом для поиска пакетов, знакомства с их описанием — проще говоря, предоставляют интерфейс пользователя (обычно в виде web-сайта).

Самый популярный индекс пакетов, это PyPI, Python Package Index. Чаще всего вы будете работать именно с ним. Но есть и другие индексы и большинство инструментов работы с пакетами могут работать с разными индексами. Отдельные индексы, к примеру, используются многими компаниями для размещения пакетов, которые не являются открытыми (open source).

Ещё один полезный индекс — Test PyPI. Это специальный индекс пакетов, который принято использовать для обучения работы с системой пакетирования Python. Ведь не очень красиво выставлять на всеобщее обозрение сотни и даже тысячи учебных пакетов: они будут попадаться в поиске, "занимать" имена, которые могли бы иметь действительно полезные пакеты, другими словами — "замусоривать" основной индекс. Тестовый индекс работает точно так же, как основной PyPI – позволяет пакеты выкладывать и скачивать – но периодически удаляет все данные.
'''

#@ Индексы vs GitHub, BitBucket и прочие хранилища кода
'''
В наши дни некоторые репозитории пакетов не хранят пакеты своими силами, а берут на себя только индексацию и управление метаданными пакетов, код же предлагается хранить на GitHub, BitBucket, GitLab, другими словами — в хранилищах исходного кода.

Такой подход в целом работает для интерпретируемых языков, ведь для того, чтобы использовать код пакета, нужно всё равно иметь доступ к исходному коду. Но хранение кода на сторонних по отношению к источнику метаданных (индексу, в случае Python) обладает рядом недостатков.

Во-первых, опубликованным кодом владеет только автор кода. Автор может даже удалить свой репозиторий, а информация о пакете в индексе сохранится. И те, кто начал использовать "сломанный" пакет, столкнутся с невозможностью сборки своих проектов.

Во-вторых, ни GitHub, ни другие хранилища Git-репозиториев не могут гарантировать неизменность данных в репозитории при использовании одних только тегов и веток — а именно такой способ привязки состояния кода к информации в индексе и используется чаще всего — ведь любой обладатель доступа к репозиторию может "переписать историю". И даже если привязывать версии пакетов в индексе к hash-суммам коммитов в Git, то изменение в истории приведёт к первой проблеме — версия пакета будет ссылаться на несуществующий источник кода (при переписывании истории hash-суммы коммитов тоже поменяются).

Обе озвученные причины приводят к тому, что ломается важное свойство системы пакетирования — воспроизводимость сборки. Воспроизводимость здесь означает, что любой проект, содержащий точное описание своих зависимостей, "соберётся" (в случае Python — запустится) в любой момент времени, даже если проект использует очень старые версии пакетов и интерпретатора!

Централизованный индекс, самостоятельно хранящий все версии всех пакетов в неизменяемом виде, даёт значительно больше гарантий, что мы сможем собрать наш старый проект, когда бы мы этого не захотели.

# Дополнительные материалы
PyPI https://pypi.org/
Test PyPI https://test.pypi.org/
'''


# >>>>>> distutils, setuptools, pip <<<<<<
'''
На прошлом уроке мы познакомились с пакетами и индексами, давайте же узнаем, как устанавливать пакеты из индекса! Для установки, обновления и удаления пакетов часто применяются так называемые пакетные менеджеры (или менеджеры пакетов). Один такой мы рассмотрим, но сначала немного поговорим о фундаменте системы пакетирования Python.
'''

#@ distutils и setuptools

'''
В поставку Python входит distutils, пакет, отвечающий за создание дистрибутивов — архивов кода, которые могут быть распакованы в целевом окружении и установлены так, чтобы интерпретатор Python "увидел" распакованный код. При создании пакета программист создаёт в корневой директории будущего пакета файл setup.py в котором импортирует из модуля distutils функцию setup и вызывает её. Таким образом каждый пакет содержит в себе программу для управления собой!

Подробнее о том, как работает distutils, можно почитать в официальной документации к пакету https://docs.python.org/3/library/distutils.html, а мы сразу двинемся дальше. Дело в том, что пакет distutils появился довольно давно и сейчас сам по себе не очень удобен в использовании. Гораздо чаще используется надстройка над distutils, пакет setuptools.

Пакеты, собранные с помощью setuptools, уже умеют предоставлять metadata: описание, версию, и самое главное — собственные зависимости! Пакеты, которые не зависят ни от чего, кроме самого Python, настолько редки, что без setuptools — можно сказать, "жизни нет". Про этот пакет стоит знать и со временем нужно будет научиться его использовать (опять же, с помощью документации), но в рамках этого курса мы будем рассматривать более простой инструмент для создания пакетов и загрузки их в индекс — poetry, с которым мы познакомимся попозже.

После того, как пакет создан и загружен в индекс, его можно скачать, распаковать во временную директорию, оттуда запустить python3 setup.py install и пакет установится. Но это слишком утомительный и непростой путь, есть способ лучше!
'''

#@ pip

'''
Каким бы способом пакет не был создан и загружен в индекс, его нужно скачивать и устанавливать, а по необходимости — и со всеми зависимостями. Сейчас этим в основном занимается специальная программа pip — The Python Package Installer.

pip — большая и сложная программа. Обо всех возможностях вы, как всегда, сможете почитать в документации https://pip.pypa.io/. Мы же рассмотрим только самую важную функцию pip — установку пакетов. В следующем уроке мы установим сам pip и с помощью него установим в окружение первый пакет!

# Дополнительные материалы
distutils - Building and installing Python modules https://docs.python.org/3/library/distutils.html
setuptools - Collection of enhancements to the Python distutils https://setuptools.readthedocs.io/
pip - The Python Package Installer https://pip.pypa.io/
'''


# >>>>>> Установка pip <<<<<<

#@ Установка pip
'''
Если вы используете macOS или Windows и устанавливали Python согласно нашим рекомендациям, то pip будет установлен вместе с интерпретатором. На Ubuntu его нужно поставить отдельно:

$ sudo apt update
$ sudo apt install python3-pip
'''

#@ Запуск pip
'''
pip можно запускать непосредственно командой pip. Но лучше воспользоваться более длинной командой, которая гарантировано вызовет самую свежую установленную версию pip для нужной версии Python — в системе уже может быть установлен Py2 с соответствующей версией pip, как правило, довольно старой.

Итак, вызываем pip:

$ python3 -m pip --version

При показе своей версии pip также сообщает, куда установлен он сам и на какой версии Python он был запущен.

Обратите внимание на структуру команды, которую мы вызывали:

$ python3 -m pip --version

Эта команда означает "python3, запусти модуль (-m) с именем pip как программу с параметром --version". Если вы в дальнейшем увидите в документации к pip команды, вроде pip help, то смело вызывайте python -m pip help — результат будет нужный!
'''

#@ Установка первого пакета

'''
Установим же первый пакет! Пусть это будет пакет cowsay https://pypi.org/project/cowsay, но устанавливать мы его будем сразу в пользовательское окружение. Причин для установки туда есть несколько:

мы не помешаем своими пакетами другим пользователям системы,
нам не потребуются права администратора (у пользователя их может и не быть),
мы не поломаем саму операционную систему случайной установкой более свежего пакета, чем тот, который требуется системе для нормальной работы (особенно это важно в Linux, где многие системные задачи решаются с помощью Python).
Итак, установка cowsay:

$ python3 -m pip install --user cowsay

Во-первых, мы видим, что пакет установился и стал доступен интерпретатору. Во-вторых, пакет — забавный :)

Флаг –-user команды pip install сообщает pip, что мы хотим установить пакет в глобальное окружение текущего пользователя. Если этот флаг не указать, то pip установит пакет в общесистемное окружение. Старайтесь не делать так!
'''

#@ pip, точки входа и PATH

'''
Установленный пакет cowsay, как мы видели выше, может быть использован из кода. Но этот пакет имеет ещё и так называемую точку входа (или entry point).

Точки входа, это готовые к исполнению программы, содержащиеся в пакете. Если у пакета есть таковые, то pip создаст для каждой специальный исполняемый скрипт, который позволит удобно запускать программу из командной оболочки. Но нужно помнить, что путь до директории, в которую pip помещает такие скрипты (на Linux это ~/.local/bin) нужно добавить в PATH! Если путь прописан правильно, то скрипт для cowsay должен работать так:

$ cowsay hi
$ exit

Точка входа, это всегда Python-модуль, пригодный для запуска в роли программы (такие программы называют ещё исполняемыми файлами, позже мы рассмотрим, как такие делать). Создаваемые pip'ом скрипты внутри вызывают python3 -m имя_модуля, поэтому установленный нами cowsay можно запускать точно также:

$ python3 -m cowsay python
'''

#@ Всегда свежий pip!
'''
Как вы могли уже догадаться, сам pip, это тоже точка входа одноимённого пакета pip, поэтому мы его запускаем командой python3 -m pip. А ещё pip может устанавливать и, что более важно, обновлять! Вы можете установить свежий pip в пользовательское окружение (именно туда, чтобы не сломать системный pip) с помощью такой команды:

$ python3 -m pip install --user --upgrade pip

Флаг --upgrade позволит обновить уже установленный пакет, если в индексе найдётся более новая версия.

# Дополнительные материалы
pip - The Python Package Installer https://pip.pypa.io/
'''



# >>>>>> pip и альтернативные источники пакетов <<<<<<

'''
На прошлом уроке мы установили пакет cowsay. Если не уточнить иное специально, pip устанавливает пакеты из основного индекса — PyPI. Оттуда был взят и пакет cowsay.

В большинстве случаев PyPI — это именно тот источник пакетов, который нам нужен. Но бывают случаи, когда пакет находится в альтернативном индексе — например, внутрикорпоративном — или же вообще ещё не опубликован ни в одном индексе, а просто загружен на GitHub. Pip умеет работать и с альтернативными индексами и с репозиториями, содержащими исходный код пакетов. Рассмотрим оба варианта.
'''

#@ Альтернативные индексы пакетов

'''
Если вызывать команду pip install с опцией --index-url <url>, то pip будет искать пакет и все его зависимости в индексе по указанному url. Давайте попробуем установить пакет из специального тренировочного индекса Test PyPI http://test.pypi.org/:

$ python3 -m pip install --user --index-url https://test.pypi.org/simple dogesay

$ dogesay foo bar baz

Заметьте, что url индекса указан в виде что-то-там/simple — именно так по соглашению должны именоваться индексы.

Test PyPI содержит плюс-минус все пакеты, которые есть в основном PyPI, но обычно держателям локальных индексов не хочется держать у себя копии всех версий всех пакетов — хочется хранить только свои пакеты, а все внешние зависимости получать из другого индекса (обычно это уже общий PyPI). У pip и для такого случая есть опция! Всего-то и нужно в дополнение к --index-url указать --extra-index-url <url>. В такой конфигурации pip ищет каждый пакет в первом индексе, а если не найдёт, то обращается ко второму, дополнительному индексу. Команда целиком может выглядеть так:

$ python3 -m pip install --user --index-url https://test.pypi.org/simple --extra-index-url https://pypi.org/simple dogesay
'''

#@ Установка пакетов из репозиториев на GitHub

'''
Иногда пакет не хочется выкладывать на PyPI, скажем, по причине того, что пакет ещё совсем "сырой", но при этом нужно проверить, как пакет работает и устанавливается ли вообще. В подобных случаях пакеты устанавливают прямо из git-репозиториев. Давайте установим с помощью pip наш учебный hexlet-boilerplates/python-package https://github.com/hexlet-boilerplates/python-package:

$ python3 -m pip install --user git+https://github.com/hexlet-boilerplates/python-package.git

Здесь вместо имени пакета указывается тот же url, который вы использовали бы при клонировании репозитория, но дополненный приставкой git+. Эта приставка подсказывает pip, что по url расположен Git-репозиторий — не обязательно размещённый на GitHub.

Во время установки пакета, pip вызывает git clone для клонирования репозитория во временную папку. Если репозиторий закрытый, то у вас будут запрошены имя пользователя и пароль для доступа к репозиторию — это работает и с приватными репозиториями GitHub!

Управлять установкой пакетов из систем контроля версий (да, систем — pip поддерживает не только Git!) можно очень гибко, например, указывать ветки, теги или хэши коммитов, по которым расположена желаемая версия пакета. Подробнее можно почитать тут https://pip.pypa.io/en/stable/reference/pip_install/#vcs-support.

Мы рассмотрели далеко не все виды источников пакетов, да и саму команду pip install рассмотрели очень поверхностно. По возможности рекомендуем изучить эту и прочие команды pip самостоятельно, ведь pip — один из ключевых инструментов разработчика на Python!

# Дополнительные материалы
pip - The Python Package Installer https://pip.pypa.io/
Test PyPI https://test.pypi.org/
Python package example (boilerplate) https://github.com/hexlet-boilerplates/python-package
'''



# >>>>>> Виртуальные окружения <<<<<<

'''
Как уже говорилось ранее, pip устанавливает пакеты в одно из двух окружений — в общесистемное или пользовательское. Интерпретатор Python при импорте модуля или пакета ищет оный сначала в пользовательском окружении, затем в общесистемном. Такая последовательность позволяет пользователю иметь нужные именно ему версии библиотек и Python программ. Но даже двух окружений недостаточно, когда программист начинает работать с несколькими проектами: разные проекты могут иметь разные наборы зависимостей. Ещё более тяжелый случай: разные проекты могут зависеть от общей библиотеки, но требовать разные её версии — конфликт версий.

Очевидно, что как минимум разработчику на Python нужен какой-то механизм, позволяющий содержать разные проекты в изолированных "песочницах". Такой механизм существует и называется виртуальные окружения.
'''

#@ Устройство виртуальных окружений

'''
Каждое виртуальное окружение представляет собой директорию, содержимое которой структурно напоминает общесистемное окружение — поддиректории соответственно названы и наполнены. Давайте рассмотрим пример:

$ tree env
env
├── bin
│   ├── activate
│   …
│   ├── pip
│   …
│   └── python3 -> …/python3
├── lib
│   └── python3.6
│       └── site-packages
│           ├── pip
│           │   ├── …
│           …
│           └── setuptools-40.6.2.dist-info
│               ├── …
…


В директории виртуального окружения находится директория bin/ внутри которой находится копия (или символическая ссылка на оригинал) интерпретатора под именем python3, а рядом с ней находится копия исполняемого файла pip. В соседней директории по пути lib/python3.6/site-packages находятся библиотеки, уже установленные в окружение: только что созданное окружение как правило имеет установленный пакет pip (а исполняемый файл bin/pip — его точка входа), а также пакет setuptools — эти два пакета составляют "необходимый минимум" для разработки проекта на Python.

При работе в окружении нужно запускать не системные Python и pip, а исполняемые файлы из папки bin. Дело в том, что интерпретатор Python, когда находится в окружении, знает, что по относительному (к директории bin) пути ../lib/python3.6 находятся все доступные пакеты. И копия pip из директории bin/ устанавливает пакеты в это же окружение, не затрагивая систему. Получается та самая желанная изоляция!
'''

#@ Создание виртуального окружения

'''
Конечно же, вручную создавать всю описанную иерархию директорий и файлов не нужно — для этого есть специальный модуль venv.

В macOS и Windows этот модуль, как и pip, входит в поставку Python. На Ubuntu же его нужно установить отдельно командой

$ sudo apt install python3-venv
Проверим, что модуль установлен и пригоден к использованию:

$ python3 -m venv --help

Создаётся окружение командой python3 -m venv имя_окружения. Давайте создадим одно и установим в это окружение пакет cowsay:

/tmp$ python3 -m venv first_venv
/tmp$ first_venv/bin/pip install cowsay
/tmp$ first_venv/bin/cowsay hello
/tmp$ first_venv/bin/pyth
/tmp$ first_venv/bin/python
>>> import cowsay
>>> cowsay.tux

Вы можете видеть, что пакет устанавливается вместе с точкой входа, которую можно вызвать командой first_venv/bin/cowsay, а также сам пакет становится доступен интерпретатору, но только тому, что запущен из окружения.

В принципе в таком виде виртуальное окружение уже можно использовать полноценно. Но вводить команды с префиксом first_env/bin/ не очень-то хочется, и есть способ упростить вызов команд, доступных в окружении — активация.
'''

#@ Активация окружения

'''
При создании окружения в поддиректорию bin помещается сценарий оболочки, который на macOS и Ubuntu называется activate, а на Windows — activate.bat. Этот сценарий нужно выполнить:

> на macOS и Ubuntu вызвать команду
$ source first_venv/bin/activate

На Ubuntu активация выглядит следующим образом:

/tmp$ source first_venv/bin/activate
(first_venv) /tmp$ cowsay hello
>>> import cowsay
>>> cowsay.tux('imported')

Вы можете заметить, что после активации отпала необходимость указывать путь до вызываемого исполняемого файла — cowsay и python в аскинеме вызываются без префикса, но это всё те же команды из окружения!

Ещё вы могли заметить, что приглашение оболочки изменилось: в нём стало отображаться имя окружения. Этот трюк работает на macOS и Ubuntu и позволяет всегда видеть, что мы находимся в виртуальном окружении.

Деактивация же окружения делается командой deactivate, которая становится доступна после активации.

Активирование и деактивация окружения влияют только на текущую сессию (заметны только в этом конкретном терминале). Что позволяет иметь несколько окружений и активировать их одновременно в разных окнах терминала.
'''

#@ Итого

'''
Виртуальные окружения — мощный и удобный инструмент изоляции программ друг от друга и от системы. Изоляция позволяет использовать даже разные версии Python в разных окружениях — при работе над проектами разного "возраста" такое часто бывает жизненно необходимо! Поэтому мы, как обычно, рекомендуем добавить виртуальные окружения в список тем для более глубокого изучения в дальнейшем.
'''

#@ Ссылки

'''
https://docs.python.org/3/library/venv.html https://docs.python.org/3/library/venv.html официальная документация по модулю venv.

https://pipxproject.github.io/pipx/ установщик Python-программ, размещающий каждую программу в её собственном виртуальном окружении, но скрывающий от конечного пользователя такие "излишние тонкости": пользователь получает сразу доступную оболочке команду — отличный способ устанавливать для постоянного использования штуки, вроде cowsay и dogesay.
'''


# >>>>>> Cкрипты <<<<<<

'''
Любая программа должна быть когда-нибудь запущена, иначе зачем её вообще писать? В интерпретируемых языках от написания кода до запуска — всего один шаг. Ничего не нужно компилировать в машинный код, всю работу делает интерпретатор, которому достаточно подать на вход скрипт (англ. script) — так часто называют программы на интерпретируемых языках, представляющие из себя простые последовательности команд, которые компьютеру нужно выполнить. Часто языки, которые максимально упрощают написание скриптов (как говорят, "скриптование") и их запуск, называют "скриптовыми языками" или же "языками для написания сценариев" (слово "script" на русский переводится как "сценарий").
'''

#@ Скрипты на Python

'''
Python отлично подходит на роль скриптового языка: последовательность команд в простых сценариях не нужно никак оформлять и запускать скрипты максимально просто — мы просто пишем команды одну за другой в файл:
'''

# file <script.py>
print('Hello, world!')
print('This is a python-script!')

'''
а затем просто вызываем интерпретатор с полученным файлом на входе:
$ python3 script.py
Hello, world!
This is a python-script!

Эта простота использования вместе с большим количеством полезных модулей и функций, входящих в поставку Python, делают последний хорошим инструментом для автоматизации различных задач, которые не хочется выполнять вручную при работе на компьютере. К тому же написание скриптов — отличная отправная точка для тех, кто только начинает знакомиться с программированием!
'''

#@ Скрипты и shebang

'''
В unix-подобных операционных системах (macOS, Linux, BSD etc) командные оболочки умеют запускать скрипты на любых языках, в т.ч. и на Python, если эти скрипты сообщают оболочке, какой интерпретатор нужно вызывать для выполнения сценария. Интерпретатор указывается специальной строкой в самой первой строчке файла скрипта, которая называется shebang, от названий первых двух символов такой строчки: # называется "sharp", а ! - "bang!".

Типичный shebang выглядит так:

#!/usr/bin/python3

где после символов #! идёт путь до интерпретатора. Командная оболочка при запуске скрипта, содержащего shebang, читает первую строку и пробует запустить указанный интерпретатор. Если скрипту с указанным shebang дать права на исполнение, то интерпретатор в командной строке можно будет не указывать:

$ cat script.py
#!/usr/bin/python3
print('Hello!')

$ chmod +x script.py

$ ./script.py
Hello!
'''

#@ Shebang и разные версии Python

'''
shebang — штука довольно простая, когда интерпретатор в системе ровно один. Но мы с вами знаем, что версий Python в системе может быть установлено несколько. Более того, в виртуальном окружении — а в работе вы практически всегда будете их использовать — путь к интерпретатору будет отличаться от /usr/bin и будет разным в разных окружениях! Как же сделать так, чтобы скрипт запускался всегда с нужной версией Python? Есть способ добиться такой универсальности: нужно всего лишь не указывать путь до команды python напрямую, а использовать программу env.

Эта программа умеет находить и запускать программы с учётом переменных https://ru.hexlet.io/courses/cli-basics/lessons/environment-variables/theory_unitокружения и, т.к. при активации виртуального окружения модифицируется переменная $PATH, то env будет запускать именно ту версию интерпретатора, которая нам нужна (она просто найдётся раньше, т.к. путь до исполняемых файлов окружения добавляется в начало $PATH).

Итак, представляем правильный способ указывать shebang в проектах на python! Встречайте:
'''

#!/usr/bin/env python3
print('Hello!')

'''
Путь до env указан конкретный потому, что эта программа практически всегда располагается именно там и не встречается в нескольких версиях :) А запомнить это правило написания shebang очень легко — "вызываем python3 с учётом окружения" ("env", это сокращение от "environment"/"окружение").
'''


# >>>>>> Cкрипты <<<<<<
'''
Как писать скрипты, мы уже узнали. Теперь представим, что у нас есть файл с кодом, который мы запускаем как скрипт. Файл разрастается, в нём появляются функции и прочие определения. В какой-то момент мы понимаем, что хотим переиспользовать, скажем, функцию из этого модуля в другом модуле. Значит, нужно импортировать!
'''

#@ Импортирование скриптов
'''
Давайте же смоделируем описанную выше ситуацию. Так будет выглядеть исходный скрипт:
'''

# file <first_script.py>

def greet(who):
    print('Hello, {}!'.format(who))

greet('Bob')
greet('Ann')

'''
А так — новый скрипт, в котором мы хотим переиспользовать функцию greet из первого модуля (скрипты — тоже модули):
'''

# file <second_script.py>

from first_script import greet

greet('Thomas')

'''
Запустим первый скрипт, а затем — второй (оба файла расположены в текущей директории):

$ python3 first_script.py
Hello, Bob!
Hello, Ann!
$ python3 second_script.py
Hello, Bob!
Hello, Ann!
Hello, Thomas!

Что мы видим — при выполнении второго скрипта выполнился и первый, хотя мы всего лишь импортировали из него одну функцию! Такова цена за простоту написания скриптов! Поскольку файл первого скрипта содержит не только определения, но и непосредственные действия (statements), то при загрузке файла (которая происходит при импорте модуля) эти действия будут выполнены. Теперь представьте, что мы бы импортировали скрипт, в котором не просто что-то печатается на экран, а удаляются какие-то файлы или того хуже — запускаются межконтинентальные ракеты!

Выходит, нам нужно как-то различать ситуации когда

1. модуль выполняется как скрипт (выполняем побочные действия),
2. модуль или его содержимое импортируются (не выполняем побочные действия).

Для этого нам понадобится немного магии!
'''

#@ Специальная переменная __name__

'''
Машинерия импортирования при загрузке модуля в первый раз (первый для текущего запуска интерпретатора) добавляет в этот модуль несколько переменных специального вида. Этих переменных довольно много, но нам пока интересна одна — переменная __name__.

Не стоит пугаться такого странного имени аж с четыремя символами подчёркивания: такие имена часто встречаются в Python-коде и как правило имеют какой-то специальный смысл. Опытный питонист помнит наизусть пару десятков таких переменных, а ещё про эти переменные любят спрашивать на собеседованиях.

Что же хранит переменная __name__ в каждом конкретном случае? В этом и весь секрет!

> Если происходит обычный импорт, то эта переменная содержит полное имя модуля (полностью квалифицированное).

> Если же происходит запуск в качестве скрипта, то переменная получает специальное значение — строку '__main__'.

Глядя на значение этой переменной, можем отличать "запуск" от импортирования.

Слово "main" используется во многих языках для именования функции, которая вызывается автоматически при старте программы, потому и в Python это слово используется в похожем смысле

Давайте вернёмся к нашему примеру и перепишем first_script.py с применением этого нового знания:
'''

# file <first_script.py>

def greet(who):
    print('Hello, {}!'.format(who))

if __name__ == '__main__':
    greet('Bob')
    greet('Ann')

'''
Теперь наш скрипт не будет приветствовать Боба и Энн, если мы будем импортировать модуль. Это победа!
'''

#@ Функция main

'''
Наш first_script.py уже достаточно хорош. Но мы можем его ещё чуть-чуть улучшить.

В теле условия if __name__… у нас перечислен набор действий, которые выполняются при запуске скрипта. Со временем таких действий может стать достаточно много. И, как вы бы догадались, может статься, что мы захотим переиспользовать и этот кусок кода! Скажу даже больше, такое происходит нередко. Поэтому существует соглашение: в теле условия if __name__… делают всего один вызов функции без аргументов main, которую объявляют выше в этом же модуле (само условие принято располагать в самом конце модуля скрипта).

С учётом всех описанных рекомендаций финальная версия скрипта first_script.py будет выглядеть так:
'''

#!/usr/bin/env python3

def greet(who):
    print('Hello, {}!'.format(who))

def main():
    greet('Bob')
    greet('Ann')

if __name__ == '__main__':
    main()


'''
Такой скрипт можно:
> запускать непосредственно;
> запускать из других скриптов, вызывая функцию main;
> использовать как библиотеку.
'''

#@ Запускаемые пакеты

'''
Рассмотрим немного экзотический, но всё же встречающийся случай — запуск пакета. Могло бы показаться, что раз при загрузке пакета всегда загружается модуль __init__.py, то и функцию main, и условие нужно располагать в нём. Но авторы по ряду причин решили реализовать запуск пакетов несколько иначе: при загрузке пакета пред запуском ищется модуль __main__.py и выполняется, как скрипт. Здесь мы не будем углубляться в причины, побудившие авторов языка сделать именно так, и просто запомним, что исполняемые пакеты всегда содержат скрипт __main__.py.

Когда же может понадобится запуск пакета? Сходу можно представить такой пример. Пусть мы имели один небольшой скрипт. Со временем кода в нём становилось всё больше — настолько много, что этот скрипт стало совершенно невозможно поддерживать. Мы решили превратить один модуль в пакет, содержащий несколько. Но как такой пакет в дальнейшем запускать? Вот для этого мы и можем использовать модуль __main__.py!

# Ссылки
Полный список того, что добавляет в модуль машинерия импортирования https://docs.python.org/3/reference/import.html#import-related-module-attributes

Имя 'main' и его значение https://docs.python.org/3/library/__main__.html#module-__main__
'''


# >>>>>> Доступный инструментарий для работы с Python-проектами. <<<<<<

#@ О важности выбора инструментария

'''
Сам по себе язык программирования мало интересен, если для него нет подходящего интерпретатора или компилятора. Но программы нужно не только запускать — их нужно доставлять до пользователя. Да и редкая программа бывает сразу готова, поэтому единожды доставленную программу нужно обновлять. А ещё её нужно продолжать разрабатывать — иногда в течении нескольких лет. Поэтому периодически возникают ситуации, когда нужно обновить какие-то сторонние библиотеки, а иногда и сам компилятор или интерпретатор. Для решения вышеперечисленных задач применительно к Python в разное время появились и развились различные инструменты. О некоторых из них ниже пойдёт речь.

Большинство инструментов имеет хорошую документацию, поэтому в рамках курса не будет дублироваться эта информация. Цель урока — дать общее представление, а местами предоставить и право выбора, какой инструмент выбрать среди доступных.

Но для начала познакомимся с новой концепцией — lock-файлами.
'''

#@ lock-файлы

'''
Обычно, при разработке автор некоторой библиотеки или программы так или иначе указывает версии сторонних пакетов, которые требуются для работы его творения. Обычно версия не закрепляется жёстко, вместо этого указывается диапазон версий, в пределах которого можно ожидать, что совместимость разных частей кода не нарушится. Именно для этого часто используется семантическое версионирование https://habr.com/ru/company/Voximplant/blog/281593/.

Однако случается, что либо диапазон версий бывает указан слишком широкий, либо семантическое версионирование оказывается применено неверно, или же просто в какой-то версии некоего пакета оказывается ошибка. Возникает ситуация, когда проект работает как нужно не на любом из сочетаний разных версий пакетов, а на некотором вполне конкретном.

lock-файл как раз и предназначен для того, чтобы в дополнение к перечню пакетов с "нечёткими" версиями, таки зафиксировать список конкретных версий, которые в данный момент для проекта подходят! В том или ином виде lock-files сейчас используются большинством современных пакетных менеджеров для разных языков программирования.
'''

#@ pyenv, средство управления разными версиями интерпретатора.

'''
Даже на этапе обучения важно иметь актуальную версию интерпретатора. И Python, будучи языком, который давно начали использовать для нужд автоматизации, часто бывает доступен в каталогах пакетов различных ОС. Однако пакеты как правило содержат только CPython (а ведь есть и другие реализации интерпретаторов Python, очень полезные в различных ситуациях), и далеко не всегда "свежий".

Авторы библиотек часто вынуждены поддерживать несколько версий Python и проверять, что новые изменения, вносимые в код, не сказываются на работоспособности оного при работе с разными версиями Python.

Т.о. на одной машине может быть установлено несколько разных реализаций Python и каждая — в более чем одном варианте. А управлять всем этим "серпентарием" призван pyenv https://github.com/pyenv/pyenv. Как бы вы не использовали Python, вам стоит научиться использовать этот инструмент.
'''

#@ pipenv, "инструментарий для людей"

'''
Да, авторы pipenv https://docs.pipenv.org/ так про своё детище и пишут. Что же это за штука? pipenv берёт на себя

> управление пакетами, т.е. заменяет pip (но использует "под капотом");
> создание виртуальных окружений (c "под капотом" venv);
> работу с зависимостями, контроль за версионированием и обновлением оных, построение графа зависимостей;
> воспроизводимость сборки (через использование тех самых lock-файлов).

pipenv — инструмент мощный, но требующий умения использовать distutils/setuptools для описания процесса сборки пакета с проектом. Новичкам может быть сложно освоить именно этот аспект использования в остальном достаточно удобной программы.

По ссылке выше вы найдёте сайт с подробнейшей документацией, советую хотя бы заглянуть туда.
'''


#@ poetry, ещё один человечный инструмент разработки

'''
В наших курсах и проектах я рекомендую использовать именно poetry. Также именно с помощью poetry оформлен наш python package boilerplate https://github.com/hexlet-boilerplates/python-package. Что же это за инструмент?

poetry https://poetry.eustace.io/, это сравнительно молодой проект, упрощающий разработку на Python. В целом он решает все те же проблемы (и тоже использует lock-файлы), что решает и pipenv, но в отличие от последнего, берёт на себя сборку пакетов. Более того, вместе с poetry вам не нужно глубоко погружаться в изучение distutils/setuptools — оные вообще не используются при описании poetry-пакета!

Документация у poetry компактная, но очень понятная. Описана и рекомендуемая структура директорий в типичном проекте и использование альтернативных индексов и многие другие аспекты — и всё это снабжено примерами! Проходите по ссылке выше и знакомьтесь.

Важно: напоминаю, я буду предполагать в дальнейших курсах и проектах использование именно poetry!
'''

#@ ipython, REPL, которого мы заслужили!

'''
Python REPL довольно удобен, а главное — всегда доступен. Но использовать его для ввода большого кол-ва кода неудобно (даже многострочный код не поредактируешь нормально!). Однако REPL в Python сделан модульным и существует несколько "улучшенных версий", наиболее популярная из которых — IPython https://ipython.readthedocs.io/.

IPython имеет
> подсветку синтаксиса,
> удобное автодополнение модулей для импортирования и определений в модулях,
> подсказки по аргументам функций и отображение документации,
> и многое-многое другое!

Большинство разработчиков, занимающихся анализом данных, проводят в IPython большую часть своего рабочего времени — настолько это мощная и полезная оболочка!
'''

#@ Всего не охватить...

'''
Вокруг базового инструментария Python за десятилетия существования языка было создано огромное количество полезностей. И благодаря тому, что в Python-мире правила хорошего тона предполагают тщательное документирование кода и сам синтаксис к этому располагает (всё те же docstrings), практически любой инструмент можно освоить самостоятельно — стоит лишь проявить любопытство! Всегда можно открыть сайт PyPI и пройтись по списку тем (topics), чтобы найти интересные проекты, способные сильно упростить жизнь и просто сделать процесс разработки и изучения более приятным!
'''




# >>>>>> Списки. <<<<<<

'''
Список — структура данных, предназначенная для хранения упорядоченных наборов элементов. Слово "упорядоченные" в данном случае означает, что элементы структуры хранятся в том порядке, в котором они были добавлены.

Элементы списка индексированы, т.е. имеют порядковый номер. Нумерация всегда начинается с нуля и всегда монотонна: у каждого последующего элемента индекс возрастает на единицу (как ещё говорят, нумерация элементов сквозная). При удалении элементов из середины списка (или даже из его начала), а также при вставке элементов в середину индексы пересчитываются и указанные выше свойства нумерации сохраняются.
'''

#@ Иммутабельность и мутабельность

'''
Мы уже знаем, что при конкатенации двух строк получается новая строка, а при сложении двух чисел получается новое число.

Рассмотренные ранее кортежи
> позволяют сгруппировать элементы, а затем разобрать группу на составляющие,
> могут быть собраны в кортеж большего размера,
> не позволяют менять состав элементов — только создание новых кортежей из элементов старых.

Таким образом все рассмотренные нами ранее типы и структуры данных — строки, числа, булевы значения, кортежи — иммутабельны (immutable), то есть будучи единожды созданными, уже не изменяются.

Списки — первая структура данных, которая может изменять своё содержимое "по месту" ("in place"). Такие объекты называют мутабельными (mutable). При этом некоторая часть операций над списками всё же создаёт новые списки на основе старых.
'''



# >>>>>> Создание списков <<<<<<

'''
Списки встроены в Python и поэтому язык предоставляет специальный синтаксис для объявления списков: списковые литералы.

Кортежи, описанные ранее, тоже встроены в язык и создаются с помощью своих собственных литералов — тех самых выражений в круглых скобках (("foo", 42) — литерал кортежа).

Создадим несколько списков, в т.ч. и один пустой:
'''

nummbers = [1, 2, 3]
strings = ["foo", "bar"]
booleans = [True, False]
empty_list = []

'''
Пока всё очень похоже на кортежи, только скобки квадратные вместо круглых.

Но на прошлом уроке я уже отмечал, что списки — мутабельные, т.е. могут изменяться со временем. Научимся же изменять списки путём добавления элементов в конец!

>>> l = [1, 2, 3]
>>> l
[1, 2, 3]
>>> l.append(4)
>>> l.append(5)
>>> l
[1, 2, 3, 4, 5]
>>> l.extend([6, 7, 8])
>>> l
[1, 2, 3, 4, 5, 6, 7, 8]
'''

#@ Списки — объекты

'''
В примере выше демонстрируется новый вид синтаксиса — вызов метода объекта.

Объекты — это такие сущности, которые могут хранить в себе некие данные (в т.ч. и другие объекты). А ещё объекты сами знают, как с хранимыми данными обращаться — как говорят, обладают поведением. Поведение объекта заключается в предоставлении методов — особого вида функций, которые всегда каким-либо образом относятся к объекту-владельцу. Вызов метода похож на вызов функции, только выглядит как "объект.метод(...)", т.е. мы всегда видим, метод какого объекта вызывается.

Об объектах, методах и элементах Объектно Ориентированного Программирования (ООП) мы поговорим в отдельном курсе. Пока же достаточно знать, что методы похожи на функции, могут модифицировать объект (а большинство объектов в Python - мутабельное) или же просто возвращать какую-то информацию об объекте.
'''

#@ Методы append и extend

'''
Итак, в коде выше список l — объект списка, а append и extend — методы объекта списка.
> append добавляет один элемент в свой список,
> extend добавляет все элементы из списка-аргумента в свой список.

Оба метода добавляют элементы в конец списка. И оба метода возвращают None, т.е. у этих методов-функций нет полезного результата — вся польза от вызова этих методов заключается в изменении связанного объекта!

Новички, в первый раз знакомящиеся с методами списка, часто совершают такую ошибку:

>>> l = [1]
>>> l = l.append(2)
>>> l
>>> # а где список?
>>> print(l)
None

Здесь во второй строке гипотетический автор кода хотел присвоить в переменную l дополненный список, но в переменной оказалось значение None (его вернул append).

Суть сей басни такова: нужно помнить, что метод может всегда возвращать None — и тем не менее влиять на мир, изменяя ассоциированный (говорят связанный или bounded) объект.
'''


# >>>>>> Ссылки <<<<<<

'''
Пока вы работали с иммутабельными значениями, способ, с помощью которого в Python эти значения передаются в функции и сохраняются в переменных, не был столь интересен. Но теперь вы учитесь работать с мутабельными объектами, а значит настало время узнать, что в Python всё передаётся по ссылке. Что же такое ссылка? Разберёмся. Но начнём знакомство со старших братьев ссылки — адреса и указателя.

Все данные, с которыми работает программа, находятся в оперативной памяти компьютера. Чтобы иметь доступ к некоторому участку памяти, нужно знать адрес этого участка.

В языках с ручным управлением памятью (C, C++ и другие) необходимо постоянно следить за тем, что память по адресу выделена и ещё не освобождена: в таких языках программист явно запрашивает у операционной системы нужное ему количество памяти. ОС в ответ на запрос выделяет участок в общей оперативной памяти, закрепляет этот блок за попросившим доступ и возвращает указатель, по сути представляющий собой тот самый адрес. Получив указатель, программист может сохранить что-то в выделенную память. По окончанию работы выделенные участки нужно освобождать — сообщать ОС, что память свободна и может быть использована для чего-то другого. Если обратиться по указателю к участку памяти, который ещё не выделен или уже освобождён, программа завершится с ошибкой!

Python является языком с автоматическим управлением памятью. Как только программисту требуется создать некое значение, требуемое количество памяти выделяется средой исполнения (runtime) автоматически, значение сохраняется в эту память и программисту возвращается ссылка на сохранённое значение. А как только данные перестают использоваться, память будет освобождена — также автоматически. Таким образом ссылки выполняют ту же роль, что и указатели в упомянутых выше языках. Но пользоваться ссылками всегда безопасно: ссылка не может указывать на память, не готовую к использованию. Более того, программисту на Python не нужно отдельно получать память и отдельно заполнять её — данные размещаются в памяти всё той же средой исполнения.

Итак, мы знаем, что когда мы создаём некое значение, мы получаем от runtime именно ссылку на него. Ссылок на одно и то же значение в любой момент времени может быть сколько-угодно. Python экономит усилия и всегда и везде передаёт любые значения по ссылкам — создаёт новые ссылки на существующие данные. Даже переменные, это всего лишь имена, привязанные к ссылкам. И при вызове функции с передачей ей аргументов, передаются не сами значения, а только ссылки на них — по одной новой ссылке на каждое значение. Когда же выполнение функции завершится, ненужные ссылки уничтожаются. И как только исчезает последняя ссылка на некое значение, среда исполнения понимает, что и само значение больше никому не нужно и его можно удалить из памяти (освободив таким образом место). Этим занимается специальный механизм среды исполнения, так называемый счётчик ссылок (reference counter).

Использование подсчёта ссылок позволяет Пайтону экономить изрядное количество памяти при передаче между разными частями программы длинных строк или больших чисел: не нужно копировать данные с места на место, как это делается в некоторых других языках. Но есть и обратная сторона медали. Передавая некоторому коду ссылку на изменяемый объект, мы не можем запретить этому коду изменить объект в процессе выполнения. Это в некоторых случаях затрудняет отладку кода и усложняет его чтение. Об этой особенности Python всегда нужно помнить.

В следующем уроке вы увидите, как передача ссылок может себя проявлять неожиданным для новичка образом.
'''



# >>>>>> Ссылки и мутабельность <<<<<<

'''
На прошлом уроке я ввёл понятие ссылки и упомянул, что в Пайтоне всё и всегда передаётся по ссылке. Поэкспериментируем со списком, как с первым известным нам изменяемым объектом. Но для начала нужно узнать об паре полезных для наших экспериментов инструментов — функции id и операторе is.
'''

#@ id и is

'''
Если обратиться к описанию функции (help(id)), то документация скажет:

id(obj, /)
    Return the identity of an object.

    This is guaranteed to be unique among simultaneously existing objects.

Функция id возвращает уникальный идентификатор объекта, который вы ей передаёте в качестве аргумента (помним, по ссылке!). Идентификатор — это обычное число. Но каждый отдельный объект имеет уникальный идентификатор, т.е. любые два разных объекта всегда будут иметь отличающиеся идентификаторы. И пусть идентификаторы не сохраняются от одного запуска Python к другому, но в рамках одного запуска связь объекта и идентификатора нерушима. Поэтому идентификаторы удобно использовать чтобы отслеживать передачи ссылок на объект между разными участками кода — идентификатор объекта будет одним и тем же, по какой бы ссылке мы к объекту не обращались.

>>> a = "some string"
>>> b = a
>>> id(a)
139739990935280
>>> id(b)
139739990935280
>>> a is b
True

Когда мы "присваиваем значение одной переменной другой", фактически создаётся новая именованная ссылка на исходное значение. Поэтому id(a) и id(b) возвращают одинаковый результат.

Оператор is проверяет равенство идентификаторов своих операндов. В данном примере обе переменные ссылаются на один объект, поэтому проверка a is b даёт True.

Проверка на равенство идентификаторов — очень быстрая. И особенно удобно ей пользоваться, когда мы имеем дело с так называемыми объектами-одиночками (singleton objects). Самые известные одиночки в Python, это True, False и None. Поэтому проверка на равенство None обычно пишется так:

...
if foo is None:
    ...

'''

#@ Списки, кортежи и ссылки

'''
Посмотрите на этот пример:
>>> a = [1, 2, 3]
>>> b = a
>>> a.append(4)
>>> b
[1, 2, 3, 4]

Что мы видим — поменяли "список a", а изменился ещё и "список b"! В действительности же нет никаких двух списков, есть две ссылки на один! Продолжим:

>>> a = []
>>> l = [a, a]
>>> a.append(1)
>>> l
[[1], [1]]

Здесь, как вы могли догадаться, в списке хранятся две ссылки на один и тот же объект — мутабельный к тому же. Именно в этом состоит тонкость работы со ссылками: когда мы получаем откуда-то ссылку, мы не можем быть уверены, что объект не будет меняться со временем без нашего участия!

А помните, я говорил, что кортеж не может изменяться? А как вам такое:

>>> a = []
>>> pair = (a, a)
>>> pair[0].append(1)
>>> pair[1].append(2)
>>> pair
([1, 2], [1, 2])


Значения в кортеже поменялось?! И всё же я говорил правду: настоящее содержимое кортежа — это ссылки на значения. И эти ссылки меняться не могут. Но могут меняться сами объекты по этим ссылкам!

Ещё интереснее наблюдать за списками и кортежами, создаваемыми с помощью специального синтаксиса — умножения списка или кортежа на число. Если умножить список или кортеж на число n, то мы получим новую коллекцию соответствующего типа, состоящую из n повторов элементов исходной коллекции. Вот несколько примеров:

>>> [1, 2, 3] * 3
[1, 2, 3, 1, 2, 3, 1, 2, 3]
>>> ('foo', 'bar') * 2
('foo', 'bar', 'foo', 'bar')
>>> [[]] * 5
[[], [], [], [], []]
>>> ((),) * 5
((), (), (), (), ())

Теперь, если мы вспомним, что коллекции — всегда коллекции ссылок, то можно будет догадаться о том, как такие "растиражированные" коллекции будут себя вести при изменении мутабельных элементов. Смотрите:

>>> t = ([], [], []) * 3
>>> t
([], [], [], [], [], [], [], [], [])
>>> t[0].append(42)
>>> t[1].append(0)
>>> t
([42], [0], [], [42], [0], [], [42], [0], [])

Запустите REPL и воспроизведите пример, а затем с помощью id и is посмотрите, какие элементы кортежа на какие объекты ссылаются.
'''

#@ Ссылки и присваивание

'''
Мы увидели, что в список можно добавить несколько ссылок на один объект. И что переменные — те же ссылки, просто именованные.

Но что происходит с переменными и элементами списка при присваивании? Посмотрим:

>>> a = "foo"
>>> id(a)
139739990954536
>>> a += "bar"
>>> a
'foobar'
>>> id(a)
139739952783688

Этот пример показывает, что имя переменной не жёстко связано со ссылкой на значение. Присваивание переменной (а += это вид присваивания) может поменять одну ссылку на другую. Это свойство присуще и элементам списка:

>>> a = "foo"
>>> l = [a, a]
>>> l[0] is l[1]
True
>>> l[0] += "bar"
>>> l
['foobar', 'foo']
>>> l[0] is l[1]
False

Здесь сначала два элемента списка ссылаются на одно значение. Но после присваивания нового значения первому элементу, связь элемента с изначальным значением разрывается и под конец элементы ссылаются на разные значения.
'''

#@@@
'''
src/solution.py
Вам необходимо реализовать функцию duplicate, которая должна принимать в качестве аргумента список и удваивать этот список "по месту" (вам нужно будет изменять исходный объект списка. Помним: список передаётся по ссылке!). Удваивание здесь означает, что после применения к нему функции список должен иметь копию всех элементов, добавленную в конец (см. пример ниже).

Пример

>>> l = [1, 2]
>>> duplicate(l)  # ничего не возвращается!
>>> l
[1, 2, 1, 2]
'''


def duplicate(items):
    items.extend(items)




# >>>>>> Модификация списков поэлементно, сортировка, разворачивание <<<<<<

'''
Как вы помните элементы списков индексированы, т.е. каждый элемент имеет порядковый номер. Первый элемент имеет индекс 0, последний — len(list) - 1.

Функция len возвращает длину списка, но работает она с различными типами, например — со строками и кортежами.

Элементы списка можно получать и заменять через присваивание по их индексу. Если указать отрицательный индекс, то элементы будут браться с конца и последний элемент списка будет иметь отрицательный индекс -1 (-0, увы, использовать не получится). Вот пара примеров использования индексов со списком:

>>> l = [0] * 3
>>> l[0], l[1] = 10, 32
>>> l[-1] = l[0] + l[1]
>>> l
[10, 32, 42]

Обратите внимание, что я создал список клонированием нулей. Так делать безопасно, потому что числа в Python — иммутабельные. Впрочем, все модификации списка я сделал через присваивание, поэтому ничего неожиданного я бы не получил, даже если бы использовал мутабельные объекты.
'''

#@ pop и insert

'''
Итак, получать и заменять элементы по одному мы умеем. Неплохо бы ещё уметь удалять старые элементы и вставлять в середину списка новые. За это отвечают методы pop и insert соответственно. pop удаляет элемент по индексу. Если не указать индекс, то удаляется последний элемент. При этом pop возвращает значение элемента, который удаляет:

>>> l = [1, 2, 3]
>>> l.pop()
3
>>> l
[1, 2]
>>> l.pop(0)
1
>>> l
[2]

А вот пример использования insert:

>>> l = [1, 2, 3]
>>> l.insert(1, 100)
>>> l
[1, 100, 2, 3]
>>> l.insert(-1, 200)
>>> l
[1, 100, 2, 200, 3]


insert всегда вставляет новый элемент перед элементом с указанным индексом относительно начала списка, вне зависимости от того, откуда мы индекс отсчитывали — от начала или от конца. И insert(-1, ..) вставляет элемент перед последним элементом!

Раз insert всегда добавляет перед, получается, что использовать insert для добавления в самый конец не получится. Но для этого у нас уже есть append.
'''

#@ Ошибки индексации

'''
Если попытаться вызвать pop() у пустого списка или указать индекс за пределами индексов существующих элементов, вы получите ошибку IndexError:

>>> l = []
>>> l.pop()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: pop from empty list

А вот insert более терпим к некорректным индексам и просто добавляет элементы с соответствующего края:

>>> l = [0]
>>> l.insert(-500, 1)
>>> l.insert(1000, 2)
>>> l
[1, 0, 2]


Однако полагаться на это не стоит — индексы всё же лучше держать под контролем!
'''

#@ Сортировка и разворачивание

'''
Списки чего-либо периодически приходится сортировать, а иногда и разворачивать. Желательно уметь это делать эффективно. Поэтому список уже имеет встроенные средства для выполнения обеих задач — методы sort и reverse. Оба метода изменяют список по месту (in place). Посмотрим на несколько примеров:


>>> l = [1, 3, 7, 2, 10, 8]
>>> l.sort()
>>> l
[1, 2, 3, 7, 8, 10]
>>> l.reverse()
>>> l
[10, 8, 7, 3, 2, 1]


Оба метода могут работать без параметров. В случае reverse нечего и параметризовывать: разворачивание — это всегда разворачивание. А вот сортировка может производиться по разным критериям. Если вызывать sort без параметров, то элементы сортируются в порядке возрастания. Однако методу можно передать параметр-функцию, которая будет возвращать критерий сортировки (т.н. ключ или key). Функция будет вызвана по одному разу для каждого элемента списка, после чего элементы будут отсортированы по возрастанию значения ключа. Давайте объявим функцию, которая будет возвращать остаток от деления аргумента на два, и используем её в роли ключа:

Оба метода могут работать без параметров. В случае reverse нечего и параметризовывать: разворачивание — это всегда разворачивание. А вот сортировка может производиться по разным критериям. Если вызывать sort без параметров, то элементы сортируются в порядке возрастания. Однако методу можно передать параметр-функцию, которая будет возвращать критерий сортировки (т.н. ключ или key). Функция будет вызвана по одному разу для каждого элемента списка, после чего элементы будут отсортированы по возрастанию значения ключа. Давайте объявим функцию, которая будет возвращать остаток от деления аргумента на два, и используем её в роли ключа:


>>> def mod2(x):
...     return x % 2
...
>>> l = [1, 2, 3, 6, 5, 4]
>>> l.sort(key=mod2)
>>> l
[2, 6, 4, 1, 3, 5]


Обратите внимание, что функцию в метод sort я передал по имени параметра. Такой синтаксис мы рассмотрим позже, но поэкспериментировать с методом sort и разными функциями-ключами вы уже сможете, указывая их по аналогии.

Функция mod2 вернула для чётных и нечётных чисел 0 и 1 соответственно. Поэтому в начале списка оказались сначала чётные числа.

Интересно, что в пределах своей группы числа сохранили порядок: 6 шла в списке перед 4, и это взаимное расположение сохранилось. Умение сохранить относительный порядок элементов, которые уже отсортированы (относительно друг друга) — важная характеристика алгоритма сортировки! Называется она стабильностью, сортировка же в этом случае называется стабильной сортировкой — и в Python сортировка именно такая.

Функция-ключ не обязана возвращать числа — она может возвращать любые значения, которые Python умеет сравнивать. Давайте в предыдущем примере усложним функцию-ключ:


>>> def key(x):
...     return (x % 2, x)
...
>>> l = [1, 2, 3, 6, 5, 4]
>>> l.sort(key=key)
>>> l
[2, 4, 6, 1, 3, 5]


Теперь числа разбиты на группы и при этом ещё и отсортированы внутри групп! Когда Python сравнивает кортежи, он сравнивает сначала первые элементы, а если те равны — вторые и т.д. Значения сравниваются, пока не найдётся первое неравенство. Либо пока не кончится один из кортежей — в этом случае более короткий будет "меньше". Вот несколько примеров:


>>> (1, 2, 3) < (1, 2, 4)
True
>>> (1, 1) < (1, 1, 1)
True
>>> (1, 2) > (1, 1, 1)
True
>>> (3, 4, 5) == (3, 4, 5)
True

Домашнее задание

У меня нет цели рассказать про все доступные методы списков, я показываю лишь общие принципы. Я не рассказал про методы count, remove, index: оставляю изучение этих методов вам. Напоминаю, посмотреть документацию можно прямо в REPL с помощью функции help. Только для просмотра информации о методе объекта, нужно передавать метод вместе с объектом: help([].count).




#@@@
src/solution.py
Вам нужно реализовать функцию rotate, которая должна принимать список в качестве аргумента и делать над ним следующее преобразование (список нужно изменять "на месте"!): последний элемент списка должен быть перемещён в начало списка (см. пример ниже). Если функция получает пустой список, то изменять его она не должна.

Для решения используйте методы insert и pop.

Пример

>>> l = [1, 2, 3]
>>> rotate(l)
>>> l
[3, 1, 2]
'''

def rotate(items):
    if items:
        items.insert(0, items.pop(-1))





# >>>>>> Срезы <<<<<<

'''
Работать с одиночными элементами вы уже умеете. Настало время перейти к очень интересному инструменту, который Pytnon предоставляет для работы с целыми подмножествами элементов списка: к так называемым срезам (slices).
'''

#@ Синтаксис описания срезов

'''
Срезы встроены в язык и снабжены своим собственным синтаксисом — настолько широко они используются. Срез записывается так же, как записывается обращение к элементу списка по индексу:

some_list[START:STOP:STEP]

Всего у среза три параметра:
> START — индекс первого элемента в выборке,
> STOP — индекс элемента списка, перед которым срез должен закончиться (т.е. сам элемент с индексом STOP не будет входить в выборку),
> STEP — шаг прироста выбираемых индексов.

Математически говоря, индексы элементов, которые будут выбраны, входят в множество

[START, START + STEP, START + 2 STEP, .., STOP)

Например, срез [3:20:5] означает выборку индексов [3, 8, 13, 18].

При этом любой из трёх параметров среза может быть опущен и вместо соответствующего параметра будет выбрано некое значение по умолчанию:

> умолчательный START означает "от начала списка",
> умолчательный STOP означает "до конца списка" (включительно),
> умолчательный STEP означает "брать каждый элемент".

Вот несколько примеров с разными наборами параметров:

[:]/[::] — "весь список",
[::2] — "нечётные по порядку элементы",
[1::2] — "чётные по порядку элементы",
[::-1] — "все элементы в обратном порядке",
[5:] — "все элементы, начиная с шестого",
[:5] — "все элементы, не доходя до шестого",
[-2:1:-1] — "все элементы от предпоследнего до второго в обратном порядке" (во всех случаях выборки от большего индекса к меньшему нужно указывать шаг!).

Срезы могут работать в двух режимах: собственно выборка и присваивание.
'''

#@ Выборка элементов

'''
Срезы-выборки работают со списками, кортежами, строками. Результатом применения выборки всегда становится новое значение соответствующего типа — список, кортеж, строка. Пример:

>>> 'hello'[2:]
'llo'
>>> (1, "foo", True, None)[2:]
(True, None)
>>> [1, 2, 3, 4, 5][2:]
[3, 4, 5]


Сразу сделаю несколько замечаний по использованию выборок:
> Так как кортежи чаще всего содержат разнородные элементы, срезы для них менее полезны, чем распаковка и перепаковка: тяжело удерживать в голове типы элементов вместе с индексами.
> Т.к. при выборке по срезу [:] создаётся новая копия списка, то именно так обычно список питонисты и копируют :)
> Нужно помнить, что хоть срез и порождает новый список или кортеж, для каждого выбранного элемента копируется только ссылка!
'''

#@ Присваивание срезу

'''
В отличие от строк и кортежей списки могут изменяться по месту. Одним из вариантов модификации является присваивание срезу. Срезу с указанным шагом можно присвоить список, содержащий соответствующее — то же, что и в срезе — кол-во новых элементов. Пример:

>>> l = [1, 2, 3, 4, 5, 6]
>>> l[::2] = [0, 0, 0]
>>> l
[0, 2, 0, 4, 0, 6]

Внимание, если вы попробуете присвоить срезу с шагом не то количество элементов, вы получите ошибку:

>>> l = [1, 2, 3, 4]
>>> l[::2] = [5, 6, 7]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: attempt to assign sequence of size 3 to extended slice of size 2


Если же срез непрерывный, т.е. шаг не указан и индексы идут подряд, то свободы нам даётся больше. Такому срезу можно присвоить как больше элементов — тогда список вырастет — так и меньше, что приведёт к урезанию списка. Примеры:

>>> l = [1, 2, 3]
>>> l[2:] = [4, 5]
>>> l
[1, 2, 4, 5]
>>> l[1:-1] = [100]
>>> l
[1, 100, 5]
>>> l[:] = []
>>> l
[]

Сначала список растёт, потом уменьшается, а под конец вообще становится пустым — и всё с помощью компактного, но мощного синтаксиса срезов.
'''

#@ Срезы — значения

'''
Хоть срезы и имеют специальную поддержку со стороны синтаксиса, но мы можем создавать и использовать срезы сами по себе — как обычные значения.

Значение среза можно сконструировать с помощью функции slice:

>>> first_two = slice(2)
>>> each_odd = slice(None, None, 2)
>>> each_odd
slice(None, None, 2)
>>> l = [1, 2, 3, 4, 5]
>>> l[first_two]
[1, 2]
>>> l[each_odd]
[1, 3, 5]

Функция slice принимает от одного до трёх параметров — те самые START, STOP и STEP. Если вы хотите "пропустить" один из параметров, то подставьте вместо него None.

None можно использовать и в записи срезов в квадратных скобках. Там None так же будет означать пропуск значения!

И конечно же на месте параметров среза могут быть любые выражения, лишь бы эти выражения вычислялись в целые числа или None.

'''

#@ Соотношение START и STOP

'''
В срезе элемент с индексом STOP не попадает в выборку, в отличие от элемента с индексом START. У такого поведения есть особенность: какой бы мы не выбрали неотрицательный индекс n для любого списка — даже выходящий за его пределы — указанное равенство будет соблюдаться:
'''

l == l[:n] + l[n:]

'''
Пример:

>>> s = 'Hello!'
>>> s[:2] + s[2:]
'Hello!'
>>> s[:4] + s[4:]
'Hello!'
>>> s[:0] + s[0:] == s
True
>>> s[:100] + s[100:] == s
True

Это свойство удобно использовать, когда вы разбираете некий текст: вам достаточно двигать позицию "разрезания" строки на начало и остаток, не заботясь о том, что какая-либо информация на границе разрезания потеряется!



#@@@
src/solution.py
В этом упражнении вам нужно будет реализовать две функции — rotated_left и rotated_right. Каждая функция должна

принять список, кортеж или строку в качестве аргумента,
с помощью срезов и конкатенации получить новое значение того же типа,
вернуть это значение.
Отличаются функции лишь "направлением поворота" (см. примеры ниже).

Т.к. и строки, и списки с кортежами разрешают конкатенацию и срезы, ваш код не должен проверять тип аргумента — нужно обойтись только лишь срезами и конкатенацией!

Обратите внимание: имена функций содержат глагол с окончанием ed — в пайтоне подобным образом часто называют функции, возвращающие новое значение на основе старого.

Примеры
При вращении влево первый элемент перемещается в конец:

>>> rotated_left("ABCD")
"BCDA"

При вращении вправо последний элемент перемещается в начало:

>>> rotated_right([1, 2, 3, 4])
[4, 1, 2, 3]
'''

def rotated_right(items):
    return items[-1:] + items[:-1]


def rotated_left(items):
    return items[1:] + items[:1]



# >>>>>> Срезы <<<<<<

'''
Ранее мы рассматривали цикл while. Эта конструкция предназначена для повторения некоего набора действий — всё, что выходит за рамки "бездумного" повторения, как правило, требует дополнительных средств для хранения состояния. Пример: счётчик, который мы изменяем в цикле. И при работе с коллекциями нам нужно как-то выбирать, с каким элементом мы работаем в текущей итерации. Так что же, использовать переменную счётчик каждый раз? Любой программист всегда стремится автоматизировать рутинную работу, и авторы языков — не исключение. Поэтому в Python для работы с коллекциями существует другой вид цикла — цикл for.

Стоит сразу отметить, что этот цикл не похож на циклы с тем же названием в других языках программирования. Во многих языках этот цикл всего лишь дополняет условие завершения цикла переменной-счётчиком. Python в стремлении сделать удобно пошёл дальше, поэтому в этом языке цикл for сразу перебирает элементы входной коллекции и думать об индексе чаще всего вообще не нужно.
'''

#@ Синтаксис

# Цикл for устроен очень просто:
for element in collection:
    print(element)  # this is body of cycle

'''
Заметьте, в простейшем случае у цикла даже нет явного условия завершения: цикл просто останавливается, когда в коллекции заканчиваются элементы!

Пример выше сработает для кортежей и списков — в этом случае будут выведены все элементы. А если проитерировать (так называют обход коллекции — позже вы узнаете, почему) строку, то переменная цикла (в коде выше это element) будет поочерёдно содержать все символы строки. Пример:

>>> for c in 'Hello!':
...     print(c)
...
H
e
l
l
o
!

Но что же делать, если нам нужно не просто получить элементы списка один за другим, но и изменить эти элементы? Ведь для этого нам понадобится индекс каждого элемента! На этот случай в Python есть удобная функция enumerate ("пронумеровать"). Эта функция снабжает каждый элемент индексом, складывая каждый индекс вместе с элементом в кортеж. Кортежи эти, как правило, прямо в первой строке цикла и распаковывают:


>>> items = ['foo', 'bar', 'baz']
>>> for (index, elem) in enumerate(items):
...     items[index] = elem + '!'
...
>>> items
['foo!', 'bar!', 'baz!']

В этом цикле мы заменили каждый элемент оригинальным значением, дополненным строкой '!'. Этот код можно было написать и несколько иначе:

>>> items = ['foo', 'bar', 'baz']
>>> for (index, _) in enumerate(items):
...     items[index] += '!'
...
>>> items
['foo!', 'bar!', 'baz!']

В этот раз мы вообще не используем сами элементы — только их индексы. Поэтому вместо переменной цикла, в которую распаковываются элементы, у нас стоит прочерк. Это не какая-то особая переменная, а всего лишь соглашение: в Python часто незначимые в данном контексте вещи "спихивают" в переменную _.

Заметьте: хоть в последнем примере речь и шла об индексах, но мы всё равно не использовали длину коллекции — enumerate тоже знает, где остановиться (в конце исходной коллекции).
'''

#@ Управление циклом с помощью break и continue.

'''
Иногда не нужно доходить до конца коллекции. Пример: поиск элемента, удовлетворяющего некоему условию. Как только мы нашли первый подходящий элемент, нам неплохо бы сэкономить ресурсы и завершить цикл. Такой ранний выход из цикла делается с помощью команды break. Вот цикл поиска первого положительного числа:

>>> items = [-2, 0, -10, 3, 5, -1]
>>> for item in items:
...     if item > 0:
...         break
...
>>> item
3

Как вы могли заметить, переменная цикла оказалась доступна и после его завершения. Однако если коллекция окажется пустой, то переменная не будет определена — имейте это в виду!

Этот код, кажется, работает, как надо. Однако если в списке не встретится ни одного положительного числа, то в переменной item окажется просто последний элемент списка! Как же понять, что мы ничего не нашли? На помощь приходит else — да, в Python у цикла for тоже есть такая ветка! В цикле else выполняется, если цикл так и не прервался с помощью break. Для алгоритмов поиска — идеальный вариант! Перепишем наш пример с применением else:

>>> items = [-2, 0, -10, -1]
>>> for item in items:
...     if item > 0:
...         break
... else:
...     item = None
...
>>> print(item)
None

Победа!

Теперь представим ситуацию, что мы в процессе выполнения тела цикла поняли, что остаток тела выполнять незачем и можно сразу перейти к следующей итерации. Для перехода к следующей итерации предназначена команда continue. Её использование продемонстрирует следующий пример: мы читаем строки содержащие строчки кода, но нам не нужно обрабатывать код тех строчек, которые начинаются с символа #. Вот так будет выглядеть код:

>>> lines_of_code = [
... '# begin of example',
... 'echo 123',
... 'cd foo',
... '# end']
>>> for line in lines_of_code:
...     if line[:1] == '#':
...         continue
...     # here we process a code
...     print(line)
...
echo 123
cd foo

Конечно же мы могли бы обойтись условной конструкцией. Однако в этом случае код, обрабатывающий нужные строки, был бы вложен глубже. А нам нужно стремиться держать вложенность кода в разумных пределах, иначе код очень быстро станет очень сложным для прочтения.
'''

#@ break, continue, else и цикл while

'''
Да, и ветка else, и команды break и continue — доступны и для цикла while! Вот комплексный пример, демонстрирующий все эти возможности:
'''

tries = 3
while tries:
    print('>>> ', end='')
    command = input()
    if not command:
        continue
    if command in ('echo', 'cd', 'help'):
        break
    print('Unknown command!')
    tries -= 1
else:
    print('Too many bad tries!')
    command = None

'''
Этот код просит пользователя ввести одну из команд, игнорирует пустой ввод, ограничивает кол-во попыток ввода. Подумайте, какая часть тела цикла за что отвечает.
'''

#@ Цикл for и изменяемые коллекции

'''
Хочу вас предостеречь от изменения состава списка во время обхода его же в цикле for. Если вы будете удалять элементы из списка, по которому проходитесь — или даже всего лишь добавлять новые элементы в конец — результат может быть неожиданным, вплоть до завершения программы с ошибкой! Лучше наполнять новый список в процессе обхода старого.

Если же вы хотите обязательно изменить состав исходного списка (объекта по ссылке), то либо обходите в цикле копию списка
'''

for x in original_list[:]:
    original_list.pop(0)  # и т.п.


# либо создайте временный список, а потом очистите исходный и добавьте элементы из временного

new_list = []
for x in original_list:
    ...
original_list[:] = []  # удаляем старое содержимое
original_list.extend(new_list)

'''
Естественно можно скомбинировать эти два варианта и сначала сделать копию, потом очистить оригинал, и затем уже в цикле обхода копии добавлять новые элементы.


#@
src/solution.py
В этом упражнении вы будете реализовывать классический цикл поиска. Функция find_index, которую вам предстоит написать, должна принимать значение и нечто, по чему можно итерироваться — строку, список, кортеж. В ответ функция должна вернуть индекс первого элемента итерируемой последовательности, равного заданному значению. Если же значение в последовательности не встречается или же последовательность окажется пустой, функция должна вернуть None.

>>> find_index('t', 'cat')
2
>>> find_index(5, [1, 2, 3, 4, 5, 6, 7])
4
>>> find_index(42, []) is None
True
>>> find_index('!', 'abc') is None
True
'''

def find_index(value, items):
    for index, item in enumerate(items):
        if item == value:
            return index



#@ Итераторы

'''
На предыдущем уроке мы рассмотрели цикл for и в тексте встретился термин "итерирование". И если в других языках это слово могут применять к любым циклам, то в Python у этого слова есть и другое значение: итерирование — это взаимодействие с неким объектом, поддерживающим протокол итерации.

Для начала разберём, что же такое протокол в контексте Пайтона. Протоколом называют набор определенных действий над объектом. И если некий объект "А" позволяет совершать над собой действия, описанные неким протоколом "Б", то говорят: "объект А реализует протокол Б" или "объект А поддерживает протокол Б". В последующих курсах вы узнаете, что различных протоколов в Python — множество. Даже многие синтаксические конструкции языка работают для самых разных объектов сходным образом именно потому, что объекты реализуют специальные протоколы. Так мы можем в шаблон подставлять не только строки, но и значения других типов, потому что эти типы реализуют протокол приведения к строке! В Python протоколы встречаются на каждом шагу.
'''

#@ Протокол итерации

'''
Протокол итерации — один из самых важных протоколов в Python. Ведь именно он позволяет циклу for работать с самыми разными коллекциями единообразно. В чём же заключается этот протокол? Протокол требует от объекта быть итерируемым (iterable), т.е. иметь специальный метод __iter__ (да, в Python не только файлы принято называть в таком стиле). Если у iterable-объекта вызвать метод __iter__, то метод должен вернуть новый специальный объект — так называемый итератор (iterator). А итератор, в свою очередь, должен иметь метод __next__.

Звучит сложно, но давайте рассмотрим живой пример — итерирование списка. Список — итерируемый, поэтому нам подходит. Итак, создадим список и итератор для него:

>>> l = [1,2,3,5,8,11]
>>> i = iter(l)
>>> i
<list_iterator object at 0x7f517843a240>

Я вызвал для списка функцию iter, но на самом деле эта функция просто вызывает у списка соответствующий метод __iter__. Это сделано для удобства чтения кода, ведь читать имена вроде __foo__ не очень удобно. Некоторые другие функции делают что-то подобное, например функция len. Большинство же специальных методов с похожими именами вызывается внутри каких-то языковых конструкций и не предназначено для вызова напрямую.

Теперь у нас есть итератор i, попробуем повызывать у него метод __next__ как напрямую, так и с помощью более удобной функции next:


>>> i.__next__()
1
>>> i.__next__()
2
>>> next(i)
3
>>> next(i)
5


Как мы видим, при каждом вызове метод возвращает очередной элемент исходного списка. А между вызовами он помнит свою позицию в списке. Т.о. итератор выполняет роль "курсора" в вашем редакторе текста: если нажимать стрелки, то курсор перемещается и указывает на новое место в тексте. Только итератор — это курсор, умеющий перемещаться только в одну сторону.

Но что же произойдёт, когда элементы в списке кончатся? Проверим:

>>> next(i)
8
>>> next(i)
11
>>> next(i)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration

Когда итератор достиг конца исходного списка, последующий вызов next привёл к специальной ошибке StopIteration. Только в данном случае это не ошибка, ведь всё когда-нибудь заканчивается! StopIteration — это исключение (exception). Об исключениях мы поговорим позже, а пока нужно лишь знать, что те средства языка, которые работают на основе протокола итерации, знают, как реагировать на это конкретное исключение. Например, цикл for "молча" завершает работу :)

Теперь вы уже можете представить, как на самом деле работает цикл for. Он получает у iterable объекта новый итератор, а затем вызывает у итератора метод __next__ до тех пор, пока не будет выброшено исключение StopIteration. Интересно, не правда ли? Но дальше будет ещё интереснее!
'''

#@ Цикл for и итераторы

'''
Что же будет, если сначала получить итератор потом передать циклу for? Такое возможно, ведь цикл for достаточно умён — он понимает, что можно сразу начать вызывать __next__!

Давайте напишем функцию, ищущую в цикле первую строку, длина которой больше пяти символов:
'''

def search_long_string(source):
    for item in source:
        if len(item) >= 5:
            return item


#@ А теперь создадим список, содержащий несколько подходящих строк и запустим функцию для этого списка пару раз:

'''
>>> animals = ['cat', 'mole', 'tiger', 'lion', 'camel']
>>> search_long_string(animals)
'tiger'
>>> search_long_string(animals)
'tiger'

Функция оба раза вернула одну и ту же строку, ведь мы передали в неё iterable, а значит цикл for создавал каждый раз новый итератор.

Но давайте же создадим итератор сами и передадим в функцию уже его:

>>> animals = ['cat', 'mole', 'tiger', 'lion', 'camel']
>>> cursor = iter(animals)
>>> search_long_string(cursor)
'tiger'
>>> search_long_string(cursor)
'camel'
>>> search_long_string(cursor)
>>> search_long_string(cursor)
>>>

Уже интереснее! Итератор запомнил состояние между вызовами функций, и мы нашли оба длинных слова. Последующие вызовы функции не вернули ничего (вернули None), потому что итератор дошёл до конца (и запомнил это).

А ведь итераторов для одного и того же списка можно создать несколько! И каждый будет помнить свою позицию! Работая с кодом на Python вы непременно увидите и не раз интересные применения протокола итерации. А поэкспериментировать прямо в REPL вы можете уже сейчас!
'''

#@ Генераторы

'''
В Python не только коллекции являются iterable. Ещё существуют так называемые генераторы (generators). Что же такое генератор? Генератор — это iterable, элементы которого не хранятся в нём, но создаются по мере необходимости. Для примера возьмём генератор range. Вот как он работает:

>>> numbers = range(3, 11, 2)
>>> for n in numbers:
...     print(n)
...
3
5
7
9
>>> list(numbers)
[3, 5, 7, 9]

Здесь range генерирует последовательность чисел от 3 до (но не включая) 11 с шагом 2 (шаг и начальное значения можно опускать, тогда счёт будет производиться от нуля и с шагом в единицу). Цикл for итерирует числа. Затем я использую функцию list, чтобы получить список — эта функция может принять в качестве единственного аргумента iterable или iterator, элементы которого сложит во вновь созданный список.

Функция list накапливает значения в список, а tuple — в кортеж.

range представляет собой перезапускаемый генератор. Для такого генератора можно создавать сколько угодно итераторов, и для каждого из них значения будут генерироваться заново.

Существуют и не перезапускаемые генераторы. Эти при вызове метода __iter__ всегда возвращают один и тот же итератор. Поэтому по значениям такого генератора можно пройтись только один раз! Примером такого генератора является enumerate, который мы рассматривали на прошлом уроке. Давайте ещё раз взглянем на него:

>>> l = enumerate("asdf")
>>> list(l)
[(0, 'a'), (1, 's'), (2, 'd'), (3, 'f')]
>>> list(l)
[]


Вторая попытка проитерировать объект в переменной l ничего не даёт, т.к. генератор уже отработал один проход.

А вот ещё один встроенный генератор — zip. Этот генератор принимает на входе несколько iterable или iterators и поэлементно группирует в кортежи. Демонстрация:


>>> keys = ["foo", "bar", "baz"]
>>> values = [1, 2, 3, 4]
>>> for k, v in zip(keys, values):
...     print(k, "=", v)
...
foo = 1
bar = 2
baz = 3
>>> z = zip(range(10), "hello", [True, False])
>>> list(z)
[(0, 'h', True), (1, 'e', False)]
>>> list(z)
[]

Пример демонстрирует два момента:
> zip — не перезапускаемый,
> zip — перестаёт генерировать кортежи, как только заканчиваются элементы в любом из источников.
'''

#@ Генераторы и ленивые вычисления

'''
Большая часть языков программирования выполняет код в том порядке, в котором элементы кода написаны. Инструкции выполняются сверху вниз, выражения вычисляются после того, как будут вычислены их составляющие, функции вызываются после того, как будут вычислены их аргументы. Такая модель исполнения называется энергичной (eager).

Существует и ленивая (lazy) модель вычисления. В рамках этой модели вычисления производятся только тогда, когда их результат становится действительно нужен. Т.к. в любой программе при разных входных данных могут быть не нужны отдельные вычисления, то ленивая модель вычисления может дать определённые преимущества: то, что не нужно — не будет вычислено. Т.о. ленивость можно рассматривать как своего рода оптимизацию.

Python, как язык с энергичной моделью вычисления, практически всегда и всё вычисляет сразу. Однако отдельные элементы ленивости присутствуют и в Пайтоне. Генераторы — один из таких элементов. Генераторы производят элементы только по мере необходимости. И даже целые конструкции, собранные из генераторов — эдакие конвейеры, собирающие составные значения — производят сборку по одному изделию за раз!

Так составной генератор zip(range(100000000), "abc") не генерирует все сто миллионов чисел, ведь строка "abc" слишком коротка, чтобы образовать столько пар. Но даже и этих пар не будет, если результат вычисления этого выражения не будет проитерирован! Так ленивость позволяет экономить память при обработке больших потоков данных — нам не нужно загружать все данные целиком, достаточно загружать и обрабатывать их небольшими порциями.

#@ Ссылки

itertools https://docs.python.org/3/library/itertools.html — очень полезный модуль стандартной библиотеки. Содержит множество функций для создания итераторов и дальнейшей работы с ними.



#@
src/solution.py
Цель данного упражнения — реализовать функцию find_second_index. В этом упражнении вам пригодится функция find_index, которую вы реализовали в прошлом упражнении. Напоминаю, эта функция возвращает индекс первого элемента последовательности, равного заданному значению. Функция find_second_index же должна возвращать индекс второго подходящего элемента в последовательности. Если подходящих элементов в последовательности меньше двух или же последовательность пуста, нужно всё так же возвращать None.

>>> find_second_index('b', 'bob')
2
>>> find_second_index('a', 'cat') is None
True

Новую функцию вам следует реализовывать с помощью уже имеющейся find_index. И не забудьте, что итератор сохраняет позицию, в которой остановился обход — это знание поможет вам в решении поставленной задачи!
'''

def find_index(value, items):
    for index, item in enumerate(items):
        if item == value:
            return index

def find_second_index(value, items):
    iterator = iter(items)
    first = find_index(value, iterator)
    second = find_index(value, iterator)
    if second is not None:
        return first + second + 1


# >>>>>> Итоги <<<<<<

'''
В рамках курса вы узнали о списках и том, как ими пользоваться. Однако в курсе был описан преимущественно императивный подход к работе со списками: списки модифицировались "по месту" путём выполнения некоторых последовательностей действий, т.е. вы объясняли компьютеру каким образом получить нужный результат. Этот подход позволяет использовать списки эффективно, и вы, используя его, будете писать программы, работающие быстро.

Однако императивный подход — не единственный. Есть и другие подходы. Например, декларативный — этот описывает в коде, что вы хотите получить в итоге. Немного к нему я уже прикоснулся, рассказав про генераторы. В последующих курсах вы узнаете, как реализовывать генераторы, а также узнаете о других инструментах декларативного программирования коллекций.

Полезно и "понимание разницы между iterable и iterator". Позже вы узнаете о других коллекциях. И эти коллекции тоже реализуют протокол итерации, поэтому использовать тот же цикл for получится и с ними. Удобно!

Помимо списков вы узнали и о таких концепциях, как ссылки и протоколы. Понимание того, что многие синтаксические конструкции работают на основе протоколов, поможет вам проектировать свои типы данных так, что с ними будет удобно и приятно работать и вам, и другим программистам. А знание того, что объекты всегда передаются по ссылке, поможет в отладке объекто-ориентированного кода и многопоточных приложений.

Также вопросы на понимание работы со ссылками и использование различных протоколов часто задают на собеседованиях! Про итераторы тоже спрашивают :)
'''


############## Python: Словари и Множества ##############

'''
Словарь, или как ещё говорят, ассоциативный массив — тип данных, представляющий собой коллекцию пар "ключ-значение". В рамках одного словаря ключи не повторяются.
Особенности
Коллекции, о которых говорилось ранее, а именно — списки и кортежи — упорядочены и хранят элементы в том порядке, в котором оные были добавлены. Словарь же не таков: он не запоминает порядок добавления элементов и вместо этого сохраняет элементы так, чтобы операции над содержимым словаря были максимально эффективны!

Элементы списка или кортежа индексированы и позиция каждого элемента представляет собой число — порядковый номер от начала коллекции. Ключами же словаря могут быть не только числа, но и многие другие типы данных, чаще всего — строки. И если индексы списка и кортежа монотонны — идут без пропусков, у соседних элементов отличаются на единицу, то никаких особых закономерностей между ключами словаря нет (кроме гарантии уникальности).

Обычно списки гомогенны, т.е. хранят элементы одного типа. Словари же, напротив, чаще всего гетерогенны: отличаться могут как типы значений, так и типы ключей — да, бывает и такое, хоть и редко :)

Для чего применимы словари?
В словарях удобно сохранять наборы сведений о некоей сущности. Скажем, пользователь может обладать никнеймом, возрастом, адресом электронной почты. И все эти данные можно сохранить в одном словаре:

user = {
    'name': 'superbob',
    'email': 'bob.is.super@mail.com',
    'age': 35
}

Так выглядит литерал словаря. Здесь 'name', 'email и 'age' — ключи словаря, а 35 и 'superbob' — очевидно, значения.

Подобным образом с помощью словарей можно описывать любые сущности предметной области, например, заказ, курс, урок, топик на форуме, комментарий в проекте. В каждом случае будет своя структура, зависящая от тех свойств, которыми описывается конкретная сущность.

Кроме того, словари используются как хранилища для конфигурационных параметров или как способ передать в функцию множество разнородных данных в виде одного параметра.
'''

#@ Литерал словаря.

'''
Словари, как и другие встроенные коллекции, поддерживаются языком и имеют свой собственный синтаксис для описания литералов. Литерал словаря записывается в фигурных скобках, пары ключ-значение разделяются запятыми, а ключ отделяется от значения двоеточием:

>>> dictionary = {
...     "foo": "bar",
...     "baz": 42,
...     "items": {
...         1: "apple",
...         2: "orange",
...         100500: "lemon"
...     },
... }
>>> dictionary
{'foo': 'bar', 'baz': 42, 'items': {1: 'apple', 2: 'orange', 100500: 'lemon'}}

В этом примере есть и ключи-строки, и ключи-числа, а одно из значений — вложенный словарь.

И переменные, конечно же, могут выступать в роли значений и ключей:
'''

#@ Доступ к элементам по ключу.

'''
Выше я объявил словарь dictionary. Запросить у него значение по ключу можно так:

>>> dictionary["baz"]
42
>>> dictionary["BANG"]
...
KeyError: 'BANG'
Ключа "BANG" в dictionary нет, поэтому было возбуждено исключение KeyError — аналог IndexError, только для словарей.

Проверить наличие ключа в словаре можно с помощью привычного оператора in:

>>> "baz" in dictionary
True
>>> "BANG" in dictionary
False
Теперь, если вы захотите получить заначение по ключу, которого может и не быть, вы можете сделать это так:

dictionary["BANG"] if "BANG" in dictionary else None
Однако подобный "безопасный" запрос элементов нужен настолько часто, что объект словаря имеет для этого специальный метод .get:

>>> dictionary.get("baz")
42
>>> dictionary.get("BANG")  # вернёт None
>>> dictionary.get("BANG", "no such key")
'no such key'
Третий вызов метода показывает, как можно явно задать значение по-умолчанию. Если его не указывать, метод вернёт None при отсутствии значения по указанному ключу.
'''

#@ Итераторы keys, values и items.

'''
Если попробовать проитерировать словарь, то мы получим перечень ключей:

>>> for k in {"a": 1, "b": 2}:
...     print(k)
...
a
b
Этого же результата можно добиться и более явно, для чего нужно будет вызвать метод .keys():

>>> list({"a": 1, "b": 2}.keys())
['a', 'b']
Чтобы получить значения, нужно вызвать метод .values():

>>> list({"a": 1, "b": 2}.values())
[1, 2]
А чтобы получить одновременно и ключи и соответствующие значения, можно вызвать метод .items():

>>> for k, v in {"a": 1, "b": 2}.items():
...     print(k, "=", v)
...
a = 1
b = 2
Важно помнить: как я уже говорил, словари не упорядочены. Поэтому строить логику кода с учётом порядка ключей в словаре не стоит!


#@@@ src/solution.py
В этой практике вам нужно реализовать две функции:

функцию make_user, которая должна принимать два параметра — имя пользователя и возраст (число). Вернуть функция должна словарь с ключами 'name' и 'age', по которым должны быть сохранены соответствующие значения.
функцию format_user, которая, будучи применена к результату вызова make_user (помним — это словарь), должна вернуть строку вида 'Phil, 25'.
Пример:

>>> phil = make_user('Phil', 25)
>>> type(phil)
<class 'dict'>
>>> format_user(phil)
'Phil, 25'
'''
def make_user(name, age):
    return {'name': name, 'age': age}


def format_user(user):
    return '{}, {}'.format(user["name"], user["age"])



# >>>>>> Изменение данных в словаре <<<<<<

'''
Словарь в Пайтоне — мутабельный, поэтому изменяется по месту. Однако для добавления новой пары ключ-значение не нужны отдельные методы, вроде спискового метода .append — достаточно обычного присваивания:

>>> d = {}  # пустой словарь
>>> d["a"] = 100
>>> d
{'a': 100}
>>> d["b"] = 200
>>> d["a"] = 0
>>> d
{'a': 0, 'b': 200}
Здесь вы можете увидеть, что присваивание значения новому ключу выглядит точно так же, как и присваивание существующему. Удобно!

Удаление элементов из словаря делается с помощью метода pop — в этом словарь уже больше похож на список. Только вместо индекса используется ключ:

>>> d = {'a': 1, 'b': 2}
>>> d.pop('a')
1
>>> d
{'b': 2}
>>> d.pop('BANG')
...
KeyError: 'BANG'
Пример показывает, что если попытаться извлечь значение по несуществующему ключу, то будет возбуждено исключение. Однако метод pop можно вызывать с указанием значения по-умолчанию. В этом случае при отсутствии ключа в словаре будет возвращено это самое значение, а исключение возбуждено не будет. Пример:

>>> d = {'a': 1, 'b': 2}
>>> d.pop('BANG', None)
>>> d.pop('BANG', 42)
42
Аналогом спискового pop без аргументов для словаря служит метод popitem. Этот метод извлекает ключ и значение в виде кортежа, а если словарь уже пуст, то возбуждает исключение:

>>> d = {'a': 1}
>>> d.popitem()
('a', 1)
>>> d.popitem()
...
KeyError: 'popitem(): dictionary is empty'
Помним, что порядок ключей в словаре не зависит от того, в какой последовательности эти ключи добавлялись в словарь. Поэтому мы не можем полагаться на то, в каком порядке будут возвращаться пары при вызове popitem! Но в том, что все пары будут извлечены и каждая пара будет извлечена строго один раз, мы можем быть уверены :)
'''

#@ Дополнение одного словаря другим.

'''
У списка есть метод extend, который расширяет один список другим. У словаря есть похожий по смыслу метод update. Однако, при вызове update ассоциированный объект словаря не просто получает пары ключ-значение из нового словаря. Происходит именно обновление данных (поэтому метод и называется update): новые ключи дописываются в словарь, а если какие-то ключи уже существовали до этого, то значения, с ними связанные, будут заменены новыми. Пример:

>>> cart = {'apples': 2, 'oranges': 1}
>>> addon = {'oranges': 5, 'lemons': 3}
>>> cart.update(addon)
>>> cart
{'apples': 2, 'oranges': 5, 'lemons': 3}

Лимоны были добавлены, а кол-во апельсинов было обновлено. Просто, понятно, удобно.
'''

#@ Копирование словаря.

'''
В случае списков мы можем сложить два списка и получить новый. Или же получить копию одного списка и уже её дополнить данными из второго. Но словари нельзя складывать и срезы словари тоже не поддерживают. Зато у словаря есть метод copy, который работает аналогично копированию списка с помощью среза [:] — при вызове он возвращает так называемую поверхностную копию (она же "неглубокая копия", "shallow copy") словаря. Поверхностная копия воспроизводит только структуру словаря, но не копирует значения, а только лишь создаёт на них новые ссылки. И тем не менее поверхностная копия — новый словарь, который может изменять свой состав, не влияя на оригинал:

>>> d = {'a': 1, 'b': [42]}
>>> c = d.copy()
>>> c.update({'a': 10, '1k': 1024})
>>> c
{'a': 10, 'b': [42], '1k': 1024}
>>> c['b'].append(None)
>>> c
{'a': 10, 'b': [42, None], '1k': 1024}
>>> d
{'a': 1, 'b': [42, None]}
Словарь c получил свою собственную структуру и его обновление не затронуло оригинальный словарь d. Однако изменение объекта списка по ссылке затронуло и оригинал, потому что при копировании словаря ссылка на список тоже скопировалась!
'''

#@ Очистка словаря.

'''
Списки мы можем очистить с помощью присваивания срезу (l[:] = []). В случае словаря вместо присваивания срезу используется метод clear:

>>> d = {'a': 1}
>>> d.clear()
>>> d
{}
Метод clear очищает словарь "по месту", конечно же.


#@@@ src/solution.py
Цель упражнения — функция count_all. Эта функция должна принимать на вход iterable источник и возвращать словарь, ключами которого являются элементы источника, а значения отражают количество повторов элемента в коллекции-источнике. Вот пара примеров, демонстрирующих то, как функция должна работать:

>>> count_all(["cat", "dog", "cat"])
{"cat": 2, "dog": 1}
>>> count_all("hello")
{'h': 1, 'e': 1, 'l': 2, 'o': 1}
>>> count_all("*" * 20)
{'*': 20}
'''

def count_all(items):
    counters = {}
    for item in items:
        counters[item] = counters.get(item, 0) + 1
    return counters



# >>>>>> Инициализация новых значений и defaultdicts <<<<<<

'''
Представьте ситуацию: вам нужно хранить в словаре в качестве значений что-нибудь мутабельное, скажем, списки. И вот в процессе работы с таким словарём вы попадаете в ситуацию, когда у вас есть ключ и элемент для добавления в список-значение, но — вот ведь незадача — ключ пока в словаре не представлен. Приходится писать подобный код:

if key not in dictionary:
    dictionary[key] = []  # инициализируем список
dictionary[key].append(value)  # изменяем список
Подобная ситуация встречается не так уж и редко. Это понимали и авторы стандартной библиотеки Python и дали словарю метод setdefault. Вышеупомянутый код можно переписать с использованием этого метода:

dictionary.setdefault(key, []).append(value)
Компактно и лаконично! Но что же делает метод setdefault? Метод принимает ключ и значение по умолчанию и возвращает ссылку на значение в словаре, связанное с указанным ключом. А если ключ в словаре отсутствует, то метод помещает по ключу то самое значение по умолчанию и возвращает ссылку на него!

В примере выше значением по умолчанию выступает пустой список [].
'''

#@ defaultdict

'''
В стандартной поставке Python присутствует модуль collections. Этот модуль, помимо прочего, предоставляет тип defaultdict. defaultdict — это во всех отношениях обычный словарь, но обладающий одним уникальным свойством: там, где словарь "ругается" на отсутствие ключа, defaultdict сам возвращает значение по умолчанию. Давайте рассмотрим пример:

>>> from collections import defaultdict
>>> d = defaultdict(int)
>>> d['a'] += 5
>>> d['b'] = d['c'] + 10
>>> d
defaultdict(<class 'int'>, {'a': 5, 'c': 0, 'b': 10})
При создании словаря я указал в качестве аргумента функцию int. Если эту функцию вызвать без аргументов, то она вернёт 0 и именно этот вызов внутри словаря d и происходит всякий раз, когда нужно получить значение для несуществующего ключа. Поэтому d['a'] += 5 даёт в итоге 5, т.к. сначала для ключа 'a' создаётся начальное значение (делается вызов int() и получается 0), а потом к нему прибавляется 5. В строчке d['b'] = d['c'] + 10 создаются значения для ключей 'b' и 'c' и затем уже по ключу 'b' записывается сумма 0 + 10.

Вот ещё один пример — на этот раз с самодельной функцией-инициализатором:

>>> def new_value():
...     return 'foo'
>>> x = defaultdict(new_value)
>>> x[1]
'foo'
>>> x['bar']
'foo'
>>> x
defaultdict(<function new_value at 0x7f2232cf5a60>, {1: 'foo', 'bar': 'foo'})
Если отбросить немного непонятное упоминание функции-инициализатора, видно, что по всем ключам, по которым я обращался к содержимому словаря, теперь записаны строки 'foo'.
'''

#@ Отличия defaultdict от обычного словаря c setdefault

'''
Зачем же иметь оба способа, если они настолько похожи, спросите вы. Но давайте сравним эти две строки:

a.setdefault(key, []).append…
# vs
b[key].append…

# b это defaultdict(list)
Строки очень похожи, но если во втором случае новый список создаётся только тогда, когда ключ не будет найден, то в первой строчке объект пустого списка будет создаваться каждый раз. Конкретно затратами на создание пустого списка можно пренебречь. Однако, если вдруг затраты на создание значения по умолчанию окажутся велики, скажем, каждое создание потребует хождения в базу данных, то вариант с defaultdict сразу же окажется гораздо более предпочтителен!

Зачем же вообще использовать setdefault? Например для того, чтобы по разным ключам инициализировать разные значения! Т.к. значение по-умолчанию передаётся каждый раз, мы можем по разным ключам хранить даже разные типы данных. С defaultdict у нас нет контроля над тем, какие значения по каким ключам класть: функция-инициализатор вызывается каждый раз одна и та же и ключ в неё не передаётся.

Наконец всегда остаются редкие случаи, когда и defaultdict не подходит, потому что нужно инициализировать значения по-разному, но не подходит и setdefault — новые значения иммутабельны и их не получится изменить по возвращаемой ссылке. Пример такого случая (вместе с решением задачи ненахождения ключа):

x['count'] = x.get('count', 0) + 1
x['path'] = x.get('path', '') + '/' + dir
Да, здесь присутствуют лишние хождения по одному и тому же ключу, но сам код читается неплохо и в данной ситуации, можно сказать, оптимален!
'''

'''
#@@@ src/solution.py
Цель упражнения — функция collect_indexes. Эта функция должна принимать на вход коллекцию (некий iterator/iterable) и возвращать словарь (или подобная ему коллекция!), где ключом будет элемент коллекции, а значением для ключа — список индексов коллекции, по которым встречается этот элемент.

Пример
>>> d = collect_indexes("hello")
>>> d["h"]
[0]
>>> d["e"]
[1]
>>> d["l"]
[2, 3]
'''
from collections import defaultdict


def collect_indexes(items):
    result = defaultdict(list)
    for index, item in enumerate(items):
        result[item].append(index)
    return result


# >>>>>> Множества <<<<<<

'''
Вы уже знаете, что ключи словаря хранятся в нём в единственном экземпляре. Добавление нового значения по существующему ключу заменяет старое значение. Такое свойство "хранения в единственном экземпляре" часто бывает полезно и в тех случаях, когда нам интересно хранить не столько значения по ключам, сколько именно сами ключи.

Например, мы можем захотеть хранить перечень городов, которые посетил каждый пользователь программы. При этом хочется для каждого города иметь ровно одну отметку о посещении на одного пользователя — это и память позволит сэкономить и поиск упростит. Также нам может понадобиться узнать, какие города посетили и Вася и Маша, а какие — только Маша (или только Вася). В математике для решения такого рода задач — хранения перечня элементов в неких наборах и сопоставления этих наборов между собой — служат множества. Python же, в свою очередь, предоставляет одноимённую структуру данных — set ("множество" на английском).

Итак, множества Python — это неупорядоченные последовательности элементов, каждый из которых в множестве представлен ровно один раз.
'''

#@  Создание множеств и манипуляция над ними

'''
Множество можно создать с помощью соответствующего литерала:
>>> s = {1, 2, 3, 2, 1}
>>> s
{1, 2, 3}
>>> type(s)
<class 'set'>

Литералы множеств записываются с применением фигурных скобок, как и литералы словарей. Однако внутри скобок через запятую перечисляются только "ключи" — элементы множества. Т.к. литерал {} уже занят словарями, пустое множество создаётся вызовом функции set без аргументов:

>>> set()
{}
>>> type(set())
<class 'set'>

Эту же функцию можно использовать, чтобы создать множество из элементов произвольного iterable или iterator:

>>> set('abracadabra')
{'c', 'd', 'a', 'r', 'b'}
>>> set([1, 2, 3, 2, 1])
{1, 2, 3}

Заметьте, что в множестве каждый уникальный элемент представлен ровно один раз, даже если в коллекции-источнике были повторы!
'''

#@ Проверка на вхождение

'''
Чтобы проверить, является ли некое значение элементом множества — или, как ещё говорят, "входит в множество", "принадлежит множеству" — нужно использовать оператор in:

>>> 42 in set()
False
>>> 42 in set([42])
True
>>> 'a' in set('abracadabra')
True

Позже вы узнаете, как это работает, но уже сейчас я могу вам сказать: проверка на вхождение в множество выполняется очень быстро, гораздо быстрее, чем проверка на вхождение в строку, кортеж или список! Так же быстро работает поиск ключа в словаре — и словарь и множество используют один механизм хранения и поиска ключей. И если на небольших коллекциях это не так заметно, то уже при наличии пары десятков элементов и в условиях, когда проверка на вхождение делается часто, разница может быть колоссальной — имейте это в виду!


#@@@ src/solution.py
Вам предстоит реализовать функцию all_unique, которая должна принимать итератор (в т.ч. и те, которые не перезапускаемые!) и возвращать True, если элементы в итераторе не повторяются (если элементов нет, то ничего не повторяется!). Пример работы функции:

>>> all_unique("cat")
True
>>> all_unique([1, 2, 3])
True
>>> all_unique([1, 2, 1])
False
'''

def all_unique(iterable):
    items = list(iterable)
    return len(items) == len(set(items))



# >>>>>> Множества <<<<<<

#@ Изменение состава элементов множества

'''
Множества в Python — мутабельные. Добавлять и удалять элементы из множества можно с помощью методов add, discard и remove:
>>> s = set()
>>> s.add(1)
>>> s.add(2)
>>> s.add(2)
>>> s
{1, 2}
>>> s.discard(1)
>>> s
{2}
>>> s.discard(1)
>>> s
{2}
>>> s.remove(1)
...
KeyError: 1

При чтении кода в этом примере вы должны были заметить, что добавление лишних элементов с помощью add и отбрасывание несуществующих с помощью discard не приводят к ошибке. Такие вот множества терпеливые! Однако вызов метода remove с несуществующим элементом приводит к ошибке.
'''

#@ Копирование и очистка множеств

'''
Так как множества мутабельны, часто возникает необходимость сделать копию перед изменением оригинала. Т.к. множества как и словари не поддерживают операцию получения среза, для копирования приходится использовать метод copy, создающий поверхностную копию множества:

>>> s1 = {1, 2, 3}
>>> s2 = s1.copy()
>>> s1 is s2
False
>>> s1 == s2
True
>>> s2.add(4)
>>> s1 == s2
False
>>> s2
{1, 2, 3, 4}

Очистить же множество без пересоздания можно с помощью метода clear:

>>> s = set("foobar")
>>> s
{'f', 'a', 'r', 'o', 'b'}
>>> s.clear()
>>> s
set()


#@@@
src/solution.py
В этой практике вы будете реализовывать функции для работы с множествами, как с наборами флагов.

Флаги удобны для управления работой некоторого кода: если флаг поднят, значит какая-то возможность включена. В этом плане флаги похожи на галочки в формах и бланках — галочку тоже можно поставить или не поставить.

В нашем случае флаги будут представлять собой элементы множества: если элемент в множестве присутствует, значит и флаг поднят. Вам же нужно будет реализовать две функции: toggle и toggled.

Функция toggle
Эта функция должна принимать флаг и множество в качестве аргументов. Если флаг уже присутствует в множестве, его нужно из множества убрать. Если же флаг отсутствует, то его нужно добавить. Таким образом функция будет переключать состояние флага. Множество нужно заменять "по месту", возвращать из функции ничего не нужно. Пример использования функции toggle:

>>> READ_ONLY = 'read_only'
>>> flags = set()
>>> toggle(READ_ONLY, flags)
>>> READ_ONLY in flags
True
>>> toggle(READ_ONLY, flags)
>>> READ_ONLY in flags
False
Функция toggled
Эта функция работает похожим на toggle образом, но вместо изменения исходного множества возвращает новое — с уже переключенным флагом. Пример:

>>> READ_ONLY = 'read_only'
>>> flags = set()
>>> new_flags = toggled(READ_ONLY, flags)
>>> READ_ONLY in flags
False
>>> READ_ONLY in new_flags
True
'''
def toggle(flag, flag_set):
    if flag in flag_set:
        flag_set.discard(flag)
    else:
        flag_set.add(flag)


def toggled(flag, flag_set):
    new_set = flag_set.copy()
    toggle(flag, new_set)
    return new_set




# >>>>>> Операции над множествами <<<<<<

'''
Создавать и модифицировать множества вы уже научились. Но если этим ограничиться, то может показаться, что множества не сильно-то и отличаются от списков — да, они позволяют быстрее проверить вхождение элемента, но зато не поддерживают механизм срезов. Так вот, наибольшую пользу приносят именно богатство и мощь средств по сопоставлению множеств!
'''

#@ Проверка на равенство

'''
Давайте проверим два множества на равенство:
>>> set([1, 2, 3, 2, 1]) == {3, 1, 2}
True

Вы могли бы подумать, что два множества равны, если каждый отдельный элемент одного множества содержится и во втором, и ваша догадка была бы близка к истине. Но вспомним, что коллекции в Python хранят только ссылки на объекты. Так что же, множества равны, если ссылаются на одни и те же объекты? Одинаковые ссылки "равны" — это правда. Но могут быть и равны разные объекты!

Дело в том, что в Python есть специальный протокол проверки на равенство. Большинство встроенных типов данных поддерживает этот протокол. Мы можем проверять на равенство числа, строки, булевы значения. А ещё можем приравнивать кортежи, списки, словари. И вот тут Python поступает очень разумно: если вы приравняете две коллекции одного типа, то эти коллекции будут считаться равными, если их элементы попарно равны (с точки зрения протокола, опять же). Посмотрите:

>>> [1, 2, ["foo", "bar"]] == [1, 2, ["foo"] + ["bar"]]
True
>>> (1, True, []) == (1, True, [])
True
>>> {"a": 1, "b": 2} == {"b": 2, "a": 1}
True

Словари равны, если порядок ключей разный — лишь бы были равны значения по соответствующим ключам и сами наборы ключей были одинаковыми!

Вот и множества равны, если содержат одинаковые наборы равных попарно элементов.
'''

#@ Объединение множеств

'''
Множества в Python, по аналогии с множествами в математике, поддерживают операцию объединения (union). Эта операция не объединяет множества, как могло бы показаться, но возвращает такое множество — новый объект — которое содержит все элементы, содержащиеся хотя бы в одном из оригинальных множеств. По смыслу объединение похоже на операцию "ИЛИ" из булевой логики: элемент будет присутствовать в объединении, если он присутствует в первом исходном множестве ИЛИ во втором. Для объединения множеств в Python используется оператор |:

>>> visited_by_masha = {'Paris', 'London'}
>>> visited_by_kolya = {'Moscow', 'Paris'}
>>> visited_by_kolya | visited_by_masha
{'London', 'Moscow', 'Paris'}
'''


#@ Пересечение множеств

'''
Раз есть операция, похожая на "ИЛИ", то логично было бы предположить, что есть и "операция И" ("Ы"?). Да, есть и такая — пересечение (intersection) множеств. В пересечение входят элементы, присутствующие в первом из оригинальных множеств И во втором. Оператор пересечения — &. Пример:

>>> visited_by_masha = {'Paris', 'London'}
>>> visited_by_kolya = {'Moscow', 'Paris'}
>>> visited_by_kolya & visited_by_masha
{'Paris'}
'''

#@ Разность множеств

'''
Разность (difference) множеств — такое множество, элементы которого содержатся в первом оригинальном множестве, но не содержатся во втором. Разность представлена оператором - (уж очень смысл похож на вычитание из арифметики). Пример:

>>> visited_by_masha = {'Paris', 'London'}
>>> visited_by_kolya = {'Moscow', 'Paris'}
>>> visited_by_masha - visited_by_kolya
{'London'}
>>> visited_by_kolya - visited_by_masha
{'Moscow'}
'''

#@ Симметрическая разность

'''
Симметрическая разность (symmetric difference) — множество, в которое входят элементы, присутствующие ЛИБО в первом, ЛИБО во втором оригинальном множестве. По смыслу операция похожа на исключающее ИЛИ (xor), поэтому и представлена оператором ^. Пример:

>>> visited_by_masha = {'Paris', 'London'}
>>> visited_by_kolya = {'Moscow', 'Paris'}
>>> visited_by_kolya ^ visited_by_masha
{'London', 'Moscow'}
'''

#@ Подмножества и надмножества

'''
Одно множество является подмножеством (subset) другого, если все элементы первого входят во второе, но второе может содержать ещё и другие элементы. Второе в этом случае является надмножеством (superset) для первого. Такое соотношение множеств можно проверить с помощью методов issubset и issuperset:

>>> a = {1, 2, 3, 4}
>>> b = {3, 4}
>>> b.issubset(a)
True
>>> a.issuperset(b)
True

Забавный факт: равные множества являются друг для друга одновременно и подмножествами и надмножествами.


#@@@ src/solution.py

В этом упражнении вам предстоит анализировать изменения, имея старую и новую версии словаря. Требуется реализовать функцию diff_keys, которая должна принимать два словаря-аргумента — "старый" и "новый" — и возвращать словарь с результатами анализа. Результирующий словарь должен содержать строго три ниже перечисленных ключа:

'kept' — множество ключей, которые присутствовали в старом словаре и остались в новом;
'added' — множество ключей, которые отсутствовали в старом словаре, но появились в новом;
'removed' — множество ключей, которые присутствовали в старом словаре, но в новый не вошли.
Пример
>>> diff_keys({'name': 'Bob', 'age': 42}, {})
{'kept': set(), 'added': set(), 'removed': {'name', 'age'}}
>>> diff_keys({}, {'name': 'Bob', 'age': 42})
{'kept': set(), 'added': {'name', 'age'}, 'removed': set()}
>>> diff_keys({'a': 2}, {'a': 1})
{'kept': {'a'}, 'added': set(), 'removed': set()}
Заметьте, значения не сравниваются — только ключи!
'''

def diff_keys(old, new):
    old_keys = set(old.keys())
    new_keys = set(new.keys())
    return {
        'kept': old_keys & new_keys,
        'added': new_keys - old_keys,
        'removed': old_keys - new_keys,
    }


# >>>>>> Методы объектов множеств <<<<<<

#@ Операции над множествами как методы

'''
Вы уже узнали об операторах, позволяющих различными способами комбинировать множества. Эти операторы максимально похожи на те, что применяются в теории множеств в математике и эта похожесть — очень важное свойство. С теорией множеств любой уважающий себя программист должен познакомиться хотя бы поверхностно — это тот самый пресловутый "фундамент". Поэтому лично я придерживаюсь мнения, что множества нужно использовать в сочетании с операторами.

Однако умолчать о том, что у каждого оператора есть и "словесный" метод-аналог, было бы неправильно. Так что знакомьтесь, методы:
'''

a.union(b)                 # аналог "a | b"
a.intersection(b)          # аналог "a & b"
a.difference(b)            # аналог "a - b"
a.symmetric_difference(b)  # аналог "a ^ b"

#@ Обновление множеств "по месту"

'''
Есть ещё одна причина, по которой я рассказал про те четыре метода выше. Помните, мы рассматривали метод update у словаря, обновляющий словарь "по месту" с помощью данных из другого словаря? Так вот, для множеств таких update-методов несколько.
'''

#@ Метод difference_update

'''
difference_update работает похоже на -/difference, а именно — удаляет из связанного множества все элементы, которые входят в множество-аргумент:

>>> a, b = {1, 2}, {2, 3}
>>> a.difference_update(b)
{1}
'''

#@ Метод intersection_update

'''
intersection_update (мутирующий аналог &/intersection) оставляет в связанном множестве только те элементы, которые входят и в множество-аргумент:
>>> a, b = {1, 2}, {2, 3}
>>> a.intersection_update(b)
>>> a
{2}
'''

#@ Метод symmetric_difference_update

'''
symmetric_difference_update (мутирующий аналог ^/symmetric_difference) добавляет в связанное множество элементы, которые есть только в множестве-аргумента, и удаляет элементы, которые есть в обоих множествах:

>>> a, b = {1, 2}, {2, 3}
>>> a.symmetric_difference_update(b)
>>> a
{1, 3}
'''

#@ Метод update

'''
update (мутирующий аналог |/union) дополняет связанное множество отсутствующими элементами из множества-аргумента:

>>> a, b = {1, 2}, {2, 3}
>>> a.update(b)
>>> a
{1, 2, 3}

Метод update с точки зрения единообразия надо было бы назвать union_update, но выбрали более распространённое имя update, т.к. это имя часто используется для сходных по смыслу методов других коллекций.



#@@@ src/solution.py

Цель упражнения — функция apply_diff. Эта функция принимает два аргумента, первым из которых выступает множество, которое нужно будет изменять "по месту" (возвращать ничего не нужно). Вторым аргументом функция принимает словарь, который может содержать ключи 'add' и 'remove' с множествами в качестве значений. Значения по ключу 'add' нужно добавить в изменяемое множество, а значения по ключу 'remove' — убрать из множества. Прочие ключи в переданном словаре значения не имеют и обрабатываться не должны.

Пример
>>> target = {'a', 'b'}
>>> diff = {'add': {'c'}, 'remove': {'a'}}
>>> apply_diff(target, diff)
>>> target
{'c', 'b'}
Подсказка
Не используйте методы add и discard. В этом упражнении нужено манипулировать множествами "целиком".
'''

def apply_diff(set_for_update, diff):
    for k, v in diff.items():
        if k == 'add':
            set_for_update.update(v)
        elif k == 'remove':
            set_for_update.difference_update(v)





############### Python: Функции ###############

#@ О курсе
'''
Функции — мощный инструмент с широкими возможностями. До сих пор мы сталкивались с самыми простыми видами функций — именованными функциями. Кроме них в Python есть анонимные функции, значительно расширяющие выразительные возможности языка.

При описании и вызове функций мы пользовались в основном позиционными аргументами — такими аргументами, которые передаются в функцию в строго определённом порядке. Однако помимо позиционных Python позволяет функциям иметь и именованные аргументы. А ещё функции в Python могут принимать переменное кол-во аргументов. Или все аргументы скопом внутри объекта-коллекции.

Ранее говорилось, что функции в Python — объекты первого класса (first class objects), т.е. могут быть переданы и приняты по ссылке и даже сконструированы "на лету". В этом курсе мы рассмотрим работу с такими функциями поподробнее. А ещё вы узнаете об интересной и мощной концепции декораторов, позволяющей делать с функциями множество интересных вещей.

Основные понятия курса:

Позиционные аргументы
Именованные аргументы
Переменное кол-во аргументов
Объекты первого рода
Анонимные функции
Декораторы
Функции высших порядков (map/filter/reduce)
'''




# >>>>>> Позиционные аргументы <<<<<<


'''
Функции, которые вы видели до этого, в основном имели позиционные аргументы. При вызове функций значения в такие аргументы подставляются согласно позиции имён аргументов в определении функции. Так, при вызове функции

def add(x, y)
    return x + y
с аргументами (10, 20) аргумент x получит значение 10, а y — 20.
'''

#@ Переменное количество аргументов.

'''
Использование позиционных аргументов выглядит просто, максимально похоже на использование функций в математике, и довольно удобно... пока вам не потребуется реализовать функцию, принимающую произвольное кол-во аргументов!

Вспомните, известная вам функция print принимает столько аргументов, сколько вы ей передадите. Она делает полезную работу даже тогда, когда вы вызываете её вообще без аргументов! Как же мы можем научить нашу собственную функцию так же терпимо относиться к кол-ву аргументов? Потребуется специальный синтаксис:

>>> def f(*args):
...     print(type(args))
...     print(args)
...
>>> f()
tuple
()
>>> f(1, 'a', None, False)
tuple
(1, 'a', None, False)

Здесь в заголовке функции (так называют строчку, в которой описываются имя функции и её аргументы) указан ровно один аргумент args, но записанный со звёздочкой впереди. Звездочка означает "эта переменная получит в виде кортежа все аргументы, от текущей позиции и до конца". Из чего следует, что такой "прожорливый" аргумент может быть только один (первый же "прожорливый" аргумент съест всё) и может располагаться только в конце списка аргументов (иначе последующим аргументам не достанется значений). А ещё пример показывает, что *args нормально переживает и отсутствие аргументов, обычные же аргументы всегда обязательны. Рассмотрим же пример посложнее:

>>> def greet(name, *args):
...     for n in (name,) + args:
...         print('Hello, {}!'.format(n))
...
>>> greet('Tom', 'Ann')
Hello, Tom!
Hello, Ann!
>>> greet()
…
TypeError: greet() missing 1 required positional argument: 'name'
Здесь функция принимает несколько аргументов, но как минимум один аргумент должен быть передан всегда. Этот первый аргумент станет значением переменной name, а остальные сохранятся в *args. Подобным образом можно делать любое нужное кол-во обязательных аргументов.
'''

#@ Передача аргументов в форме коллекции.

'''
Иногда хочется сначала сформировать набор аргументов, а потом передать их функции. Скажем, прочитать аргументы из файла или получить каким-то другим программным способом. Здесь нам опять пригодится звёздочка:

…
>>> names = ['Tom', 'Ann']
>>> greet(*names)
Hello, Tom!
Hello, Ann!

Более того, часть аргументов можно передавать непосредственно и даже коллекции подставлять не только по одной:

…
>>> greet(
...    'Bob', *['Mary', 'Clair'], 'Sam',
...    *('Henry', 'John')
... )
Hello, Bob!
Hello, Mary!
Hello, Clair!
Hello, Sam!
Hello, Henry!
Hello, John!
'''

#@ Соглашения об именовании *args.

'''
Напоследок отмечу, что среди питонистов принято называть упомянутый аргумент именно *args (от слова "arguments"). Старайтесь придерживаться этого соглашения и вы.



#@@@ src/solution.py
Вам нужно реализовать функцию greet, которая должна принимать несколько имён (как минимум одно!) и возвращать строку приветствия (см. примеры ниже).

Примеры
>>> greet('Bob')
'Hello, Bob!'
>>> greet('Moe', 'Mary')
'Hello, Moe and Mary!'
>>> greet(*'ABC')
'Hello, A and B and C!'
Подсказка
При решении вам может пригодиться метод join у объекта строки. Работает он так:

>>> ','.join(['A', 'B', 'C'])
'A,B,C'
>>> ','.join(['A'])
'A'
>>> ''.join(['Hello', 'World'])
'HelloWorld'
'''

def greet(who, *args):
    names = ' and '.join((who,) + args)
    return 'Hello, {}!'.format(names)




# >>>>>> Именованные аргументы <<<<<<

'''
До этого момента мы вызывали функции в основном с позиционными аргументами. Но в Python функции могут иметь ещё и именованные аргументы (keyword arguments). Что же это такое? Узнаем, взглянув на следующий пример:

>>> def bar(length, char1, char2):
...     return (char1 + char2) * length + char1
...
>>> print(bar(5, '-', '*'))
-*-*-*-*-*-


Функция bar имеет три аргумента. Вызов функции тоже выглядит довольно понятно. Теперь предположим, что char1 и char2 чаще всего получают одни и те же значения. В такой ситуации удобно указать значения по умолчанию:

>>> def bar(length, char1='-', char2='*'):
...     return (char1 + char2) * length + char1
...
>>> print(bar(5))
-*-*-*-*-*-
>>> print(bar(3, '.'))
.*.*.*.
>>> print(bar(2, ':', '|'))
:|:|:

Выглядит удобно. Но что делать, если нас устраивает значение по умолчанию для char1, но мы хотим изменить задать свой вариант char2? Придётся указывать оба? Не придётся, ведь за редким исключением любой позиционный аргумент может быть указан по имени:

>>> print(bar(4, char2='#'))
-#-#-#-#-
>>> print(bar(char2='$', length=3))
-$-$-$-

Во втором вызове я даже порядок аргументов перепутал и ничего не сломалось! Да, именованные аргументы обладают таким свойством: порядок именованных аргументов не имеет значения!

Однако имеет значение порядок групп аргументов: позиционные значения должны быть указаны до любых именованных! Иначе вы получите ошибку SyntaxError: positional argument follows keyword argument.

Также в том случае, когда функция имеет позиционные аргументы без значений по умолчанию, значения для этих аргументов обязательно должны быть указаны так или иначе — либо в виде позиционных значений, либо в виде именованных. Нарушение этого правила приведёт к ошибке вида:

>>> bar(char2='!')
…
TypeError: bar() missing 1 required positional argument: 'length'
'''

#@ Когда стоит применять именованные аргументы?

'''
Каких-то строгих правил на этот счёт не существует. Однако широко практикуется такой подход: если функция принимает больше трёх аргументов, нужно хотя бы часть из них указать по имени. Особенно важно именовать значения аргументов, если несколько значений имеют одинаковый тип. Потому что очень трудно понять, что делает функция с подобным вызовом:
'''

make('circle', 300, 150, 10, None, 2.5, False)

# Сравните с этим:

make(
    shape='circle',
    x=300, y=150, radius=10,
    line_pattern=None,
    line_width=2.5,
    fill=False
)

'''
Такой код читать значительно проще!

Конечно, у вышеупомянутого правила есть пара исключений. Первое: функции, назначение которых очевидно. Да, очевидность относительна, но всё же обычно довольно легко понять, что скрывается за значениями в вызове point3d(10, 50, 21) или rgb(0, 255, 0). Тут, увы, работает только здравый смысл.

Во-вторых, нет ни смысла, ни возможности, указать по именам аргументы, объявленные через "звёздочку":

>>> def sum(*args):
...     …
...
>>> sum(x1=1, x2=2)
…
TypeError: sum() got an unexpected keyword argument 'x1'

В таких функциях имя args недоступно извне, ведь это не один аргумент, а получатель произвольного их количества.


#@@@ src/solution.py
В этом упражнении вам нужно будет, используя функцию rgb, реализовать функцию get_colors, которая должна вернуть словарь цветов (о цветовой модели RGB вы можете почитать тут). В словаре должны присутствовать ключи 'red', 'green', 'blue'. Каждому ключу должен соответствовать результат вызова функции rgb со значением 255 для соответствующего ключу аргумента. Для построения каждого цвета используйте только один аргумент!

Пример
>>> colors = get_colors()
>>> set(colors.keys()) == {'red', 'green', 'blue'}
True
>>> colors['red']
'rgb(255, 0, 0)'
>>> colors['blue']
'rgb(0, 0, 255)'
'''
def rgb(red=0, green=0, blue=0):
    return 'rgb({}, {}, {})'.format(red, green, blue)

def get_colors():
    return {
        'red': rgb(red=255),
        'green': rgb(green=255),
        'blue': rgb(blue=255),
    }



# >>>>>> Больше об именованных аргументах <<<<<<

#@ Получение именованных аргументов в виде словаря

'''
Позиционные аргументы можно получать в виде *args, причём произвольное их количество. Для именованных аргументов существует подобная возможность. Только именованные аргументы получаются в виде словаря, что позволяет сохранить имена аргументов в ключах:

>>> def f(**kwargs):
...     return kwargs
...
>>> f(x=1, y=2, z=None)
{'x': 1, 'y': 2, 'z': None}
По соглашению аргумент, получающий подобный словарь, принято называть kwargs от словосочетания "keyword arguments".

Аргумент *args в определении функции пишется после всех обычных позиционных аргументов перед первым аргументом со значением по умолчанию, а **kwargs пишется в самом конце, после последнего аргумента со значением по умолчанию. Давайте определим функцию, которая принимает все виды аргументов:

>>> def f(x, y, *args, kx=None, ky=42, **kwargs):
...     return (x, y, args, kx, ky, kwargs)
...
>>> f(1, 2, 3, 4, kx='a', ky='b', kz='c')
(1, 2, (3, 4), 'a', 'b', {'kz': 'c'})
Не нужно пугаться, в реальном коде редко какая функция использует все эти возможности одновременно! Но понимать, как каждая отдельная форма объявления аргументов работает и как такие формы можно сочетать — очень важно!
'''

#@ Передача именованных аргументов с помощью словаря

'''
Как и в случае позиционных аргументов, именованные можно передавать в функцию "пачкой" в виде словаря. Для этого нужно перед словарём поставить… две звёздочки! Пример:

>>> def coords(x, y):
...     return (x, y)
...
>>> coords(x=1, **{'y': 2})
(1, 2)

Как вы видите, я и обычный именованный аргумент указал, и развернул в аргументы словарь — так тоже можно и это даже удобно! Попробуем функцию f из примера в начале урока вызвать с двумя наборами аргументов — одним для позиционных и вторым для именованных:

>>> positional = (2, 3)
>>> named = dict(ky='b', kz='c')
>>> f(1, *positional, 4, kx='a', **named)
(1, 2, (3, 4), 'a', 'b', {'kz': 'c'})

Обратите внимание на то, как я сконструировал словарь: я не написал литерал, а вместо этого вызвал функцию dict с несколькими именованными аргументами — так словарь ещё больше похож на "сохранённый набор аргументов"!

Также отметьте, что при подстановке аргументов "разворачивающиеся" наборы аргументов вроде *positional и **named можно указывать вперемешку с аргументами соответствующего типа: *positional с позиционными, а **named — с именованными. И конечно же, все именованные аргументы должны идти после всех позиционных!
'''

#@ Keyword-only аргументы

'''
В Python 3 добавили возможность пометить именованные аргументы функции так, чтобы вызывать функцию можно было, только передав эти аргументы по именам. Такие аргументы называются keyword-only и их нельзя передать в функцию в виде позиционных. Выглядит функция с подобными аргументами так:

>>> def open_file(name, *, writable=False, binary=False):
...     …
...
>>> f1 = open_file('foo.txt', writable=True)
>>> f2 = open_file('bar.bin', binary=True)
>>> f3 = open_file('raw.dat', True, True)
…
TypeError: open_file() takes 1 positional argument but 3 were given

Здесь * выступает разделителем: отделяет "обычные" аргументы (их можно указывать и по имени и позиционно) от "строго именованных". Такой разделитель можно использовать только один раз в одном определении. А ещё его нельзя применять в функциях с *args — да, не очень логично, но так уж вышло. Зато можно объявлять функции, у которых будут только строго именованные аргументы, для этого нужно поставить звёздочку в самом начале перечня аргументов.

Этот пример неплохо демонстрирует подход к описанию аргументов. Первый аргумент — имя файла, который будет открыт. Имя файла всегда присутствует, ведь нужно же что-то открыть, и связано по смыслу с именем функции. Поэтому этот аргумент можно не именовать. А вот writable и binary — необязательные аргументы. Которые получают ещё и ничего не говорящие значения True/False. Вполне логично ожидать, что вызов вида open_file('raw.dat', True, True) мало кому понравится! Поэтому опции и объявлены так, что могу быть указаны только явно.

#@@@ src/solution.py
Цель данного упражнения — функция updated. Эта функция должна принимать словарь в качестве единственного позиционного аргумента (обязательного) и произвольное кол-во именованных аргументов. Возвращать же функция должна новую версию словаря, в котором ключи, соответствующие именованным аргументам, должны иметь сопутствующие значения (см.примеры).

Примеры
>>> d = {'a': 1, 'b': False}
>>> updated(d, a=2, b=True, c=None)
{'a': 2, 'b': True, 'c': None}
>>> d
{'a': 1, 'b': False}
>>> updated(d) == d
True
>>> updated(d) is d
False
'''

def updated(dictionary, **kwargs):
    new = dictionary.copy()
    new.update(kwargs)
    return new



# >>>>>> Функции высшего порядка <<<<<<

'''
Вы помните, что в Python всё есть объект. А значит всё может быть передано и получено по ссылке. Это же касается и функций. В языках, где функции можно принимать и передавать в качестве значений, функции называются гражданами первого сорта (first-class citizen). А функции, которые принимают в качестве аргументов другие функции и/или возвращают оные в качестве результата, принято называть функциями высшего порядка (или же функциями высших порядков, ФВП, high-order functions).

Функции первого порядка принимают и возвращают "обычные" значения, т.е. не функции.

Давайте реализуем простейшую функцию высшего порядка:

>>> def call_with_five(function):
...     return function(5)
...
>>> def add_one(x):
...     return x + 1
...
>>> call_with_five(add_one)
6

Здесь функция call_with_five принимает другую функцию на входе и возвращает результат вызова оной с аргументом 5.

Усложним пример — добавим ещё и возврат функции:

>>> def double(function):
...     def inner(argument):
...         return function(function(argument))
...     return inner
...
>>> def multiply_by_five(x):
...     return x * 5
...
>>> double(multiply_by_five)(3)
75

В этом примере прямо в теле функции double создаётся функция inner (это имя довольно часто используется для именования функций, создаваемых на лету внутри внешней функции) и возвращается в роли результата. Именно потому, вызов double возвращает функцию, мы можем сразу же сделать второй вызов ((3)), который уже даст нам результат двойного применения исходной функции к аргументу. Но мы могли бы и не вызвать функцию-значение сразу, а вместо этого сохранить в переменную:

>>> multiply_by_25 = double(multiply_by_five)
>>> multiply_by_25
<function double.<locals>.inner at 0x7fd1975c58c8>
>>> multiply_by_25(1)
25
>>> multiply_by_625 = double(multiply_by_25)
>>> multiply_by_625
<function double.<locals>.inner at 0x7fd1968f41e0>
>>> multiply_by_625(1)
625

Заметьте, что при выводе значения ссылки multiply_by_25 отображается double.<locals>.inner — та самая созданная на лету функция inner. И в случае multiply_by_625 функция называется inner, но адрес в памяти имеет другой (большое шестнадцатеричное число после "at")!

# Зачем всё это?

Сейчас вам может показаться, что примеры выше — довольно таки надуманные и не похожи на реально полезный код. Однако не спешите с выводами! ФВП — это очень мощный инструмент в умелых руках. На следующем уроке мы рассмотрим несколько ФВП, очень даже полезных именно с практической точки зрения!
'''


# >>>>>> Знакомство с map, filter, reduce <<<<<<

# Классические ФВП

'''
В этом уроке я расскажу про три примера функций высшего порядка, которые довольно распространены и часто применяются на практике программистами на разных языках.

Заранее отмечу: примеры в данном уроке слегка упрощены. Дело в том, что встроенные в Python версии упоминаемых функций реализованы слегка иначе для обеспечения большей гибкости и производительности. Однако назначение и общий принцип действия простые примеры демонстрируют, на мой взгляд, вполне успешно.
'''

#@ map

'''
При работе со списками часто встаёт задача применить некоторое преобразование (одно и то же) к каждому элементу. Конечно, мы всегда можем написать цикл. Однако этот цикл будет выглядеть практически одинаково практически во всех случаях:
'''

def f(x):
    …

new_list = []
for item in old_list:
    new_item = f(item)
    new_list.append(new_item)

# …
# используем new_list


'''
В таких случаях меняется только применяемая функция f. Так почему бы нам не обобщить этот код так, чтобы функция была параметром? Так и сделаем:
'''

>>> def map(function, items):
...     result = []
...     for item in items:
...         result.append(function(item))
...     return result
>>> map(str, range(5))
["0", "1", "2", "3", "4"]

'''
Функция называется "map", т.е. "отобразить". Название пришло из математики, где точно так же называется функция, которая отображает одно множество значений в другое путём преобразования всех элементов с помощью некоей трансформации (как правило, функции). В большинстве языков также используют это имя.
'''

#@ filter

'''
Часто нужно не столько преобразовать элементы, а просто оставить одни элементы списка, но отбросить другие — согласно некоторому критерию. Во многих языках для решения этой задачи существует функция filter, код которой выглядит очень похоже на код map:

>>> def filter(predicat, items):
...     result = []
...     for item in items:
...         if predicat(item):
...             result.append(item)
...     return result
...
>>> def is_even(x):
...     return x % 2
...
>>> filter(is_even, range(6))
[1, 3, 5]

Наша функция filter применяет предикат к каждому элементу и добавляет в выходной список только те элементы, для которых предикат вернул True.

У функции filter имя более "говорящее" и менее академичное, но такое же популярное — многие языки имеют аналогичную функцию с тем же именем.
'''

#@ reduce

'''
И map, и filter работали с отдельными элементами независимо. Но ведь встречаются и циклы, которые агрегируют результат — формируют результирующее значение, комбинируя элементы между собой с использованием аккумулятора.

Типичными примером агрегации может быть сумма всех элементов списка. Или, скажем, произведение. Представим, что нам нужно сложить элементы списка [1, 2, 3, 4, 5]. С точки зрения математики сумма

1 + 2 + 3 + 4 + 5

может быть выражена как

(((((0 + 1) + 2) + 3) + 4) + 5).

Ноль здесь — тот самый аккумулятор (его начальное состояние). Он не добавляет к сумме ничего, но может служить отправной точкой. А ещё — будет результатом, если входной список пуст.

С помощью цикла мы бы суммировали так:
'''

acc = 0
for item in items:
    acc = acc + item

# А умножали бы так:

acc = 1
for item in items:
    acc = acc * item

'''
Замечаете тенденцию? Циклы отличаются только начальным значением аккумулятора (0 и 1) и операцией, которая комбинирует элемент и аккумулятор (+ и *). Обобщаем!

>>> def reduce(operation, initial_value, items):
...     acc = initial_value
...     for item in items:
...         acc = operation(acc, item)
...     return acc
...
>>> from operator import add, mul
>>> reduce(add, 0, [1, 2, 3, 4, 5])
15
>>> reduce(mul, 1, [1, 2, 3, 4, 5])
120

В примере я использовал функции add и mul из модуля operator. Так вот, это аналоги + и * в виде функций, которые можно использовать в связке с ФВП. Возьмите этот модуль на заметку и поэкспериментируйте с его содержимым!

Функции, называемой в Python reduce не так повезло с именем, как двум предыдущим. Уж как только эту функцию не называют — и inject, и reduce, и aggregate.

И лишь в математике всё однозначно: такая функция называется левая свёртка (left fold). И имя "свёртка" вполне себе говорящее — применяя эту функцию, мы сворачиваем список в одно значение!

А левая наша свёртка потому, что "схлопывать" элементы с аккумулятором мы начинаем слева. Существует ещё и правая свёртка, но в виде встроенной функции в Python она не представлена. Правая свёртка для суммы выглядит так:

(1 + (2 + (3 + (4 + (5 + 0)))))

В большинстве случаев обе свёртки дают одинаковый результат, если применяемая операция ассоциативна (т.е. позволяет расставлять скобки произвольно — как в случае наших сумм). Но через цикл итерации элементов проще реализовать именно левую, поэтому она и используется чаще.
'''
# >>>>>> Знакомство с map, filter, reduce <<<<<<
#@ map/filter/reduce против цикла for

'''
Мы с вами реализовали целые три функции, каждая из которых, имеет меньшую мощность, чем цикл for. Более того, цикл for позволяет гибко управлять процессом итерации с помощью команд break и continue. Зачем же тогда нужны эти отдельные маломощные версии, когда есть одна универсальная?

А нужны эти функции затем, что каждая функция делает ровно одну работу, что значительно упрощает рассуждение о коде, его чтение и написание. С первого взгляда на имя функции мы можем понять, что filter — фильтрует, а map — преобразует элементы, но не наоборот! Более того, по построению filter не меняет элементы, а только лишь отбрасывает их часть. А map меняет значение элементов, но не меняет их количество и позиции. Это знание того, что код сделать не может, дорогого стоит! Имей же мы на руках цикл for, нам бы пришлось (и приходится!) "выполнить код в уме" (как ещё говорят, "поработать интерпретатором"), ведь цикл for может делать что угодно — и менять элементы, и отбрасывать их и агрегировать результат, и даже делать всё это одновременно!

И пусть все случаи применения цикла заменить на функции не получится. Но в тех простых случаях, когда можно достигнуть нужного результата с применением менее мощного и вместе с тем более простого в понимании инструмента — стоит, как минимум, подумать об этой альтернативе!
'''


# >>>>>> Встроенные map, filter, reduce <<<<<<

'''
Все три рассмотренные нами на прошлом уроке ФВП присутствуют в Python "из коробки". При этом map и filter можно использовать сразу, а reduce нужно импортировать из модуля functools.

Сейчас же мы рассмотрим отличия каждой конкретной функции от тех простых вариантов, которые мы реализовали ранее. А начнём мы со свёртки.
'''

#@ functools.reduce

'''
Взглянув на объявление функции, мы увидим

reduce(function, sequence[, initial]) -> value
Здесь стоит обратить внимание на то, что начальное значение аккумулятора — опциональный аргумент ([, initial]). Если его не указать, то reduce будет использовать в качестве начального значения первый элемент последовательности sequence. Но в этом случае нужно помнить, что если последовательность пустая, то вызов reduce завершится с ошибкой!
'''

#@ filter

'''
Теперь взглянем на filter:

filter(function or None, iterable) -> filter object
С function всё понятно, но что делает None в роли предиката? Это замена для условия "всё, что угодно, лишь бы было истинно!". Тот же результат даст фильтрация с bool в качестве результата.

Обратите внимание на возвращаемое значение filter object. Это не список, но итератор. Т.е. встроенный filter — ленивый. Возвращает элементы по одному, если находит подходящие, конечно.
'''

#@ map

'''
Встроенный map отличается от нашей наивной реализации:

map(func, *iterables) --> map object
Здесь map object — тоже итератор. Это понятно. А вот жадный аргумент *iterables принимает несколько итерируемых объектов вместо одного! Если map передать более одного источника элементов, то функция func будет вызвана сначала для всех первых элементов, потом для вторых, и так далее, пока не закончатся элементы хотя бы в одном источнике. Это чем-то похоже на функцию zip, которую я упоминал в курсе по спискам, только zip всегда возвращает кортежи, а map применяет произвольную функцию (от соответствующего числу источников количества аргументов). Вот пример применения функции map к паре источников:

>>> from operator import mul
>>> list(map(mul, "abc", [3, 5, 7]))
['aaa', 'bbbbb', 'ccccccc']

Заметьте, что я обернул вызов map в вызов list, чтобы превратить итератор в список для последующего вывода на экран.
'''

#@ map/filter/reduce и побочные эффекты.

'''
При использовании рассматриваемых "заменителей цикла for" следует руководствоваться одним важным правилом: применяемые с их помощью функции должны по возможности быть чистыми (pure functions).

Функция является чистой, если не производит побочные эффекты (side effects) и возвращает результат, зависящий только от аргументов. Подробно про побочные эффекты мы поговорим в последующих курсах, пока же я дам краткое определение: побочные эффекты — это наблюдаемые последствия вызова функции, не относящиеся к возвращаемому результату.

Если функция печатает что-то в консоль, пишет в файл, посылает по сети — это функция с побочными эффектами. Если вызов функции зависит от внешнего мира (глобальные мутабельные объекты, например), а не только от аргументов — функция, опять же, не чистая!

Чем плохо использование побочных эффектов вместе со, скажем, функцией map? Например тем, что во первых функция возвращает ленивый итератор — а значит эффекты будут происходить не при вызове, а тогда, когда мы будем потреблять элементы!

А ещё побочные эффекты нарушают законы, которые характерны для математических версий map, filter и reduce.
'''

#@ Грязные функции и reduce

'''
При использовании функций с побочными эффектами для правой и левой свёрток перестаёт работать равенство результата: левая свёртка будет производить эффекты для элементов по порядку, а правая — с конца к началу! Даже если возвращаемый из функции результат сойдётся (а в случае функций, зависящих от внешнего мира, даже это может быть неправдой), общий наблюдаемый эффект (например, порядок записанных в файл строк) будет отличаться!
'''

#@ Грязные функции и map

'''
Если мы возьмём грязную функцию, то для map нарушится закон

map(f, map(g, l)) == map(f*g, l)

Здесь в виде f*g я записал (это псевдокод!) композицию функций, т.е. получение функции, делающей x -> f(g(x)). Встроенного оператора для композиции в Python нет, но функция композиции пишется элементарно.

Данный закон очень важен, ведь он позволяет произвести оптимизацию: превратить два прохода по последовательности в один. При использовании же функции с эффектами программа до оптимизации и после неё будет работать по-разному: до оптимизации будут выполнены сначала все эффекты функции g, потом — эффекты функции f, а после оптимизации эффекты g и f будут происходить парами!
'''

#@ Грязные функции и filter

'''
Для filter возможна такая оптимизация:
filter(f, filter(g, l)) == filter(g&f, l)

Здесь g&f, это условное обозначение функции, которая делает x -> g(x) and f(x). Опять же, такого оператора в Python нет, но реализовать подобную функцию очень просто.

В случае filter после оптимизации эффекты тоже "перемешаются", как было описано выше для функции map.
'''

#@ Простое правило

'''
Если вы видите, что в ФВП просится не чистая функция — перепишите на цикл. Мы помним, что цикл у нас мощный и в его теле может происходить что угодно — вот пусть и эффекты происходят в цикле, а не в чистых map/filter/reduce.

И пусть оптимизация согласно законам конкретно во встроенных функциях не делается (пока!), но вы можете натолкнуться на библиотеку, в которой подобные оптимизации будут возможны, или даже сами подобную реализуете! А потом окажется, что сходу понять, почему код после оптимизации работает именно так, практически невозможно. Но ведь функции map/filter/reduce как раз и нацелены на упрощение понимания логики, а мы с помощью грязных функций снова всё запутываем!
'''


# >>>>>> Замыкания <<<<<<


'''
Помните функцию inner, которую мы создавали в первом уроке по ФВП. Так вот, эта функция была замыканием! Замыкание (closure), это такая функция, которая ссылается на локальные переменные (использует их в своём теле) в области видимости, в которой она была создана. Этим замыкание отличается от обычной функции, которая может использовать только свои аргументы и глобальные переменные. Рассмотрим пример, демонстрирующий замыкание, и уже на нём разберём что и чем является:
'''

G = 10

def make_closure():
    a = 1
    b = 2
    def inner(x):
        return x + G + a
    return inner

'''
В этом примере inner — замыкание. Переменная b не используется в теле inner и замыканием запомнена не будет. А вот переменная a, напротив, участвует в формировании результата вызова inner и поэтому её значение будет запомнено. А вот G, это глобальная переменная (если принять факт, что указанный код находится на верхнем уровне модуля, т.е. не вложен ни в какие другие блоки).

Кстати, функции, создаваемые на верхнем уровне модуля, т.е. не внутри каких-либо других функций, замыканиями не являются — им просто нечего замыкать, ведь все видимые таким функциям внешние имена (импорты и другие определения из этого модуля, находящиеся выше по строчкам кода) являются глобальными.
'''

#@ Момент запоминания значений переменных

'''
Отмечу важную особенность: фактическое запоминание значения происходит в тот момент, когда область видимости, в которой было создано замыкание, "заканчивается", например завершается выполнение текущей функции. Проще всего думать, что на момент создания функции замыкаемые переменные сначала записываются в некий список дел в виде пунктов "не забыть запомнить текущее значение переменной xyz", а выполняются эти пункты после завершения тела функции, создавшей замыкание. Вот пример, демонстрирующий это самое позднее запоминание:

>>> def make_closure():
...     y = 1
...     def inner(x):
...         return x + y
...     y = 42
...     return inner
...
>>> make_closure()(100)
142
Здесь inner получает в качестве запомненного значения 42, пусть даже присваивание этого значения переменной y происходит и после объявления функции! Ещё "забавнее" выглядит замыкание переменной цикла:

>>> printers = []
>>> for i in range(10):
...     def printer():
...         print(i)
...     printers.append(printer)
...
>>> printers[0]()
9
>>> printers[5]()
9
>>> printers[9]()
9
>>> i = 42
>>> printers[0]()
42
Казалось бы, мы создали десяток функций, каждая из которых должна печатать своё число, но все функции печатают последнее значение переменной цикла! Здесь тоже фактическое запоминание происходит при выходе из области видимости в которой определена переменная i, вот только эта область видимости на момент вызова замыканий ещё не завершилась (в этом REPL-примере она завершится только при выходе из REPL)! Поэтому после выхода из цикла все замыкания выводят 9, а после изменения значения переменной i выводимое значение также меняется!
'''

#@ Борем замыкания!

'''
Как же запоминать то, что нужно и когда нужно? Как же нам починить пример с циклом, чтобы каждая функция печатала своё значение и не реагировала на дальнейшие изменения переменной цикла? Отвечаю: нужно замкнуть переменную в области видимости, которая завершится сразу же после создания замыкания! Этого можно добиться, завернув создание функции в… другую функцию! Вот код:

>>> printers = []
>>> for i in range(10):
...     def make_printer(arg):
...         def printer():
...             print(arg)
...         return printer
...     p = make_printer(i)
...     printers.append(p)
...
>>> printers[0]()
0
>>> printers[5]()
5
Результат положительный! Но как же этот код работает? Заметьте, в этот раз printer замыкает значение переменной arg, а эта принадлежит функции make_printer и видна только пока выполняется тело функции. А ведь это именно то, что нам нужно: когда происходит выход из тела make_printer, возвращаемое замыкание получает таки своё значение. А раз функция make_printer вызывается с разными аргументами, то и замыкания получают разные значения!

Эта техника "завернуть в функцию и тут же вызвать" не является эксклюзивным для Python "костылём": она применяется и во многих других языках, реализующих механизм замыканий. Например, точно так же поступают программисты на JavaScript.
'''



# >>>>>> Анонимные функции. <<<<<<

'''
Иногда нам нужна функция, чтобы её передать куда-то (в функцию высшего порядка), но больше эта функция нигде не понадобится. Как вы можете знать, придумывание имён в программировании — одна из основных проблем. Но если функция нужна здесь и сейчас, а больше нигде её вызывать не придётся, то и имя такой функции не нужно! Такие одноразовые функции позволяют описывать практически все языки, умеющие работать с функциями как со значениями. В Python определение подобной одноразовой функции выглядит так:

>>> lambda x: x + 1
<function <lambda> at 0x7f56e5798a60>

Мы сконструировали функцию, но имя она не получила, поэтому REPL её отобразил, как function <lambda>.

Ключевое слово lambda названо в честь лямбда абстракции — основного кирпичика Лямбда Исчисления, математического аппарата, часто применяющегося в разработке языков программирования. В Лямбда Исчислении все функции — анонимные, поэтому анонимные функции во многих языках тоже иногда называют "лямбдами" или "лямбда-функциями".

Рассмотрим пример, использующий анонимную функцию:

>>> l = [1, 2, 5, 3, 4]
>>> l.sort(key=lambda x: -x)
>>> l
[5, 4, 3, 2, 1]

Метод sort принимает в качестве аргумента key ссылку на функцию. В примере в качестве аргумента указана функция, меняющая знак у аргумента — поэтому список получается отсортирован от большего к меньшему. Сортировка с указанием ключа сама по себе встречается довольно часто, а вот ключи сортировки чаще всего будут разными. Поэтому выносить ключи в именованные функции смысла нет и анонимные функции здесь подходят идеально!
'''

#@ Особенности анонимных функций.

'''
Вы могли заметить, что аргументы анонимных функций не заключены в скобки. К этому нужно будет привыкнуть. Остальные средства для описания аргументов доступны в полной мере — и именованные аргументы, и *args* с **kwargs.

А ещё вы могли обратить внимание на то, что в примерах функции явно что-то возвращают, но слово return нигде не указано! Дело в том, что тело лямбда-функции — это всегда одно выражение, результат вычисления которого и будет возвращаемым значением. Да, в теле лямбда-функции не получится выполнить несколько действий и не получится использовать многострочные конструкции вроде for и while. Но зато анонимные функции обычно просто читать, чего было бы сложно добиться, разреши авторы "многострочные" лямбды.

Ещё одна особенность лямбда-функций заключается в том, что само определение функции является выражением! Функции можно конструировать и тут же вызывать, не заканчивая выражение:

>>> 1 + (lambda x: x * 5)(8) + 1
42

Этот пример выглядит забавно, но именно в таком виде лямбды встречаются редко. Зато часто можно встретить возврат лямбды из функции:

>>> def caller(arg):
...     return lambda f: f(arg)
...
>>> call_with_five = caller(5)
>>> call_with_five(str)
'5'
>>> call_with_five(lambda x: x + 1)
6

Кстати, этот пример даёт понять, что лябмды являются замыканиями: возвращаемая лямбда запоминает значение переменной arg!
'''



# >>>>>> Декораторы <<<<<<

'''
Представьте, что вам захотелось иметь возможность выводить на печать все результаты вызова некой функции. Однако саму функцию модифицировать не хочется, а вместо этого вы желаете получить универсальный инструмент, пригодный для использования с любыми функциями.

Давайте реализуем такую функцию, для чего воспользуемся ФВП (функцией высшего порядка):

>>> def printing(function):
...     def inner(*args, **kwargs):
...         result = function(*args, **kwargs)
...         print('result =', result)
...         return result
...     return inner
...
>>> def add_one(x):
...     return x + 1
...
>>> add_one = printing(add_one)
>>> y = add_one(10)
result = 11
>>> y
11


Сначала разберёмся с функцией printing. Эта функция создаёт замыкание inner, которое принимает любые аргументы, применяет к ним функцию, печатает результат и тут же возвращает его. Заметьте, в определении inner я использовал аргументы *args, **kwargs, которые функция без изменения передаёт замкнутой функции function — именно так в Python объявляют "всеядные" функции, которые "пробрасывают" любые комбинации аргументов.

Теперь посмотрим на пример применения printing. В примере я заменил функцию обёрнутым (wrapped) вариантом через присваивание старому имени функции нового значения. Да, функции в Python — обычные переменные в той области видимости, где были объявлены!

Имя "printing" ("печатающий") я выбрал неспроста — подобные обёртки над функциями часто называют в похожей манере. Ведь и по смыслу поведение, которое добавляет обёртка к исходной функции, служит дополнением для оной. И читается printing(add_one) практически по-человечески: "добавить единицу, печатая на экран (результат)".

Подобное оборачивание — довольно частая операция в коде, широко использующем функции высшего порядка. Авторы языка Python даже завели для удобного использования функций-обёрток специальный синтаксис! Вот эти самые функции-обёртки вместе с синтаксисом оборачивания называются декораторами.

Тут я вынужден предупредить, что те из вас, кто знаком с паттерном проектирования "Декоратор", могут смело забыть всё, что они знали об оном! Дело в том, что в декораторы в Python — сугубо самостоятельная вещь (а не реализации упомянутого паттерна.) Те, кому словосочетание "паттерн Декоратор" ничего не говорит, могут не обращать на это замечание внимания :)
'''

#@ Синтаксис применения декоратора.

'''
Применения декоратора printing к функции add_one с использованием специального синтаксиса можно записать так:
'''

@printing
def add_one(x):
    return x + 1

'''
Имя декоратора пишется на строчке, предшествующей заголовку функции, а перед именем пишется символ @. После такого применения декоратора нам уже не нужно "переприсваивать" функцию (add_one = printing(add_one))!

Применение даже одного декоратора становится удобнее с таким синтаксисом, но применять подобным образом можно сколько угодно декораторов! Выглядеть это будет так:
'''

@logging
@printing
@cached
def foo():
    # …

# Что будет равнозначно коду

foo = cached(foo)
foo = printing(foo)
foo = logging(foo)
# или в одну строку
foo = logging(printing(cached(foo)))

'''
Обратите внимание и запомните: оборачивание происходит сначала в ближайшие к имени функции обёртки, т.к. как бы "изнутри наружу" — cached, затем printing и в конце logging.
'''


# >>>>>> Больше о декораторах <<<<<<

#@ Декораторы с параметрами.

'''
Давайте пофантазируем вновь: представим, что нам хочется иметь возможность валидировать аргументы (проверять соответствие их значений неким правилам) функций. И хочется это делать с помощью декораторов, которые можно применять раз за разом. Парочку таких декораторов мы и реализуем к концу урока. Но для начала нужно слегка отвлечься.

Что будет, если аргументы функции не проходят нашу проверку? Нам нужно показывать ошибку. Но как это сделать? Подробнее о работе с ошибками я расскажу в следующем курсе, а пока просто покажу, как спровоцировать ошибку:

>>> raise ValueError('Value too low!')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: Value too low!

Вот такую ошибку мы и будем показывать, если значение аргумента не проходит валидацию! Можно приступать к созданию декораторов.

Пусть у некой функции числовой аргумент должен быть больше нуля и не равен некоторым "плохим" значениям. Конечно, мы могли бы сделать специальные декораторы вида
'''

@greater_than_zero
@not_bad
def function(arg):
    # …

'''
Вот только на все случаи жизни таких узкоспециализированных декораторов не напасёшься! Хочется как-то отделить оборачивание функции и сами проверки, чтобы в роли последних могли выступать обычные предикаты. Но как декоратор узнает о предикате, если всегда принимает единственный параметр — оборачиваемую функцию? Ответ: через замыкание! Нам нужна функция, которая примет в качестве аргумента функцию-предикат и вернёт функцию-обёртку, а та потом тоже примет в качестве аргумента функцию и вернёт функцию же! Напишем же этот слоёный пирог из функций:
'''

def checking_that_arg_is(predicat, error_message):
    def wrapper(function):
        def inner(arg):
            if not predicat(arg):
                raise ValueError(error_message)
            return function(arg)
        return inner
    return wrapper


'''
Функция checking_that_arg_is принимает предикат и возвращает wrapper. Вот wrapper — это уже наш декоратор с привычным уже inner внутри. Который проверяет аргумент предикатом, и, если условие соблюдено, вызывает function. Выглядит сложновато, но вы со временем научитесь сразу писать и читать такой код, ведь декораторы — в т.ч. и с параметрами — частые гости в коде на Python.

Применение декоратора с параметрами выглядит так:
'''

@checking_that_arg_is(condition, "Invalid value!")
def foo(arg):
    # …


'''
Думаю, что вы и сами сможете проследить, что и с какими аргументами здесь вызывается!

Теперь у нас есть то, чем оборачивать. Сейчас я напишу несколько замыканий, которые выступят проверками:
'''

def greater_than(value):
    def predicat(arg):
        return arg > value
    return predicat

def in_(*values):
    def predicat(arg):
        return arg in values
    return predicat

def not_(other_predicat):
    def predicat(arg):
        return not other_predicat(arg)
    return predicat

'''
Функции not_ и in_ имеют в конце названия символ _. Именно так принято называть переменные, имена которых совпадают с ключевыми словами или именами встроенных функций.

Эти ФВП принимают параметры и возвращают предикаты, которые удобно использовать с описанным выше декоратором. Вспомним: нам нужно проверять, что аргумент функции имеет значение, большее нуля и не равное некоторым плохим значениям. Вот как эти условия будут выглядеть в коде:

>>> @checking_that_arg_is(greater_than(0), "Non-positive!")
... @checking_that_arg_is(not_(in_(5, 15, 42)), "Bad value!")
... def foo(arg):
...     return arg
...
>>> foo(0)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 5, in inner
ValueError: Non-positive!
>>> foo(5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 6, in inner
  File "<stdin>", line 5, in inner
ValueError: Bad value!
>>> foo(6)
6

Условия выглядят почти как фразы на разговорном английском, не правда ли?! Каждая "фабрика предикатов" (ФВП, возвращающая предикат) получилась достаточно абстрактной, чтобы быть применимой для валидации разных значений. А ещё наши предикаты композируемы — удобны для создания комбинаций из существующих функций без написания новых (мне лично нравится not_(in_(…))!).
'''

#@ Оборачиваем функции правильно.

'''
Когда мы объявляем функцию, то функция получает имя. А ещё функция может иметь строку документации или docstring. Эту документацию показывают разные инструменты, например IDE. Или функция help() в Python REPL:

>>> def add_one(arg):
...     """
...     Add one to argument.
...
...     Argument should be a number.
...     """
...     return arg + 1
...
>>> add_one
<function add_one at 0x7f105936cd08>
>>> # ^ вот и имя у объекта функции!
>>>
>>> help(add_one)
…
    add_one(arg)
    Add one to argument.

    Argument should be a number.
…

Но что будет, если мы обернём функцию с помощью декоратора? Посмотрим:

>>> def wrapped(function):
...     def inner(arg):
...         return function(arg)
...     return inner
...
>>> add_one = wrapped(add_one)
>>> add_one
<function wrapped.<locals>.inner at 0x7f1056f041e0>
>>> help(add_one)
…
inner(arg)
…

Функция потеряла и имя (теперь это wrapped.<locals>.inner) и документацию! Но как же сохранить и то и другое? Можно сделать это вручную — скопировать у оригинальной функции атрибуты __name__ и __doc__. Но есть способ лучше! Перепишем наш декоратор с помощью декоратора wraps из модуля functools:

>>> from functools import wraps
>>> def wrapped(function):
...     @wraps(function)
...     def inner(arg):
...         return function(arg)
...     return inner
...
>>> def foo():
...     """Bar."""
...     return 42
...
>>> foo = wrapped(foo)
>>> foo
<function foo at 0x7f1057b15048>
>>> help(foo)
…
foo()
    Bar.
…


Мы обернули функцию foo, но обёртка сохранила документацию и имя! Кстати, вы заметили, что wraps — тоже декоратор с параметром? Думаю, что вы даже сможете представить, как он реализован!

У обёрток, созданных с применением wraps, есть ещё одно полезное свойство: до обёрнутой функции можно всегда достучаться потом: ссылка на оригинальную функцию хранится у обёртки в атрибуте __wrapped__:

>>> foo.__wrapped__
<function foo at 0x7f1056f04158>

Декоратор wraps сделает ваши декораторы достойными представителями вида, всегда используйте его!
'''



# >>>>>>  Рекурсия <<<<<<

'''
Рекурсия в программировании — это возможность дать определение функции, используя в процессе саму определяемую функцию. В математике многие функции определены именно таким образом, поэтому и большинство языков программирования берёт на вооружение этот подход. Python здесь не является исключением: обычно в определении функции вы можете использовать только определения, данные ранее, но есть одно исключение — функция в своём теле может вызывать себя. Выглядит это так:
'''

def factorial(n):
    if n <= 0:
        return 1
    return n * factorial(n - 1)

# Эта функция, вычисляет факториал числа n через умножение числа на факториал числа n - 1.


#@ Условие завершения рекурсии.

'''
Рассмотренный пример демонстрирует использование условия, прекращающего рекурсию. Если в этой функции убрать условие, проверяющее аргумент на неотрицательность, то первый же вызов этой функции заставит программу "зациклиться" — функция продолжит вызывать себя снова и снова.

В определениях рекурсивных функций практически всегда присутствует подобное условие. Оно позволяет вычислению пойти по одной из веток: по рекурсивной — в этой ветке произойдёт вызов себя (а то и не один!), и терминальной, которая закончит вычисление и вернёт результат.

Есть даже такое правило: какой-то из аргументов рекурсивной функции должен обязательно "убывать". Убывание может означать уменьшение счётчика, отбрасывание "головы" списка при движении к его хвосту, вызов себя для части исходной структуры при обработке древовидных структур данных. К сожалению, в общем случае понять, что программа не зациклится, можно только методом "пристального взгляда" и применением тестов. Особенно важно проверять срабатывание условия завершения рекурсии!
'''

#@ Переполнение стека.

'''
Большинство программ, написанных на языках, поддерживающих вызов функций, этот самый вызов устроен так: перед вызовом функции текущее место в программе запоминается в стеке, а когда функция возвращает результат, то соответствующий элемент стека отбрасывается.

Стек (stack) — структура данных, похожая на стопку монет: монета, положенная последней, будет снята первой (при снятии монет порядок получается обратным порядку складывания).

В этом же стеке сохраняются значения аргументов функции, а иногда и другая служебная информация. При этом память, выделенная для стека при запуске программы, конечна и довольно ограничена. Что же произойдёт, если функция будет вызывать себя снова и снова и не возвращать результат? Эта память когда-нибудь закончится! Когда заканчивается память, выделенная для стека вызовов, случается так называемое "переполнение стека".

Из-за переполнения стека вы не сможете посчитать факториал для достаточно больших чисел с помощью рекурсивной функции. Но сможете посчитать с помощью итеративной — написанной с использованием циклов и переменных. К слову, вот так выглядит переполнение стека при подсчёте факториала:

>>> factorial(1000)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 4, in factorial
  File "<stdin>", line 4, in factorial
  File "<stdin>", line 4, in factorial
  [Previous line repeated 995 more times]
  File "<stdin>", line 2, in factorial
RecursionError: maximum recursion depth exceeded in comparison


Заметьте, сообщение говорит, что "превышена максимальная глубина рекурсии". Глубиной рекурсии называется количество последовательных вызовов "себя" без возврата значения. В Python максимальная длина искусственно ограничена, потому что проще считать количество вызовов, чем предсказывать окончание памяти.

#@ Зачем рекурсия нужна.

Вы можете подумать, почему же программисты не перестают использовать рекурсивные функции и не переходят на итеративные? Дело в том, что некоторые алгоритмы реализуются сильно проще, если использовать именно рекурсию, а не циклы. Часто такие алгоритмы работают с рекурсивными же структурами данных — деревьями, "словарями словарей словарей" и подобными. При реализации таких алгоритмов нужно помнить, что память для стека не бесконечна. Впрочем, обычно не бесконечны и сами обрабатываемые структуры данных, поэтому отказываться полностью от рекурсии не стоит!
'''

#@ Рекурсия прямая, косвенная, линейная, каскадная.

'''
Видов рекурсии существует несколько. Если функция вызывает себя непосредственно, то мы имеем дело с прямой рекурсией. Если же функция вызывает внутри себя другую, которая когда-то вызовет первую, то это уже косвенная рекурсия.

Если при вычислении результата функции нужно вызвать себя один раз, как в примере с factorial, то рекурсия называется линейной. Только имейте в виду, что "один раз" ничего не говорит про общее количество вызовов функции в теле! Речь идёт именно о количестве вызовов, результаты которых потребуются для оного общего вычисления. Рассмотрим два разных примера: в одном рекурсия будет линейной, а в другом каскадной — так называют рекурсию с "несколькими вызовами себя".

Рекурсия в этой функции (которая проверяет Гипотезу Коллатца) — линейная:
'''

def collatz(n):
    if n == 1:
        return True
    if not n % 2:
        return collatz(n // 2)
    return collatz(n * 3 + 1)

'''
Здесь в теле функции рекурсивных вызова два, но в каждом конкретном "заходе" используется только один.

А вот рекурсия в этой функции (которая вычисляет очередное Число Фибоначчи) — каскадная:
'''

def fibonacci(n):
    if n <= 2:
        return 1
    return fibonacci(n - 1) + fibonacci(n - 2)

'''
Здесь функция всегда вызывает себя два раза. Сначала будет два вызова себя, которые превратятся в четыре (два раза по два вызова), затем в восемь — количество вызовов растёт "каскадно", отсюда и название рекурсии.
'''

#@ Заключение.

'''
Рекурсия — мощный инструмент в умелых руках. Многие задачи можно решать с помощью рекурсии элегантно, а если умеючи — то и эффективно.
'''



############ Python: Абстракция с помощью данных ############

#@ Введение

'''
Абстракция — основной способ борьбы со сложностью в программировании. Она позволяет уйти от деталей реализации и сосредоточиться на главном. Хороший пример абстракции — функция сортировки списка. Не важно, как она устроена, важно, что она делает то, что нам нужно.

Другой пример — функции высших порядков, такие как map и filter, позволяют обрабатывать коллекции без знания их внутреннего устройства. Причём коллекция не обязательно должна быть плоской: подобные функции можно написать для сколь угодно сложных структур, например, для деревьев. Абстракция с помощью функций помогает сосредоточиться на самой обработке, а не на процессе обхода данных.

С другой стороны, сами данные нередко имеют сложную структуру. Представление пользователя в нетривиальной системе может потребовать описания десятков и сотен различных параметров и данных, связанных с ними. В этой ситуации полезно спрятать сложную структуру за набором функций. Такие функции скрывают внутреннюю сложность и упрощают поддержку кода. Подобное сокрытие деталей реализации и называется абстракция с помощью данных.

В данном курсе мы познакомимся с некоторыми базовыми принципами проектирования программ. С тем, как моделировать и представлять в программе объекты реального (и воображаемого) мира. Примером для проектирования послужит создание библиотеки для работы с графическими примитивами, такими как точки, отрезки, фигуры. Эта библиотека, с одной стороны, достаточно понятна (в том числе визуально) для всех, с другой — очень просто представляется в коде.

Основные темы этого курса:

Предметная область (Domain Model)
Онтология
Уровни проектирования (барьеры абстракции)
Инвариант
'''



# >>>>>> Онтология <<<<<<


'''
Программы, которые пишут программисты, всегда создаются под определённую предметную область. Например, бухгалтерский софт основывается на правилах ведения бухгалтерского учёта, а сайт для просмотра сериалов — на понятиях из телеиндустрии, таких как "сезон" или "эпизод". То же самое относится и к любой другой предметной области: бронирование авиабилетов, отелей, поиск туров, продажа и покупка автомобилей и так далее.

Понимание предметной области, для которой вы пишите программу, также важно, как и умение программировать. Это не значит, что её нужно знать досконально — иногда область может быть по-настоящему сложной (например, те же бухгалтерия или технологическое производство). Но общее понимание всё же требуется.

Рассмотрим в качестве примера Хекслет, так как вы с ним достаточно хорошо знакомы. Вы неплохо знаете его предметную область, хотя вряд ли думали о ней так, как мы сделаем это сейчас. В первую очередь, для её понимания нужно выделить ключевые понятия. У обучающих ресурсов это, как правило, "курс" и "урок", но на самом деле понятий гораздо больше. В случае Хекслета ещё можно выделить "профессию", "испытание" (практика после курса), "code review", "квиз" (набор вопросов и ответов), "участника курса" (вы становитесь участником, когда вступаете в курс), "проект". Этот список можно продолжать ещё долго. Вероятно, вы удивитесь, но на Хекслете существует более двухсот подобных понятий, которые также называют сущностями, и все они описаны в коде.

Сущности находятся в некоторых взаимоотношениях друг с другом. Например, квиз содержит (агрегирует) в себе вопросы. А каждый вопрос, в свою очередь, содержит в себе ответы. Профессия состоит из курсов, курсы из уроков, уроки — из теории, квиза и практики. Эти связи имеют конкретные названия. Например:

Один урок может находиться только в одном курсе, но курс содержит множество уроков. Такая связь называется "один ко многим" (one-to-many или o2m).
Один курс могут проходить множество пользователей, и один пользователь может проходить много курсов. Такая связь уже называется "многие ко многим" (many-to-many или m2m).
Реже встречается отношение "один к одному" (one-to-one или o2o). На Хекслете так связаны пользователь и эксперт.
ERD

В реальности всё ещё чуть сложнее, потому что одна и та же сущность с точки зрения разных систем может выглядеть совершенно по-разному. Пользователь Хекслета с точки зрения бухгалтера (а у нас есть бухгалтер!) и пользователь с точки зрения ментора — две большие разницы.

Описание объектов рассматриваемой области и связей между ними называется онтологией предметной области. Эту онтологию хорошо знают эксперты соответствующей области (в бухгалтерии — бухгалтер, в обучении — преподаватель). Но, в отличие от программистов, они часто представляют её на интуитивном уровне, неформально. На практике программисты (или бизнес-аналитики и менеджеры) общаются с заказчиками, которые могут сами выступать в роли экспертов и строят вместе с программистами формальную онтологию — этот процесс происходит постоянно в процессе развития проекта и не выделяется в отдельный этап проектирования. Создатели онтологии выделяют конкретные термины, договариваются о том, что они означают и как связаны друг с другом. Затем с помощью ER-модели программист формирует необходимую модель данных. ER-модель используется при высокоуровневом (концептуальном) проектировании баз данных. На этом этапе уже проявляются зачатки архитектуры будущего приложения.

Далеко не всегда можно однозначно сказать, какая связь существует между двумя сущностями. Иногда программисты думают наперёд и сразу формируют более сложные связи, например, m2m, а не o2m, что сказывается на сложности кода. Чем сложнее связь, тем больше кода и выше стоимость её создания и поддержки. Сложность связей можно описать так: o2o, o2m, m2m, правее — сложнее. Иногда программисты ошибаются при выборе той или иной связи, что обычно говорит о недостаточно хорошем понимании предметной области. Приведу интересный пример. Предположим, что в системе нужно реализовать пользователя и заграничный паспорт. Интуитивно кажется, что между этими понятиями связь один к одному: ведь один пользователь может иметь один заграничный паспорт. Так? Не совсем: паспорт может поменяться, если он был утерян или закончился его срок действия. К тому же, в некоторых странах разрешено владение одновременно несколькими заграничными паспортами.

С другой стороны, реальный мир всегда сложнее и полнее, чем любая модель. И задача программиста состоит не в том, чтобы создать универсальную и всеобъемлющую модель некоторой области, а в том, чтобы понять потребности конкретного бизнеса, выделить для них только значимые части рассматриваемой предметной области и перенести их в код.

В зависимости от языка меняется способ представления сущностей в коде. В некоторых определяются типы (используя АТД, интерфейсы или классы), в других — структуры, а третьи вообще не предоставляют никаких вариантов, кроме словарей (ассоциативных массивов).

Со следующего урока мы начнём изучать различные предметные области и строить подходящие модели данных.

DDD

Наиболее полно рассматриваемая тема раскроется тогда, когда мы начнём изучать ООП и ORM. Сейчас достаточно того, что у вас есть общее представление о предметной области, сущностях и связях. Не забудьте почитать информацию по приведённым ссылкам — чем больше вопросов появится на этом этапе, тем лучше.
'''


# >>>>>> Точки на координатной плоскости <<<<<<

'''
Одна из самых удобных тем для тренировки навыков моделирования — геометрия. В отличие от других разделов математики, она визуально представима и интуитивно понятна для всех. Для начала вспомним базовые понятия, с которыми будем иметь дело.

Координатная плоскость — плоскость, на которой задана система координат. Координаты задаются на двух пересекающихся под прямым углом (если система координат — декартова) прямых x и y, называемых числовыми осями.

Самый простой примитив, который можно расположить на плоскости — точка. Её положение определяется двумя координатами, и в математике она записывается так: (2, 3), где первое число — координата по оси x, а второе — по оси y. В коде её можно представить как кортеж, состоящий из двух элементов.

>>> # x = 2, y = 3
>>> point = (2, 3)
>>> # или же
>>> point = 2, 3

Этого уже достаточно для выполнения полезных геометрических действий. Например, для поиска симметричной точки относительно x, достаточно инвертировать второе число (поменять знак на противоположный).

>>> # x = 2, y = 3
>>> point = 2, 3
>>> x, y = point
>>> # x = 2, y = -3
>>> symmetrical_point = x, -y

Иногда бывает нужно найти точку, находящуюся между двумя другими точками ровно посередине (ещё говорят, что нужно найти середину отрезка). Такая точка вычисляется через поиск среднего арифметического каждой из координат. То есть координата x "срединной" точки равна (x1 + x2) / 2, а координата y — (y1 + y2) / 2.

>>> def get_middle_point(p1, p2):
...     x1, y1 = p1
...     x2, y2 = p2
...     x = (x1 + x2) / 2
...     y = (y1 + y2) / 2
...     return x, y
...
>>> point1 = 2, 3
>>> point2 = -4, 1
>>> get_middle_point(point1, point2)
(-1, 2)

Подобных операций в геометрии очень много. С точки зрения организации кода, все функции, связанные с работой точек, логично поместить в модуль points.

В свою очередь, точки объединяются в отрезки. Каждый отрезок задаётся парой точек — противоположных концов отрезка. В коде отрезок можно представить аналогично точке в виде кортежа из двух элементов.

>>> point1 = 3, 4
>>> point2 = -8, 10
>>> segment = point1, point2
'''



# >>>>>> Семантика списков и словарей <<<<<<

'''
В предыдущем уроке я сказал, что кортеж — самый простой способ представить точку. Но правильный ли это способ? Почему бы не взять, скажем, список? Давайте разберёмся.

Когда мы говорим про конструкции языка, то, помимо синтаксиса, нужно всегда помнить о семантике. То есть о том, для решения каких задач она создана. На практике же инструменты часто используются не по назначению. Это приводит к созданию кода, который сложнее понять и отлаживать, а значит и поддерживать.

Список, по своей сути, — коллекция, набор некоторых однотипных значений, подразумевающих возможность перебора и одинаковой обработки. Кроме того, эти значения друг с другом жёстко не связаны и могут существовать независимо. В списке, часто (но не всегда), отсутствует позиционность, то есть жёстко зафиксированные места для его значений. Либо позиция зависит от конкретной задачи. Вот некоторые примеры из жизни где списки подходят:

Список стоп-слов
Список пользователей
Список уроков курса
Список ходов шахматной партии (порядок важен)
Применительно к нашей графической библиотеке список подходит, например, для хранения коллекции точек или набора отрезков.

Сама точка не является коллекцией. Это единое целое, части которого, не имеют смысла сами по себе. Между ними нельзя установить никакого порядка, в отличие от, скажем, списка пользователей. А код, который работает с конкретной точкой представленной списком, всегда ожидает, что список состоит из двух элементов, каждый из которых имеет определённую позицию. Другими словами, список используется как структура для описания составного объекта (то есть такого, который описывается не одним значением, а несколькими, в данном случае — двумя числами-координатами).

Кортеж, как структура с фиксированным составом элементов подходит для представления точек значительно лучше: элементы кортежа не меняют свои позиции, их не становится ни больше ни меньше. Но кортежи — не единственный вариант для представления сущностей. Для представления тех же точек и отрезков можно использовать словарь:

point = {"x": 2, "y": 3}
symmetrical_point = {
    "x": -point["x"],
    "y": point["y"],
}
Кода стало чуть больше, но семантика важнее: каждый элемент данных теперь имеет имя. Имена использовать проще, чем индексы. Поэтому мы и рекомендуем кортежи распаковывать в переменные с говорящими именами, как только вам нужно поработать с содержимым вместо кортежа целиком. Код с переменной x или обращением по ключу point["x"] проще понимать, чем код с point[0]. Словари, к тому же, выглядят информативнее при выводе на экран — по именам ключей часто можно сразу догадаться, о чём идёт речь.

Представьте, как будет выглядеть представление отрезка на списках. Как список списков:

point1 = [2, 3]
point2 = [-8, 10]
segment = [point1, point2]

# код сложный для понимания
point1[1]
point2[0]
segment[1][0]
Понять, что это отрезок, нереально без понимания контекста. Единственное, что частично спасает ситуацию — хорошие имена переменных, но этого мало.

Использование правильной (подходящей под задачу) структуры данных намного важнее:

point1 = {"x": 3, "y": 4}
point2 = {"x": -8, "y": 10}
segment = {
    "begin_point": point1,
    "end_point": point2,
}

# good semantics
point1["x"]
point2["y"]
segment["endPoint"]["y"]
Запомните простое правило: код, который заставляет думать: не говорящие имена, плохие абстракции, неправильные структуры данных, сильная зависимость от контекста — плохой код (при этом важно не путать лёгкость и простоту).

Использование словаря сразу даёт ещё одно крайне важное преимущество — расширяемость. Кортеж (не говоря уж о списке), используемый как структура, хрупок. Поменять местами значение аргументов нельзя — сломается весь код, который рассчитывал на определённый порядок, либо придётся всё переписывать. Расширить тоже просто так не получится: часть кода, конечно, продолжит работать, но часть может сломаться (например, x, y = point). А использование словаря не полагается на порядок ключей и уж точно не зависит от их количества. В любой момент можно добавить новый ключ, и программа почти наверняка останется работоспособной.

Какие ещё данные нужно представлять словарями? Любую одиночную сущность:

Пользователь
Курс
Урок
Платёж
Шахматная партия (помимо даты, имён и места, она содержит набор ходов)
'''



# >>>>>> Создание абстракции <<<<<<

'''
Декартова система координат — не единственный способ графического описания. Другой способ — полярная система координат.

Полярная система координат — двухмерная система координат, в которой каждая точка на плоскости однозначно определяется двумя числами — полярным углом и полярным радиусом. Полярная система координат особенно полезна в случаях, когда отношения между точками проще изобразить в виде радиусов и углов; в более распространённой декартовой, или прямоугольной, системе координат, такие отношения можно установить только путём применения тригонометрических уравнений. (c) Wikipedia

Вообразите себе ситуацию. Вы разрабатываете графический редактор (Photoshop!), и ваша библиотека для работы с графическими примитивами построена на базе декартовой системы координат. В какой-то момент вы понимаете, что переход на полярную систему поможет сделать систему проще и быстрее. Какую цену придётся заплатить за такое изменение? Вам придётся переписать практически весь код.
'''

point = {"x": 2, "y": 3}
symmetrical_point = {
    "x": -point["x"],
    "y": point["y"],
}


'''
Связано это с тем, что ваша библиотека не скрывает внутреннюю структуру. Любой код, использующий точки или отрезки, знает о том, как они устроены внутри. Это относится как к коду, который создаёт новые примитивы, так и к коду, который извлекает из них составные части. Изменить ситуацию и спрятать реализацию достаточно просто, используя функции:
'''

point = make_descartes_point(3, 4)
symmetrical_point = make_descartes_point(-get_x(point), get_y(point))

'''
В примере мы видим три функции make_descartes_point, get_x и get_y. Функция make_descartes_point называется конструктором, потому что она создаёт новый примитив, функции get_x и get_y — селекторами (selector), от слова "select", что в переводе означает "извлекать" или "выбирать". Такое небольшое изменение ведёт к далеко идущим последствиям. Главное, что в прикладном коде (том, который использует библиотеку) отсутствует работа со структурой напрямую.
'''

# То есть мы работаем не так
point = [1, 4] # мы знаем что это список
print(point[1]) # прямое обращение к списку

# А так
point = makeDescartesPoint(3, 4) # мы не знаем как устроена точка
print(get_y(point)) # мы получаем доступ к частям только через селекторы

'''
Глядя на код, даже нельзя сказать, что из себя представляет точка "изнутри", какими конструкциями языка представлена (для этого можно воспользоваться отладочной печатью). Так мы построили абстракцию данных. Суть этой абстракции, заключается в том, что мы скрываем внутреннюю реализацию. Можно сказать что создание абстракции с помощью данных, приводит к сокрытию этих данных от внешнего кода.

А вот один из способов реализовать абстракцию для работы с точкой:
'''

def make_descartes_point(x, y):
    return {"x": x, "y": y}

def get_x(point):
    return point["x"]

def get_y(point):
    return point["y"]


'''
Теперь мы можем менять реализацию без необходимости переписывать весь код (однако, переписывание отдельных частей всё же может понадобиться). Несмотря на то, что мы используем функцию make_descartes_point, которая создаёт точку на основе декартовой системы координат (принимает на вход координаты x и y), внутри она вполне может представляться в полярной системе координат. Другими словами, во время конструирования происходит трансляция из одного формата в другой:
'''

import math

def make_descartes_point(x, y):
    # конвертация
    return {
        "angle": math.atan2(y, x),
        "radius": math.sqrt(x ** 2 + y ** 2)
    }

'''
Начав однажды работать через абстракцию данных, назад пути нет. Придерживайтесь всегда тех функций, которые вы создали сами. Либо тех, которые вам предоставляет используемая библиотека.
'''


# >>>>>> Интерфейсы <<<<<<

'''
В IT широко распространён термин "Интерфейс", который по смыслу похож на то, как мы используем это слово в повседневной жизни. Например, пользовательский интерфейс представляет собой совокупность элементов управления сайтом, банкоматом, телефоном и так далее. Интерфейсом пульта управления от телевизора являются кнопки. Интерфейсом автомобиля можно назвать все рычаги управления и кнопки. Резюмируя, можно сказать, что интерфейс определяет способ взаимодействия с системой.

Создание грамотных интерфейсов не так уж просто, как может показаться на первый взгляд. Я бы даже сказал, что это крайне сложно. Каждый день мы встречаемся с неудобными интерфейсами, начиная от способов открывания дверей и заканчивая работой лифтов. Чем сложнее система (то есть, чем больше возможных состояний), тем сложнее сделать интерфейс. Даже в примитивном примере с кнопкой включения телевизора (два состояния — вкл/выкл), можно реализовать либо две кнопки, либо одну, которая ведёт себя по разному в зависимости от текущего состояния.

В программировании всё устроено похожим образом. Интерфейсом называют набор функций (имена и их сигнатуры, то есть количество и типы входящих параметров, а также возвращаемое значение), не зависящих от конкретной реализации. Такое определение один в один совпадает с понятием абстрактного типа данных. Например, для точек интерфейсными являются все функции, которые мы реализовывали в практике, и которые описывались в теории.

Как соотносятся между собой понятия абстракция и интерфейс? Абстракция это слово, описывающее в первую очередь те данные, с которыми мы работаем. Например, почти каждое веб-приложение включает в себя абстракцию "пользователь". На Хекслете есть абстракция "курс", "проект" и многое другое. Интерфейсом же называется набор функций, с помощью которых можно взаимодействовать с данными.

Но функции бывают не только интерфейсные, но и вспомогательные, которые не предназначены для вызывающего кода и используются исключительно внутри абстракции:
'''

# Функции make_user, get_age, is_adult — интерфейс абстракции User.
# Они используются внешним (пользовательским, вызывающим) кодом.
def make_user(name, birthday):
    return {
        "name": name,
        "birthday": birthday,
    }

def get_age(user):
    return calculate_age(user["birthday"])

def is_adult(user):
    return get_age(user) >= 18

# Эта функция не является частью интерфейса абстракции User.
# Она является "внутренней" и возвращает возраст пользователя.
def calculate_age(birthday):
    ###

'''
В сложных абстракциях (которые могут быть представлены внешними библиотеками), количество неинтерфейсных функций значительно больше, чем интерфейсных. Вплоть до того, что интерфейсом библиотеки могут являться одна или две функции, но в самой библиотеке их сотни. То, насколько хороша ваша абстракция, определяется в том числе тем, насколько удобен её интерфейс.
'''


# >>>>>> Уровневое проектирование <<<<<<

'''
Рассмотрим ещё одну простую систему — рациональные числа и операции над ними. Напомню, что рациональным называют число, которое может быть представлено в виде дроби a/b, где a — это числитель дроби, b — знаменатель дроби. Причём b не должно быть нулём, поскольку деление на ноль не допускается.

Рациональные числа в Python не поддерживаются, поэтому абстракцию для них создадим самостоятельно. Как обычно, нам понадобятся конструктор и селекторы:

>>> # создали рациональное число "одна вторая"
>>> num = make_rational(1, 2)
>>> numer = get_numer(num)
1
>>> denom = get_denom(num)
2

С помощью трёх функций мы определили рациональное число. Одна функция (конструктор) собирает его из частей, другие (селекторы) позволяют каждую часть извлечь. Чем при этом, с точки зрения языка, является num — абсолютно не важно. Хоть функцией (и такое возможно), хоть списком, хоть словарём. Во внутренней реализации можно даже использовать строки:

>>> def make_rational(numer, denom):
...     return "{}/{}".format(numer, denom)
...
>>> def get_numer(rational):
...     numer, _ = rational.split('/')
...     return numer
...
>>> def get_denom(rational):
...     _, denom = rational.split('/')
...     return denom
...
>>> make_rational(10, 3)
"10/3"

Несмотря на то, что мы научились представлять рациональные числа, эта абстракция сама по себе малоприменима. Абстракция становится полезна тогда, когда появляется возможность оперировать ей. Для рациональных чисел базовыми операциями можно считать арифметические, например, сложение, вычитание или умножение. Умножение рациональных чисел — самая простая операция. Для её выполнения нужно перемножить числители и знаменатели:

3/4 * 4/5 = (3 * 4)/(4 * 5) = 12/20

Самое интересное начинается в процессе реализации. Если предположить, что реальная структура рационального числа выглядит так: {"numer": 2, "denom": 3}, то, чисто технически, решение может быть таким:
'''

def multiply_rational(rational1, rational2):
    return {
        "numer": rational1["numer"] * rational2["numer"],
        "denom": rational1["denom"] * rational2["denom"],
    }

'''
С точки зрения вызывающего кода всё нормально, абстракция сохранена. На вход в mul подаются рациональные числа, на выходе — рациональное число. А вот внутри никакой абстракции нет, обращение с рациональными числами строится на основе знания их устройства. Любое изменение внутренней реализации рациональных чисел потребует переписывания всех операций, работающих с рациональными числами напрямую — то есть без селекторов или конструктора. Данный код нарушает принцип одного уровня абстракции (single layer abstraction).

При разработке сложных систем используется подход — уровневое проектирование. Он заключается в том, что системе придаётся структура при помощи последовательных уровней. Каждый из уровней строится путём комбинации частей, которые на данном уровне рассматриваются как элементарные. Части, которые строятся на каждом уровне, работают как элементарные на следующем уровне.

Уровневое проектирование пронизывает всю технику построения сложных систем. Например, при проектировании компьютеров резисторы и транзисторы сочетаются (и описываются при помощи языка аналоговых схем), и из них строятся и-, или- элементы и им подобные, служащие основой языка цифровых схем. Из этих элементов строятся процессоры, шины и системы памяти, которые в свою очередь служат элементами в построении компьютеров при помощи языков, подходящих для описания компьютерной архитектуры. Компьютеры, сочетаясь, дают распределённые системы, которые описываются при помощи языков описания сетевых взаимодействий, и так далее. (c) SICP
'''

def multiply_rational(rational1, rational2):
    return make_rational(
        get_numer(rational1) * get_numer(rational2),
        get_denom(rational1) * get_denom(rational2),
    )


'''
В нашем примере базовым уровнем являются типы, встроенные в сам язык: числа и списки. На их основе сформирован уровень для представления рациональных чисел: make_rational, get_denom, get_numer. Затем — уровень, на котором реализованы арифметические операции над рациональными числами: сложение, вычитание, умножение и так далее.

Подчеркну, что речь идёт про реализацию самих уровней. Например, операция сложения полностью опирается на конструктор и селекторы, но ничего не знает и не может знать про внутреннее устройство самих рациональных чисел. С другой стороны, это не значит, что в одном месте не могут появиться функции из разных уровней. Могут и это нормально во многих случаях. Например:
'''

def f(rational1, rational2):
    rational3 = add_rational(rational1, rational2)
    denom = get_denom(rational3)
    numer = get_numer(rational3)
    print("Denom: {}".format(denom))
    print("Numer: {}".format(numer))




# >>>>>> Инварианты <<<<<<

'''
Абстракция позволяет нам не думать о деталях реализации и сосредоточиться на её использовании. Более того, при необходимости реализацию абстракции можно всегда переписать, не боясь сломать использующий её код. Но есть ещё одна важная причина, по которой нужно использовать абстракцию — соблюдение инвариантов.

Инвариант в программировании — логическое выражение, определяющее непротиворечивость состояния (набора данных).

Разберёмся на примере. Когда мы описали конструктор и селекторы для рациональных чисел, то неявно подразумевали выполнение следующих инвариантов:

>>> num = make_rational(numer, denom)
>>> numer == get_numer(num)
True
>>> denom == get_denom(num)
True

Передав в конструктор рационального числа числитель и знаменатель, мы ожидаем, что получим их (те же числа), если применим селекторы к этому рациональному числу. Именно так определяется корректность работы данной абстракции. Этот код практически является тестами!

Инварианты существуют относительно любой операции. И иногда они довольно хитрые. Например, рациональные числа можно сравнивать между собой, но не прямым способом, потому, что одни и те же дроби можно представлять разными способами: 1/2 и 2/4. Код, который не учитывает этого факта, работает некорректно:

>>> num1 = make_rational(2, 4)
>>> num2 = make_rational(8, 16)
>>> num1 == num2
False

Задача приведения дроби к нормальной форме называется нормализацией. Реализовать её можно разными способами. Самый очевидный — выполнять нормализацию во время создания дроби, внутри функции make_rational. Другой — выполнять нормализацию уже при обращении через функции get_numer и get_denom. Последний способ обладает недостатком — вычисление нормальной формы происходит на каждый вызов. Избежать этого можно, используя технику мемоизации.

Учитывая новые вводные, становится понятно, что инвариант, связывающий конструктор и селекторы, нуждается в модификации. Функции get_numer и get_denom должны вернуть не переданные значения, а значения после нормализации (если дробь уже нормализована, то это будут те же самые значения).


>>> num = make_rational(10, 20)
>>> get_numer(num)
10
>>> get_denom(num)
20

Становится понятно, что абстракция не только прячет от нас реализацию, но и отвечает за соблюдение инвариантов. Любая работа в обход абстракции чревата тем, что не будут учтены внутренние преобразования:

>>> # Эти данные не нормализованы,
>>> # потому что не использовался конструктор
>>> num = {"numer": 10, "denom": 20}
>>>
>>> # Возвращается не то что должно
>>> # (ожидается нормализованный возврат)
>>> get_numer(num)
1
>>> get_denom(num)
2

Защиту данных можно организовать и без специальных средств, только за счёт функций высшего порядка. Данный способ основан на создании абстракций с помощью анонимных функций, замыканий и передачи сообщений (подробнее в SICP). Если вы хотите узнать об этом больше, то попробуйте наш курс Python: Составные данные

Хочу сразу предостеречь вас от следования культу карго. Несмотря на то, что идея с защитой данных выглядит очень здраво, в реальности подобные механизмы крайне легко обходятся с помощью Reflection API и даже без них, просто за счёт ссылочных данных. Поэтому подобная защита — она больше "от дурака". Второй момент связан с тем, что в мире немало языков (пример, JavaScript), в которых всё нормально с абстракциями, но нет механизмов для защиты данных — и ничего страшного не произошло. Другими словами, на практике, при использовании абстракций, никто особо и не пытается их нарушать специально. И я склоняюсь к мысли, что значение принудительной защиты данных сильно преувеличено.
'''




##########  Ключевые аспекты веб-разработки на Python ##########

#@ Введение

'''
Вы уже умеете пользоваться языком в целом. Этот навык ценен сам по себе и необходим каждому программисту на Python. Однако Python — язык общего назначения, а значит может применяться в самых разных областях. Более того, Python даст фору многим другим "универсальным" языкам в плане широты круга решаемых задач! Некоторые из областей применения сравнительно невелики (например, написание скриптов автоматизации), другие — просто огромны (Data Science)! И чем больше предметная область, тем больше нужно знать программисту!

Web-разработка — большая область. Большая часть Web построена по так называемой клиент-серверной модели. Клиент (например, браузер) делает запрос на сервер, сервер готовит ответ и отправляет его обратно. Python чаще всего отвечает за серверную часть и берёт на себя

получение запросов от клиента,
хранение и обработку данных в Базах Данных,
формирование HTML-страниц или других представлений данных в БД,
выдачу результата по разным каналам (не только выдача страниц для отображения в браузере, но и отправка почты, CSS-уведомлений и т.п.).
Та часть Web-приложения, которая работает на сервере, называется backend. А та, что работает в браузере пользователя, т.е. на клиенте, называется frontend. Как я уже отметил выше, Web-разработка на Python сосредоточена именно на создании backends.
'''


# >>>>>> Из чего состоит backend? <<<<<<


'''
Когда сервер получает запрос от браузера, с программной стороны его обрабатывает Web-сервер. Некоторые языки встраивают web-сервер прямо в своё приложение, но большинство интерпретируемых языков использует специальную внешнюю программу. Таких самостоятельных Web-серверов существует несколько, но наиболее популярен Nginx. Он берёт на себя обработку входящих запросов, отдачу статических файлов, распределение запросов между web-приложениями.
'''

#@ WSGI.

'''
В случае Python за web-сервером как правило находится WSGI-сервер, запускающий WSGI-приложения. WSGI или Web Service Gateway Interface — это такая абстракция, согласно которой ответчик на запросы, это Python-функция, принимающая запрос и возвращающая ответ! Звучит просто, не правда ли? Минимальное WSGI-приложение выглядит примерно так:
'''

def app(environ, start_response):
    data = b"Hello, World!\n"
    start_response("200 OK", [
        ("Content-Type", "text/plain"),
        ("Content-Length", str(len(data)))
    ])
    return iter([data])

'''
Всё, что касается конкретного запроса, приходит в аргументе environ, функция start_response устанавливает параметры ответа (в данном примере, размер ответа и тип содержимого), а затем функция просто возвращает итератор, построчно отдающий ответ. Если вы возьмёте популярный WSGI-сервер gunicorn, сохраните функцию в файл example.py и вызовете команду gunicorn -w 4 example:app, то вы получите рабочее Web-приложение!
'''

#@ Web-фреймворк.

'''
Показанное Web-приложение пусть и работает, но на любой запрос оно будет возвращать один и тот же текст. Что-то более сложное написать в таком стиле будет проблематично, пусть и выполнимо. Чтобы упростить жизнь типичного backend-разработчика и помочь ему реализовывать типичные приложения, используются фреймворки (frameworks) — библиотеки, задающие готовую структуру приложения. В эту структуру разработчику нужно только вписывать свои кусочки кода, а сам "скелет" приложения оказывается сразу готов к применению. Именно Web помогают писать web-фреймворки. Самые популярные web-фреймворки для Python — это Django и Flask.

Web-фреймворки берут на себя маршрутизацию, упрощают работу с заголовками и данными запросов, формирование ответов в разных форматах, сохранение истории запросов в файлы (для анализа и сбора статистики, для нужд отладки).
'''

#@ ORM и шаблонизатор.

'''
Что же ещё находится в бэкенде, кроме машинерии обработки запросов? Чаще всего — ORM и шаблонизатор.

ORM или Object Relation Model, это средство работы с записями в базах данных (БД), представляющие записи в виде понятных для языка программирования объектов.

Шаблонизатор — средство, позволяющее писать HTML и CSS в отдельных файлах, а затем модифицировать их содержимое из кода так, чтобы вёрстка отображала нужные данные. Шаблонизатор даёт возможность сверстать макет один раз, а потом программно получать из макета разные страницы.

Некоторые Web-фреймворки, такие как Django, уже включают в себя ORM и шаблонизатор. Вместе с этим существуют и самостоятельные реализации данных средств.
'''



# >>>>>> Микрофреймворки <<<<<<

'''
Backend Web-приложения большую часть времени обрабатывает запросы от frontend'а. Ответная реакция на запрос, как правило, зависит от того, какой был запрошен адрес и с каким HTTP-глаголом. Чаще всего используются POST- и GET-запросы. Подробнее о глаголах протокола HTTP вы узнаете в соответствующем курсе, пока же достаточно понимать, что глагол — такая же часть запроса, как и URL (тот самый адрес, который вы видите в браузере).

Практически в любом Web-приложении нужно

Принять запрос.
Определить, какой обработчик должен выполниться.
Выполнить обработчик и подготовить ответ.
Вернуть ответ клиенту.
Этот набор действий практически не меняется от проекта к проекту, поэтому его и выносят во фреймворк. При этом типичный фреймворк (не только Web-фреймворк) устроен так, что работает в режиме "не звоните нам, мы сами вам позвоним": пользователь фреймворка встраивает свои функции в готовый каркас, а фреймворк сам решает, когда и какие функции вызывать. Этим фреймворк отличается от обычной библиотеки — последние обычно отдают контроль пользователю.

Давайте рассмотрим пример кода, построенного с использованием web-фреймворка:
'''

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

'''
Эти пять строчек — готовое Web-приложение, пусть и содержащее всего один обработчик hello_world. Обратите внимание на то, насколько код обработчика лаконичен: обработчик возвращает строку и вообще является максимально простой функцией. Вся "магия" (в смысле "автоматика") сокрыта в декораторе @app.route, который привязывает обработчик к конкретному пути (route).

В HTTP-запросе путь — это часть адреса, идущая следом за доменным именем. В адресе https://foo.bar/this/is/a/path путём будет строка /this/is/a/path. В примере выше hello_world отвечает на запросы по пути '/' — это так называемый "корень" ("root"), минимально возможный путь (в адресе "https://hexlet.io/" завершающий слэш — тот самый "корень" сайта, т.е. его главная страница).

Рассмотренный пример демонстрирует использование микрофреймворка Flask. Приставка "Микро-" в отношении Web-фреймворка обычно говорит о том, что фреймворк берёт на себя только маршрутизацию (routing) (сопоставление путей с обработчиками) и, возможно, немного помогает с формированием простых ответов (скажем, текстовых как в примере выше).

"Микроскопичность" часто связана ещё и с тем, что небольшие web-приложения, реализованные с помощью микрофреймворков, умещаются в один файл с кодом! А вот большие фреймворки вроде Django уже требуют тщательного распределения кода по пакетам и модулям в соответствии со строгими правилами.

И если к микрофреймворку вы, скорее всего будете со временем добавлять библиотеки, добавляющие приложению функциональности, то большой фреймворк обычно уже укомплектован кодом, как говорят, на все случаи жизни.

Такое разделение на "разумный минимум" и "всё сразу (и сразу по строгим правилам)" сказывается на простоте изучения: с микрофреймворком сильно проще стартовать! А большие фреймворки можно будет освоить позже, когда вы освоитесь с основами Web-разработки и решите создать что-то большое и сложное!

Вы могли бы подумать, что микрофреймворки — это нечто "игрушечное" или "учебное", но я предостерегаю вас от подобного вывода! Микрофреймворки применяются в реальных проектах, в том числе и больших. Разница между большим фреймворком и микрофреймворком с дополнительными библиотеками может быть минимальна. Часто выбор между тем и другим вообще зависит от вкусовых предпочтений разработчика :)

#@ Самостоятельная работа

Прочитайте главу "A Minimal Application" https://flask.palletsprojects.com/en/1.1.x/quickstart/#a-minimal-application руководства по быстрому старту с Flask и добейтесь того, чтобы приложение запускалось на вашей машине локально и сайт открывался в браузере.
'''



# >>>>>> Шаблонизация <<<<<<

@app.route('/')
def root():
    return 'Main page'

'''
В примере выше обработчик на запрос главной страницы отдаст строчку 'Main Page'. Такой пример хорошо подходит для демонстрации, но обычно браузер ожидает HTML-страницу. Причём страница может быть достаточно большой — десятки и сотни килобайтов. Если мы попробуем создавать HTML так:
'''

@app.route('/')
def root():
    title = 'My super site'
    return f'<html><body><h1>{title}</h1></body></html>'


'''
то код достаточно быстро превратится в нечто нечитаемое. Для работы с HTML во фреймворках используют специальные библиотеки, называемые шаблонизаторами (templating engines). Принцип работы шаблонизатора заключается в том, что в отдельном файле описывается шаблон, который во время работы программы загружается и превращается в HTML. При этом шаблон может содержать как обычные HTML-тэги, так и специальную разметку, позволяющую подставлять в HTML значения, отображать и прятать отдельные фрагменты по условию, "размножать" фрагменты в цикле, и тому подобное. Вот пример шаблона для популярного шаблонизатора Jinja:
'''

{% extends "email-html_base.tmpl" %}

{% block content %}
    <p>
        {{ msg }}
    </p>
    <p>
      <b>AFFECTED INSTANCES:</b>
    </p>
    <table class='noborder'>
      <tr>
    <th>UUID</th><th>IP Address</th><th>Host</th>
      </tr>
      {% for instance in instances -%}
        <tr>
          <td>{{ instance.id }}</td>
          <td>{{ instance.access_ip_v4 }}</td>
          <td>{{ instance.name }}</td>
        </tr>
      {% endfor %}
    </table>
{% endblock %}


'''
При чтении такого шаблона библиотека подставляет переменные и выполняет код логики каждый раз. Это позволяет использовать один и тот же шаблон для выдачи разных страниц, отличающихся только частью содержимого (чаще всего — подставляемыми переменными).

Стоит отметить, что многие шаблонизаторы можно использовать для формирования произвольных текстов, а не только HTML.
'''

#@ Безопасность

'''
Об этом редко говорят во время обучения, но безопасность крайне важна при работе с HTML формами и шаблонами в целом. Не понимая основ защиты, вы гарантировано сделаете ошибку, которая может привести к фатальным последствиям для проекта. Например, отсутствие экранирования пользовательских данных приведёт к тому, что появится возможность провести XSS-атаку.
'''

#@ Самостоятельная работа

'''
Добавьте к web-проложению, которое вы реализовали на прошлом уроке, вывод HTML. В этом вам поможет глава "Rendering Templates" https://flask.palletsprojects.com/en/1.1.x/quickstart/#rendering-templates всё того же руководства.
'''




# >>>>>> СУБД <<<<<<


'''
Предположим, что мы решили реализовать сайт с объявлениями и хотим дать возможность создавать их нашим пользователям. К текущему моменту мы уже знаем как вывести страницу с формой для добавления объявления. Но что делать после того, как данные формы придут на сервер? Где их хранить?

Самый простой вариант, который можно придумать — файлы. Всё, что приходит, можно записывать в файл, а при выводе читать из него. Такой подход обладает бесконечным числом недостатков и абсолютно неудобен в работе. Правильный способ работы с данными — база данных. База данных, в конечном итоге, тоже хранится в файлах, но этим процессом на 100% управляет СУБД, так называемая система управления базами данных. Именно её необходимо установить перед началом работы. В вебе наиболее распространены две системы: PostgreSQL и MySQL. Настройка и установка СУБД — не такой тривиальный процесс, как установка интерпретатора, поэтому здесь мы его рассматривать не будем. В сети вы можете найти множество готовых рецептов по установке СУБД на вашу операционную систему. Искать лучше так: "postgresql install ubuntu".

СУБД стартуют как отдельные программы и живут своей собственной жизнью. Эти системы устроены таким образом, что могут обслуживать множество разных баз данных. Обычно один сайт использует одну базу данных, но все базы данных разных сайтов могут храниться в одной СУБД. С конкретной базой данных взаимодействовать можно двумя способами:

> Запустив командную оболочку СУБД, которая позволяет в интерактивном режиме поработать с командами, записать и прочитать данные, добавить пользователя в систему и так далее. При подключении (или уже после) обязательно выбрать базу данных, с которой вы хотите взаимодействовать:

> Подключиться к СУБД из своей программы, используя драйвер. Драйвер — это библиотека, которая общается с СУБД. Она выставляет наружу относительно простой интерфейс для выполнения запросов и получения результатов. Чуть ниже мы посмотрим, как такой подход работает на практике.
'''

#@ Отношения

'''
PostgreSQL и MySQL относятся к классу реляционных баз данных, так как работа этих СУБД основана на реляционной алгебре. Мы не будем погружаться в теоретические дебри. Скажу лишь, что данные в реляционных базах хранятся в виде таблиц. Наверняка вы работали с табличными данными в Microsoft Office или Google Spreadsheets.

Каждая таблица в такой базе данных имеет своё имя и набор именованных колонок. Колонки в базе данных обычно называют полями. Например, таблица с объявлениями может называться ads и содержать следующие данные:

id	telephone	title
1	132453	Продам машину
2	342341	Куплю яхту
3	908324	Сдам в аренду палатку

Каждая строчка в таблице независима от других и представляет из себя законченный набор данных, в нашем случае — одно объявление. Строчки принято называть записями.

Обратите внимание на поле id. Его вводят искусственно, для идентификации конкретной строчки. СУБД содержат механизмы, позволяющие генерировать идентификатор автоматически при вставке данных в базу. Как правило, идентификаторы используют в адресах страниц. Например такой адрес http://myavito.ru/ads/53 выведет объявление с id, равным 53.
'''

#@ SQL.

'''
Любые манипуляции c таблицами в реляционных базах данных выполняются с помощью языка запросов SQL (Structured Query Language). Открыв командную оболочку СУБД, можно попробовать выполнить следующие запросы (предполагаем, что таблица ads уже создана):

SELECT * FROM ads; -- выбрать все записи
SELECT title FROM ads WHERE id = 4; -- выбрать title для записи с id равным 4
SELECT telephone FROM ads ORDER BY id DESC; -- выбрать все телефоны отсортировав их по полю id в обратном порядке

INSERT INTO ads (telephone, title) VALUES ("392503", "Куплю слона"); -- вставить в таблицу ads новую запись

DELETE FROM ads WHERE id = 5; -- удалить запись с id равным 5

Как видите, SQL — это простой текст, причём довольно понятный и без лишних пояснений. Конечно, в случае сложных SQL-запросов, придётся сильно попотеть, чтобы их понять, но в большинстве случаев SQL получается достаточно простой.
'''

#@ Драйвер.


'''
Если внутри командной оболочки базы мы можем выполнять SQL напрямую, то из кода этого не сделать. Необходим драйвер, который передаст наш SQL базе данных и вернёт ответ. Но перед тем, как послать запрос, нужно подключиться к самой базе, введя правильное имя пользователя и пароль. СУБД — многопользовательская система с продвинутой системой прав. Безопасность при работе с базой — ключевой аспект. Ведь данные — самое ценное, что есть в приложении. Если потеряются данные, то бизнес, скорее всего, прекратит своё существование.

К примеру, драйвер postgres (сторонний пакет https://postgres-py.readthedocs.io/) позволяет работать с PostgreSQL как-то так:

>>> from postgres import Postgres
>>> db = Postgres("postgres://user@localhost/test")
>>>
>>> db.run("CREATE TABLE foo (bar text, baz int)")
>>> db.run("INSERT INTO foo VALUES ('buz', 42)")
>>> db.run("INSERT INTO foo VALUES ('bit', 537)")
>>>
>>> db.one("SELECT * FROM foo WHERE bar='buz'")
Record(bar='buz', baz=42)
>>>
>>> db.all("SELECT * FROM foo ORDER BY bar")
[Record(bar='bit', baz=537), Record(bar='buz', baz=42)]
>>>
>>> db.all("SELECT baz FROM foo ORDER BY bar")
[537, 42]
'''

#@ Что нужно выучить.

'''
Напомню, что не нужно расстраиваться, если вы не поняли большинство описанных здесь вещей. Достаточно, что теперь вы осознаете, насколько непросто с наскоку прыгнуть в реальную разработку и нужна предварительная подготовка. Перечислю некоторые новые темы, которые нужно изучить, чтобы без проблем писать код, представленный выше:

> Базы данных. Необходимо уметь устанавливать и настраивать их. Настройка включает в себя оперирование сокетами (в том числе сетевыми), управление пользователями и многими другими вещами (опять знание операционных систем).
> Необходимо знать SQL, что включает в себя и основы теории множеств.
> Понятия нормализации и денормализации. Нормальные формы. Ключи и индексы.
> Сериализация и десериализация.
> Идемпотентность.
> Fluent Interface.
> Итератор.
> Безопасность: Экранирование, SQL Injection.
'''

#@ Самостоятельная работа

'''
С этого урока самостоятельно работать не получится, появляется слишком много нюансов по настройке и подключению к базе данных из кода. Вы, конечно, можете попробовать (и даже хорошо бы), но обладая только базовыми знаниями Python, вам понадобится приложить сверхусилия для настройки и запуска всей системы в целом.

В любом случае полезно установить саму базу и поиграться с ней.
'''



# >>>>>> ORM <<<<<<

'''
Любое программное обеспечение разрабатывается под конкретную предметную область, например, система аналитики оперирует понятиями "просмотр", "сессия", "воронка", "когорта", а интернет-магазин — "товар", "категория", "платёжный шлюз". Все вместе они составляют онтологию предметной области (говорят модель предметной области). Кроме самих понятий онтология содержит и описание их связей. Например, сущность "Пользователь" связана с сущностью "Покупка" как "один ко многим". То есть один пользователь может выполнить сколько угодно покупок, но каждая покупка принадлежит только одному пользователю.

Модель предметной области — основа коммуникации и взаимопонимания между членами команды. Она не зависит ни от языка программирования, ни от программирования вообще. Не важно кто общается: программисты между собой или программисты с заказчиками, менеджерами или дизайнерами. Все вместе они оперируют сущностями и связями предметной области и бизнес-правилами, используемыми в данной программе. К таким правилам может относиться автоматическое включение скидки при заказе от определённого объёма товаров.


Важно понимать, что модель на то и модель, что она отражает лишь часть предметной области с некоторой детализацией. Причём, в программах из одной области, но от разных производителей, модель может быть разной. Конечно же, в таких областях, как бухгалтерия, есть некоторый набор фиксированных сущностей, их связей и правил работы, но есть и те вещи, где возможны вариации. В менее формальных областях таких возможностей ещё больше.

Приведу несколько примеров из Хекслета. Количество сущностей — больше сотни, количество связей — много сотен, количество правил посчитать сложно, их тоже много.

На основе модели предметной области формируется модель данных в коде. Создаются сущности, определяются их связи. Затем строится рабочий код, который оперирует сущностями, исходя из требований (бизнес-правил). На этом этапе возникает вопрос: а как эти сущности отображаются (от англ. "mapping" — "отображение") на базу данных, ведь именно там в конечном итоге всё хранится.

Самый простой вариант — создавать по таблице на каждую сущность и связывать их через внешние ключи. Именно так и делают в большинстве проектов, но не руками, а используя ORM (object-relation mapper). По сути, ORM — фреймворк для данных. С помощью него описываются сущности и их связи, определяется то, как сущность отображается на базу данных (как правило в полуавтоматическом режиме). ORM берет на себя серьёзную часть работы по генерации SQL-запросов, по извлечению данных и кастингу (casting, преобразование типов базы данных в типы целевого языка и обратно), по автоматическому извлечению связей. В итоге получается, что ORM прячет всю работу с базой данных (требуя только правильного конфигурирования) и сам выполняет все необходимые запросы. В сложных случаях их все равно приходится писать самостоятельно, но, как минимум, ORM содержат в себе query builder, который упрощает генерацию SQL.

В экосистеме Python таких ORM существует несколько, некоторые из них разрабатывались под конкретные фреймворки и поставляются с ними. Другие вполне самостоятельны. Рассмотрим пример, реализованный с использованием Django ORM.

Определение сущности Photo:
'''

from django.db import models

class Photo(models.Model):
    title = models.CharField(max_length=200)
    image = models.ImageField()
    slug = models.SlugField()

# Использование:

# получаем объекты из базы
photos = Photo.objects.all()
# передаём их в шаблон
render(request, 'polls/detail.html', {'photos': photos})


'''
Код, описывающий сущность, может показаться простым, однако степень автоматизации в Django ORM очень велика — под капотом у такого простого кода скрыты и создание сущности в БД, и целый набор проверок тех значений, которые вы помещаете в модель. По хорошему, перед тем как начинать работать с ORM, нужно сначала научиться основам баз данных. Причём не через программирование, а через прямую работу с базой. Познакомиться с понятием нормализации, внешними и первичными ключами, индексами, планом запроса и научиться работать с SQL как для изменения структуры базы данных, так и для манипулирования данными внутри базы. Затем перейти на уровень выполнения запросов из языка программирования (в Python для этого используется различные библиотеки вроде postgres). И только затем переходить к ORM. Всё это будет далее в курсах.
'''



# >>>>>> MVC <<<<<<

'''
В предыдущем уроке мы дошли до следующей структуры:
'''

# получаем объекты из базы
photos = Photo.objects.all()
# передаём их в шаблон
render(request, 'polls/detail.html', {'photos': photos})

'''
> Модель предметной области (или просто Модель) описана с помощью ORM (хотя это не обязательно, хранилище — вещь отдельная от модели).
> Функция-обработчик обращается к модели для выполнения запрошенных операций и выводит необходимые данные в шаблон.
> Шаблон описывает представление конкретной страницы и строится на основании данных переданных из функции-обработчика.

Описанная структура носит гордое имя MVC или Model-View-Controller (обычно добавляют приписку version 2, так как первая версия MVC используется для толстых клиентов, в которых все работает немного по-другому), где M - модель предметной области, C - наша функция обработчик (в других фреймворках могут быть другие сущности), а V - шаблон. MVC разделяет приложение минимум на три слоя и определяет то, как они могут взаимодействовать друг с другом. Это важно для создания модульных приложений, то есть таких, которые легко развивать и модифицировать. При этом никто не запрещает добавлять новые и дробить текущие слои, все это уже зависит от сложности самого приложения.

M — ядро приложения. В идеале — чистая бизнес-логика. M не знает ничего о других частях приложения и не может на них влиять.
C - использует M для выполнения запрашиваемых операций и отвечает за генерацию V.
V - получает данные от C и иногда от M, но такое не приветствуется. И уж точно V не должен знать ничего о базе данных. Кстати, этим грешат начинающие разработчики, которые выполняют SQL запросы прямо из шаблонов.

MVC является архитектурным шаблоном (или паттерном проектирования). Шаблон проектирования в разработке — повторяемая архитектурная конструкция, представляющая собой решение проблемы проектирования в рамках некоторого часто возникающего контекста. В нашем случае контекст — обработка HTTP-запросов.

Паттернов проектирования очень много на все случаи жизни. Некоторые из них очень простые и ближе к идиомам, то есть каким-то локальным участкам кода, которые принято писать тем или иным способом в конкретном языке. Некоторые паттерны — всеобъемлющие, подобные MVC. Они определяют глобальные ограничения, но ничего не говорят о способе реализации. В любом случае паттерны — не догма и не формальная спецификация, а значит всегда есть место для самостоятельного выбора.

В MVC заложена довольно простая, но важная идея разделения приложения на слои с чёткими границами. Такой подход позволяет развивать каждый слой независимо от других, при условии, что у вас правильно выстроены зависимости между ними. Обратите внимание, что в MVC все связи однонаправленные. Другими словами, в MVC нет двух слоёв, которые знают друг о друге одновременно. Если один слой знает о другом, то второй ничего не знает о первом и наоборот. Модульность (в общем случае — абстракция) — это один из ключевых факторов, делающих приложения по настоящему качественными с точки зрения разработки. Как вы увидите позже, многие веб-фреймворки построены именно по модели MVC с небольшими модификациями, не влияющими на ключевую идею.
'''



# >>>>>> Fullstack-фреймворки <<<<<<


'''
Фреймворк Flask, который мы рассматривали в самом начале курса, относится к классу так называемых микрофреймворков. Все они в той или иной степени являются клонами Ruby-фреймворка Sinatra, который задал моду на микрофреймворки.

Посмотрите насколько схожа структура кода:

#@ Ruby:

# Ruby
require 'sinatra'
get '/frank-says' do
  'Put this in your pipe & smoke it!'
end

Java:

// Java
import static spark.Spark.*;

public class HelloWorld {
    public static void main(String[] args) {
        get("/hello", (req, res) -> "Hello World");
    }
}
JavaScript:

// Javascript
import Express from 'express';
const app = new Express();

app.get('/', (req, res) => res.send('Hello World!'));
Python:
'''

# Python
from flask import Flask
app = Flask(__name__)

@app.route("/")
def hello():
    return "Hello World!"


'''
Все они как братья-близнецы в плане определения маршрутов и задания обработчиков для них. Кроме базовой функциональности в микрофреймворках нет ничего. Все остальное придётся ставить отдельно.

В противовес микрофреймворкам — полноценные фреймворки, большие пакеты с кодом, включающие в себя "из коробки" (по умолчанию) всё, что только может потребоваться. Они обычно хорошо расширяются, а на GitHub лежит множество полезных дополнений. Большая история веб-фреймворков берет своё начало с 2004 года, когда появился первый релиз Ruby On Rails, фреймворка на языке Ruby. "Рельсы" намного обогнали своё время и задали тон на многие года вперёд. Многие современные веб-фреймворки — клоны Rails в той или иной степени.

И если в Ruby кроме Rails, можно сказать, больше ничего и нет (что положительно сказывается на развитии, так как все бегут в одну сторону), то в Python роль "фреймворка по умолчанию" играет Django, хотя в разное время существовали и другие сравнимые с ним по мощности фреймворки (Zope, Plone, WebPy и прочие).

Приведу коротко возможности, которыми обладают современные фреймворки:

> Генерация кода. Любой полноценный фреймворк содержит утилиту, позволяющую из командной строки генерировать код, скажем, тесты или миграции.
> Встроенные механизмы для тестирования. Другими словами, фреймворк даёт возможность начать писать тесты практически без необходимости что либо дополнительное ставить или конфигурировать.
> ORM. Либо своя, либо популярная для языка в целом.
> Шаблонизатор и хелперы (вспомогательные функции) для повторяющихся задач вывода информации.
> Абстракции для работы с письмами.
> Инструменты для интернационализации и локализации. Причём, в идеале, чтобы все остальные части фреймворка также были интегрированы с i18n.
> Механизмы, обеспечивающие безопасность, например, CQRS.
> Кэширование.
'''



# >>>>>> API <<<<<<

'''
Пока мы говорили только о "классических" Web-приложениях — страницах гипертекста, отображаемых в браузере. И если классическое Web-приложение отдаёт браузеру только лишь страницы — такое приложение частно называют Web-сайтом (website) — то современные сложные Web-приложения чаще всего ведут себя иначе. При открытии адреса приложения в браузере сервер единожды отдаёт HTML-страницу, а в дальнейшем страница с помощью JavaScript сама отвечает за отображение данных, которые не встроены в разметку страницы, но вместо этого загружаются с сервера отдельными запросами от страницы к API.

API или Application Programming Interface (Программный интерфейс приложения), это протокол взаимодействия между вашим приложением и другими программами. API не является частью, непосредственно отвечающей за общение приложения и пользователя. Вместо этого пользователь обычно использует отдельную программу-клиент, которая обращается к серверу лишь по мере необходимости, а не в ответ на каждое действие пользователя (как это обычно делает браузер, когда запрашивает Web-страницу, как только пользователь введёт URL или кликнет ссылку).

Более того, одно такое приложение может использовать несколько разных API, не все из которых даже предоставляются тем же сервером, который отдал первоначальную страницу! Так, например, сайт может одновременно показывать горячие новости из Twitter, карту Google Maps, встроенное YouTube-видео — весь этот контент запрашивается у соответствующих сервисов именно через API.

Ещё один пример API, используемый повсеместно — вход (аутентификация) на сайт с помощью какой либо соцсети. В этом случае взаимодействие между клиентом (браузером) его сервером, а также с сервером, предоставляющим API для аутентификации, и даже взаимодействие между этими серверами без участия клиента, может быть достаточно сложным! Это вам не простой диалог "запрос-страница"!

Современный Web немыслим без API, ведь они позволяют компаниям делать хорошо одно дело (карты, хранение видео и фото, аутентификацию), а разработчик может использовать эти наработки в своих приложениях. А в итоге выигрывают все — и пользователи, и автор приложения, и владельцы API (зарабатывающие на своём контенте).
'''



########### Python: Основы текстового ввода-вывода ###########

'''
Каждый программист постоянно сталкивается с необходимостью прочитать что-то из файла и записать что-то в файл. При этом может показаться, что файлы — это же так просто!

Немного теории
Однако в современных операционных системах файловый ввод-вывод устроен достаточно сложно. Для обеспечения максимального быстродействия чтения и записи в файлы, а также контроля за безопасностью этого процесса, большинство ОС не позволяют программам напрямую работать с диском. Да те и не могут этого сделать чисто физически: невозможно в одну программу заложить понимание всего того множества файловых систем (file system, FS — способ хранения данных в файлах на диске), которые существуют и используются в наше время! А ведь кроме поддержки разных FS, современная операционная система занимается ещё кэшированием операций с диском, проверкой прав доступа, и прочими служебными делами.

Программам же операционная система предоставляет специальные объекты — файловые дескрипторы (file descriptors). Имея файловый дескриптор, можно "просто писать" и "просто читать" данные, не задумываясь о файловой системе, кэшировании и прочих "низкоуровневых сущностях".

И вот тут-то и скрывается подводный камень: файловые дескрипторы удобны, но на создание каждого расходуется некоторое вполне ощутимое кол-во ресурсов. Поэтому у операционной системы есть общий лимит на количество одновременно использующихся файловых дескрипторов.И при этом каждая программа дополнительно ограничена — имеет свой собственный лимит. Как только программа исчерпает доступное ей кол-во дескрипторов, следующая же попытка открыть очередной файл закончится с ошибкой! Поэтому программисту важно следить за тем, сколько файлов программа открывает в каждый момент и закрывает ли она файлы своевременно.

Следить за закрытием файлов важно ещё и потому, что другая программа не сможет открыть файл, пока ваша его не закроет. А ещё некорректно закрытый файл может быть сохранён на диск неправильно, что приведёт к потере данных.
'''



# >>>>>> Открытие и закрытие файлов <<<<<<

'''
В Python файл открывается с помощью функции open, которой нужно передать путь до файла и режим. С путём всё понятно. А режим нужен для того, чтобы указать то, как мы хотим использовать файл: будем ли мы записывать или читать, будем работать с текстом или же с бинарными данными, хотим ли мы очистить файл перед записью в него. Пока мы будем работать с файлами в самых простых режимах: чтение и запись текста.

Чтобы что-то прочитать из файла, надо бы его создать и что-то в него записать. С этого и начнём. Откроем файл на запись:

>>> f = open('foo.txt', 'w')
>>> f
<_io.TextIOWrapper name='foo.txt' mode='w' encoding='UTF-8'>

Переменная f теперь ссылается на некий файловый объект. Пусть вас не пугает имя типа, пока вы можете обращать внимание только на параметры — name, mode и encoding. Имя и режим те, что мы указали при вызове open, а кодировка encoding выбрана умолчательная — UTF-8 (практически всегда именно она вам и будет нужна).

Итак, файл мы открыли. Закрывается он так:

…
>>> f.close()
>>> f.closed
True

closed здесь — атрибут объекта f. Атрибуты — это такие переменные внутри связанного объекта.
'''

#@ Автоматическое закрытие файла.

'''
Вы уже знаете, что Python — язык с автоматическим управлением памятью. Зная это, можно догадаться, что среда исполнения закрывает файл, когда удаляется последняя ссылка на файловый объект. Легко и просто!

В простых скриптах можно не заниматься ручным закрытием файлов. Дело в том, что скрипты, как правило, не открывают большое количество файлов одновременно и выполняются за достаточно короткое время. Таким образом закрытие файлов по завершению выполнения скрипта вполне приемлемо.

А вот в больших программах, которые работают в течение продолжительного времени, уже нужно следить за тем, чтобы файлы закрывались вовремя, в идеале — сразу после того, как всё нужное было из файла прочитано или записано в него.
'''



# >>>>>> Запись и чтение <<<<<<

'''
Давайте откроем файл на запись, запишем в него текст, и закроем файл. Метод write записывает строку в файл без какой-либо дополнительной обработки:

>>> f = open("foo.txt", "w")
>>> f.write('Hello\nWorld!')
12
>>> f.close()

Здесь "w" означает режим "запись" (write), а 12 сообщает о кол-ве символов, которые мы записали в файл соответствующим вызовом write.

Теперь откроем файл в режиме чтения и прочитаем всё содержимое:

>>> f = open("foo.txt", "r")  # "r" — чтение, read
>>> f.read()
'Hello\nWorld!'
>>> f.close()

Ура, мы прочитали ровно то, что записали до этого.
'''

#@ Позиция в файле.

'''
Вызывать метод write можно несколько раз. Каждый раз мы получим в ответ кол-во символов, которое записали. Текст же будет накапливаться. Так происходит потому, что вызов метода write перемещает так называемую текущую позицию в файле в его (файла) конец.

read тоже учитывает текущую позицию: читает текст от неё и до конца файла. Методу можно явно сказать, сколько символов должно быть прочитано — в этом случае метод постарается прочитать указанное количество символов, если таковых хватает в файле. В любом случае вызов метода read перемещает позицию в то место, где закончилось чтение.

При открытии файла текущая позиция всегда указывает на первый символ текста (т.е. равна нулю). А при прочтении файла до конца с помощью вызова метода read без параметров позиция перемещается в конец файла и последующие чтения ничего не дают:

>>> f = open("foo.txt", "r")  # "r" — чтение, read
>>> f.read()
'Hello\nWorld!'
>>> f.read()
''
>>> f.close()

Позицию в файле можно изменять и вручную. Для этого используется метод seek, о котором вы можете почитать в документации.
https://docs.python.org/3/library/io.html#io.TextIOBase.seek
'''

#@ Позиция и текстовые файлы.

'''
Чаще всего вам придётся работать с текстовыми файлами. В таких файлах позиция не столь важна, т.к. не учитывает разделение текста на строки. А вот при работе с файлами в двоичном режиме умение работать с позицией и смещениями очень важно. Советую поэкспериментировать с позиционированием внутри файлов и записью/чтением нетекстовых данных.
'''



# >>>>>> Построчные чтение и запись <<<<<<

#@ Запись текста построчно.

'''
На предыдущем уроке я упоминал, что последовательные вызовы метода write дописывают текст в конец. Но часто мы имеем итератор, выдающий некий текст построчно. Можно, конечно, написать цикл, однако есть способ и получше: метод writelines. Работает он так:

>>> f = open("foo.txt", "w")
>>> f.writelines(["cat\n", "dog\n"])
>>> f.close()
>>> f = open("foo.txt", "r")
>>> print(f.read())
cat
dog

>>> f.close()

Как вы видите, все строчки записались в нужном порядке. Такой вариант записи предпочтителен, когда нужно записать большой объем текста, который вы получаете и обрабатываете строчка-за-строчкой. Можно предварительно накопить весь текст в одну большую строку, однако для этого может потребоваться большой объём памяти. Гораздо лучше записывать строчки по мере готовности и writelines для этого подходит идеально!
'''

#@ Чтение файла построчно.

'''
Файл построчно можно не только писать, но и читать:

>>> f = open("foo.txt")
>>> f.readline()
'cat\n'
>>> f.readline()
'dog\n'
>>> f.readline()
''
>>> f.close()

Здесь Python сам понимает, что строчки в тексте нужно разделять по символу перевода строки. Вызов readline перемещает позицию к следующей строке и как только текст закончится, все последующие вызовы будут возвращать пустую строку.

Заметьте, строчки текста содержат и сами символы перевода строки.

Метод readline довольно удобен, когда мы хотим управлять процессом чтения из файла. Однако часто нужно просто прочитать все строчки текста. Для этого нужно всего навсего... проитерировать файловый объект! При этом вы получите итератор строчек, который можно вычитать в цикле:


>>> f = open("foo.txt")
>>> for l in f:
...     print(l)
...
cat

dog

>>> f.close()


Если не указать режим, как я сделал в этот раз, то файл откроется на чтение. Удобно.

Подумайте, почему напечатались лишние пустые строчки.

Итератор строчек файла, как и положено, ленив. Он вычитывает строки лишь по мере необходимости. А останавливается тогда, когда читать уже становится нечего.

Ленивость позволяет, в частности, не дочитать файл:


>>> f = open("foo.txt")
>>> for l in f:
...     print(l)
...     break
...
cat

>>> print(f.read())
dog

>>> f.close()

Если же нужно получить сразу все строчки текста в виде списка, то можно вызывать метод readlines и получить тот самый список.
'''

#@ Потоковая обработка больших файлов.

'''
Использование итераторов очень удобно для потоковой обработки файлов. При потоковой обработке нет необходимости хранить весь файл в памяти, а значит обрабатываемые файлы могут быть очень большими! Вот так может выглядеть скрипт, который нумерует строчки входного файла и записывает в выходной:
'''

input_file = open("input.txt", "r")
output_file = open("output.txt", "w")
for i, line in enumerate(input_file, 1):
    output_file.write("{}) {}".format(i, line))
input_file.close()
output_file.close()


# Сохраните этот скрипт в файл и посмотрите, как он работает.




# >>>>>> Менеджеры контекста <<<<<<


'''
Ручное закрытие файлов, а так же отдача закрытия на откуп среде исполнения, обладают одним существенным недостатком: если между открытием файла на запись и его закрытием произойдёт ошибка, то в лучшем случае файл окажется открыт слишком долго (может остаться ссылка), а в худшем случае не сохранится часть данных.

Хочется иметь возможность автоматически закрывать файл сразу после окончания работы с ним и осуществлять закрытие даже при возникновении ошибки. Файловые объекты уже умеют работать в таком режиме, но для этого их нужно использовать как менеджеры контекста.
'''

#@ Краткое введение в менеджеры контекста.

'''
Менеджер контекста (context manager) — это некий объект, реализующий одноимённый протокол (да, кругом протоколы!). Объекты, реализующие этот протокол, позволяют использовать следующий специальный синтаксис:
'''

with object as foo:
    # Здесь нам доступен ресурс foo.
    # Это тело with-блока.
# А здесь ресурс foo уже освобождён,
# даже если в теле with-блока произошла ошибка.

'''
Весь код в теле with-блока работает "в контексте". Чаще всего контекст подразумевает выделение некоего ресурса, например, файла. По выходу из контекста ресурс автоматически освобождается, даже если при выполнении блока возникло исключение. То, что нам нужно!
'''

#@ Использование файлов как менеджеров контекста.

'''
Рассмотрим сразу комплексный пример. Для чего перепишем скрипт нумерации строк файла из предыдущего урока:
'''

with open("input.txt", "r") as input_file:
    with open("output.txt", "w") as output_file:
        for i, line in enumerate(input_file, 1):
            output_file.write(
                "{}) {}".format(i, line)
            )

'''
Явные вызовы close пропали, но теперь файлы закрываются надёжно и вовремя!

В дальнейшем мы рассмотрим подробнее и сам протокол менеджеров контекста и познакомимся с несколькими встроенными реализациями оного. Но именно файловый CM чаще всего используется в повседневной жизни питониста. Учитесь использовать его и ваши программы будут надёжными!
'''


'''
src/url.py
Реализуйте абстракцию для работы с URL. Она должна извлекать и менять части адреса.

Интерфейс:

make(url) - Конструктор. Создает URL.
get_scheme(data) - Селектор (геттер). Извлекает схему.
set_scheme(data, scheme) - Сеттер. Меняет схему.
get_host(data) - Геттер. Извлекает host.
set_host(data, host) - Сеттер. Меняет host.
get_path(data) - Геттер. Извлекает путь.
set_path(data, path) - Сеттер. Меняет путь.
get_query_param(data, param_name, default=None) - Геттер. Извлекает значение для параметра запроса. Третьим параметром функция принимает значение по умолчанию, которое возвращается тогда, когда в запросе не было такого параметра
set_query_param(data, key, value) - Сеттер. Устанавливает значение для параметра запроса. Если передано значение None, то параметр отбрасывается.
to_string(data) - Геттер. Преобразует URL в строковой вид.
Все сеттеры должны возвращать новый изменённый URL, а старый оставлять неизменным.

Примеры
>>> import url
>>> u = url.make('https://hexlet.io/community?q=low')
>>>
>>> u = url.set_scheme(u, 'http')
>>> url.to_string(url)
'http://hexlet.io/community?q=low'
>>>
>>> u = url.set_path(u, '/404')
>>> url.to_string(u)
'http://hexlet.io/404?q=low'
>>>
>>> url.get_query_param(u, 'q')
'low'
>>>
>>> u = url.set_query_param(u, 'page', 5)
>>> url.to_string(u)
'http://hexlet.io/404?q=low&page=5'
>>>
>>> u = url.set_query_param(u, 'q', 'high')
>>> url.to_string(u)
'http://hexlet.io/404?q=high&page=5'
>>>
>>> u = url.set_query_param(u, 'q', None)
>>> url.to_string(u)
'http://hexlet.io/404?page=5'
Подсказки
Парсинг URL — urllib.parse.urlparse
Парсинг параметров запроса — urllib.parse.parse_qs
Формирование строки с параметрами запроса — urllib.parse.urlencode
Сборка конечного URL — urllib.parse.urlunparse
urlparse возвращает иммутабельный объект типа namedtuple. Получить копию такого объекта с одним изменённым значением можно с помощью метода _replace.
'''

from urllib.parse import parse_qs, urlencode, urlparse, urlunparse


def make(url):
    """Make an URL representation from string."""
    return urlparse(url)


def get_scheme(data):
    """Return a scheme of given URL."""
    return data.scheme


def set_scheme(data, scheme):
    """Return a new URL with replaced host."""
    return data._replace(scheme=scheme)  # noqa: WPS437


def get_host(data):
    """Return a host of given URL."""
    return data.netloc


def set_host(data, host):
    """Return a new URL with replaced host."""
    return data._replace(netloc=host)  # noqa: WPS437


def get_path(data):
    """Replace scheme of given URL."""
    return data.path


def set_path(data, path):
    """Return a new URL with replaced path."""
    return data._replace(path=path)  # noqa: WPS437


def get_query_param(data, key, default=None):
    """
    Return a value of named query parameter of given URL.

    Function returns default value if named parameter is not present.
    """
    return parse_qs(data.query).get(key, [default])[0]


def set_query_param(data, key, value):
    """Return a new URL with replaced query parameter."""
    params = parse_qs(data.query)
    if value is None:
        params.pop(key, None)
    else:
        params[key] = value
    return data._replace(query=urlencode(params, doseq=True))  # noqa: WPS437


def to_string(data):
    """Return a string representation of given URL."""
    return urlunparse(data)



###### ООП #####

'''
Объекты и классы.
Итак, в Python объекты, это значения, создаваемые на основе шаблона — класса. Программист описывает с помощью специального синтаксиса содержимое класса и потом во время исполнения создаёт объекты — экземпляры (instances) этого класса. У класса есть свои данные — атрибуты класса. К ним имеют доступ все экземпляры класса. При этом экземпляры имеют свои атрибуты — атрибуты экземпляра. Эти данные доступны только объекту владельцу.

Технически в Python любой объект может получить доступ к содержимому любого другого объекта, если имеет ссылку на него. Но на уровне добровольных соглашений такой доступ можно ограничивать.

Некоторые атрибуты могут быть функциями. В этом случае такие атрибуты называют методами. Вы уже пользовались методами списков и словарей, так что некоторое представление о методах у вас уже имеется!

Инкапсуляция.
Инкапсуляция — это упаковывание данных и поведения (процедур, работающих с данными) в один объект. Инкапсуляция преследует всё ту же цель — сокрытие сложности за абстракцией. Но просто так складывать всё подряд в какой-то объект не следует. Данных и поведения должно быть столько, сколько необходимо и достаточно: объект должен хранить все свои и только свои данные самостоятельно и предоставлять все необходимые средства для манипуляции этими данными.

Представим для примера, что у нас смоделирован объект "человек". Человек может иметь домашних питомцев. Так вот с точки зрения инкапсуляции неверно будет хранить питомцев где-то в отдельном списке: питомцы принадлежат человеку, это часть данных модули человека в нашей системе. Делаем вывод: список питомцев должен быть инкапсулирован в объект "человек".

Теперь представим, что нам нужно прикреплять питомцев к уже существующему человеку. Если мы дадим прямой доступ к списку питомцев и разрешим делать с этим списком любые преобразования, возможные для обычных списков, то мы можем получить человека, питомцами которого являются две десятка чисел и строк, а также пароход, файл и None! По-хорошему, программист, работающий с нашей моделью человека, вообще не должен знать, что питомцы хранятся в списке, ему достаточно (и необходимо) метода "добавить питомца" — вот это и есть абстракция!

Полиморфизм.
Полиморфизм ("многообразие форм" по-гречески) позволяет смотреть на разные объекты так, чтобы с определённой точки зрения они были похожи. Под похожестью здесь я подразумеваю одинаковое поведение, то есть возможность выполнить одни и те же действия.

Например, для того, чтобы произвести перекличку, мне достаточно знать, что все опрашиваемые субъекты могут назвать себя. И мне в данном случае не важно, у кого я спрашиваю имя — у человека, робота или говорящего динозавра.

Так вот, код, который работает с разными объектами без точного знания того, с чем он работает в данный момент, и использующий только лишь их (объектов) общие свойства, называется полиморфным. А возможность писать такой код — и есть полиморфизм.

Как вы можете уже догадаться, полиморфизм тоже связан с абстракцией: полиморфному коду достаточно знать об объектах только важные ему сведения, от остального знания код абстрагируется!

В приведённом выше примере про человека и питомцев мы можем ввести такую абстракцию: питомцем может считаться что угодно, чем человек может владеть и о чём может заботиться, получая от заботы удовольствие (очень абстрактное описание понятия "питомец", не правда ли?). Под эту абстракцию подойдёт, например, камень, или игрушечный робот — его можно любить, о нём можно заботиться (мыть камень, менять батарейки у робота). Вот такая вот забавно абстрактная модель взаимоотношений человека с питомцем :)

Наследование.
Наследование — свойство объектной модели устанавливать связь между классами так, что классы-потомки получают (наследуют) те же свойства и поведение, которыми обладают классы-предки. Одни и те же классы могут быть потомками одних классов и при этом являться предками для других — так получаются "иерархии классов".

Иногда такие иерархии повторяют иерархии объектов реального мира, в других ситуациях сущности, описываемые классами могут описывать что-то, не имеющее аналогов за пределами модели. Но во всех случаях мы опять же получаем инструмент для абстрагирования: если мы знаем, что некий класс реализует нужное нам поведение, то мы можем предполагать, что и все его потомки, в том числе и непрямые, будут этим поведением обладать!

Всё в том же примере системы с людьми и питомцами все питомцы (соответствующие классы) семейства кошачьих могут иметь общего предка (тоже класса) "Абстрактная Кошка". Про которую известно, что она умеет прыгать и пить молоко. Это знание позволит нам, всего лишь проверив принадлежность конкретного питомца к Абстрактным Кошкам, понять, чем мы можем питомца кормить и хватит ли невысокого забора вокруг жилища, чтобы питомец не убежал.

Тут вы можете даже увидеть связь наследования с полиморфизмом: если мы знаем, что питомец — кошка, то может статься, что большего нам знать и не нужно. Получается полиморфный код, работающий только с кошками, но зато с любыми!

ООП и реальный мир.
Во многих источниках информации об ООП говорят о том, что объектный подход интуитивен, ведь он позволяет описывать реальный мир. После знакомства с подходом при подобном его позиционировании разработчик часто начинает строить иерархии классов, подобные существующим в реальности: "млекопитающие — кошачьи — тигры". Вот только у ООП нет такой цели — моделировать жизнь!

Программы пишутся для компьютеров. И пишутся в основном не биологами или астрономами, а "компьютерщиками". Поэтому гораздо больше шансов встретить объект-дерево, моделирующий не "берёзу", а "красно-чёрное" (и это не слегка подгоревший осенью клён!). Программисту нужно управлять сложностью кода, а не каталогизировать флору и фауну, вот он и абстрагирует сущности, выделяя их из кода, из алгоритмов!

ООП — это всего лишь развитие существовавших и до появления самого термина "Объектно Ориентированное Программирование" инструментов. Объекты в голове программиста существовали уже тогда, когда он использовал только структуры данных и процедуры для работы с оными. Выделение подхода ООП всего лишь систематизировало уже привычные техники, внесло общую терминологию и общие техники для решения типичных задач (те самые "паттерны проектирования").

Предметная область — те самые игра, игроки, персонажи, битвы — тоже поддаётся моделированию с помощью объектов. Но моделирование это должно делаться не для красоты самой модели, не для составления каталога игровых сущностей, а для упрощения написания кода, решающего конкретную задачу (написания игры)!
'''

